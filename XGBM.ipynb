{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data_m1 = pd.read_excel('data/M1.xlsx')\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X_m1 = data_m1.drop('WPR', axis=1)\n",
    "y_m1 = data_m1['WPR']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_m1, X_test_m1, y_train_m1, y_test_m1 = train_test_split(X_m1, y_m1, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline XGBoost MSE (Train):  0.623058598718014\n",
      "Baseline XGBoost MSE (Test):  0.6420943976217208\n"
     ]
    }
   ],
   "source": [
    "#Baseline model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Baseline XGBoost model\n",
    "xg_reg_baseline = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                                   colsample_bytree=0.3, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth=5, \n",
    "                                   n_estimators=100)\n",
    "xg_reg_baseline.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Predictions for training and test sets\n",
    "y_train_pred_baseline = xg_reg_baseline.predict(X_train_m1)\n",
    "y_test_pred_baseline = xg_reg_baseline.predict(X_test_m1)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "mse_train_baseline = mean_squared_error(y_train_m1, y_train_pred_baseline)\n",
    "mse_test_baseline = mean_squared_error(y_test_m1, y_test_pred_baseline)\n",
    "\n",
    "print(\"Baseline XGBoost MSE (Train): \", mse_train_baseline)\n",
    "print(\"Baseline XGBoost MSE (Test): \", mse_test_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: Swarm best objective change less than 1e-08\n",
      "Best Parameters from PSO: [ 0.15904774  3.16678363 52.25852661]\n",
      "Best MSE from PSO: 0.611900692378837\n"
     ]
    }
   ],
   "source": [
    "#PSO Optimization of hyperparameters\n",
    "from pyswarm import pso\n",
    "\n",
    "# Objective function for PSO\n",
    "def pso_objective(params):\n",
    "    learning_rate, max_depth, n_estimators = params\n",
    "    xg_reg = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                              colsample_bytree=0.3, \n",
    "                              learning_rate=learning_rate, \n",
    "                              max_depth=int(max_depth), \n",
    "                              n_estimators=int(n_estimators))\n",
    "    xg_reg.fit(X_train_m1, y_train_m1)\n",
    "    predictions = xg_reg.predict(X_test_m1)\n",
    "    return mean_squared_error(y_test_m1, predictions)\n",
    "\n",
    "# Define bounds for learning_rate, max_depth, n_estimators\n",
    "bounds = ([0.01, 3, 50], [0.2, 10, 200])\n",
    "\n",
    "# Run PSO\n",
    "best_params, best_mse = pso(pso_objective, bounds[0], bounds[1], swarmsize=50, maxiter=100)\n",
    "\n",
    "print(\"Best Parameters from PSO:\", best_params)\n",
    "print(\"Best MSE from PSO:\", best_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The best solution found:                                                                           \n",
      " [ 0.16391442  4.91699179 51.03343838]\n",
      "\n",
      " Objective function:\n",
      " 0.6167259495562297\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: GA is terminated due to the maximum number of iterations without improvement was met!Best Parameters from GA: [ 0.16391442  4.91699179 51.03343838]\n",
      "Best MSE from GA: 0.6167259495562297\n"
     ]
    }
   ],
   "source": [
    "#Genetic Algorithm Optimization of hyperparameters\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "\n",
    "def ga_objective(params):\n",
    "    learning_rate, max_depth, n_estimators = params\n",
    "    xg_reg = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                              colsample_bytree=0.3, \n",
    "                              learning_rate=learning_rate, \n",
    "                              max_depth=int(max_depth), \n",
    "                              n_estimators=int(n_estimators))\n",
    "    xg_reg.fit(X_train_m1, y_train_m1)\n",
    "    predictions = xg_reg.predict(X_test_m1)\n",
    "    return mean_squared_error(y_test_m1, predictions)\n",
    "\n",
    "varbound = np.array([[0.01, 0.2], [3, 10], [50, 200]])\n",
    "\n",
    "model = ga(function=ga_objective, \n",
    "           dimension=3, \n",
    "           variable_type='real', \n",
    "           variable_boundaries=varbound,\n",
    "           algorithm_parameters={\n",
    "               'max_num_iteration': 200,  # Fewer iterations\n",
    "               'population_size': 50,    # Smaller population\n",
    "               'mutation_probability': 0.1,\n",
    "               'elit_ratio': 0.01,\n",
    "               'crossover_probability': 0.5,\n",
    "               'parents_portion': 0.3,\n",
    "               'crossover_type':'uniform',\n",
    "               'max_iteration_without_improv': 50})\n",
    "\n",
    "model.run()\n",
    "best_params_ga = model.output_dict['variable']\n",
    "print(\"Best Parameters from GA:\", best_params_ga)\n",
    "print(\"Best MSE from GA:\", model.output_dict['function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model with the best hyperparameters from GA\n",
    "# xg_reg_ga = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "#                              colsample_bytree=0.3,\n",
    "#                              learning_rate=best_params_ga[0],\n",
    "#                              max_depth=int(best_params_ga[1]),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from HHO: [ 0.15904768  3.         50.        ]\n"
     ]
    }
   ],
   "source": [
    "from niapy.task import Task\n",
    "from niapy.algorithms.basic import HarrisHawksOptimization\n",
    "from niapy.problems import Problem\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class XGBBenchmark(Problem):\n",
    "    def __init__(self):\n",
    "        # Call the parent class constructor with the dimension, lower, and upper bounds\n",
    "        super().__init__(dimension=3, lower=[0.01, 3, 50], upper=[0.2, 10, 200])\n",
    "        self.X_train = X_train_m1\n",
    "        self.y_train = y_train_m1\n",
    "        self.X_test = X_test_m1\n",
    "        self.y_test = y_test_m1\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        learning_rate, max_depth, n_estimators = x\n",
    "        xg_reg = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                                  colsample_bytree=0.3, \n",
    "                                  learning_rate=learning_rate, \n",
    "                                  max_depth=int(max_depth), \n",
    "                                  n_estimators=int(n_estimators))\n",
    "        xg_reg.fit(self.X_train, self.y_train)\n",
    "        predictions = xg_reg.predict(self.X_test)\n",
    "        return mean_squared_error(self.y_test, predictions)\n",
    "\n",
    "# Define the task\n",
    "task = Task(problem=XGBBenchmark(), max_iters=100)\n",
    "\n",
    "# Run the HHO algorithm\n",
    "algorithm = HarrisHawksOptimization(population_size=30)\n",
    "best_params_hho = algorithm.run(task=task)\n",
    "print(\"Best Parameters from HHO:\", best_params_hho[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSO Optimized MSE (Train/Test): 0.6736009306703107 0.611900692378837\n",
      "GA Optimized MSE (Train/Test): 0.6495081085067926 0.6167259495562297\n",
      "HHO Optimized MSE (Train/Test): 0.675810346109813 0.6139867744446434\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(params, X_train, y_train, X_test, y_test):\n",
    "    learning_rate, max_depth, n_estimators = params\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                             colsample_bytree=0.3, \n",
    "                             learning_rate=learning_rate, \n",
    "                             max_depth=int(max_depth), \n",
    "                             n_estimators=int(n_estimators))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    return mse_train, mse_test, y_train_pred, y_test_pred\n",
    "\n",
    "# Evaluate PSO optimized model\n",
    "mse_train_pso, mse_test_pso, y_train_pred_pso, y_test_pred_pso = train_and_evaluate(best_params, X_train_m1, y_train_m1, X_test_m1, y_test_m1)\n",
    "\n",
    "# Evaluate GA optimized model\n",
    "mse_train_ga, mse_test_ga, y_train_pred_ga, y_test_pred_ga = train_and_evaluate(best_params_ga, X_train_m1, y_train_m1, X_test_m1, y_test_m1)\n",
    "\n",
    "# Evaluate HHO optimized model\n",
    "mse_train_hho, mse_test_hho, y_train_pred_hho, y_test_pred_hho = train_and_evaluate(best_params_hho[0], X_train_m1, y_train_m1, X_test_m1, y_test_m1)\n",
    "\n",
    "# Compare the results\n",
    "print(\"PSO Optimized MSE (Train/Test):\", mse_train_pso, mse_test_pso)\n",
    "print(\"GA Optimized MSE (Train/Test):\", mse_train_ga, mse_test_ga)\n",
    "print(\"HHO Optimized MSE (Train/Test):\", mse_train_hho, mse_test_hho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Baseline model predictions\n",
    "baseline_results_train = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_baseline})\n",
    "baseline_results_test = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_baseline})\n",
    "baseline_results_train.to_csv('outputs/XGB_baseline_train_results.csv', index=False)\n",
    "baseline_results_test.to_csv('outputs/XGB_baseline_test_results.csv', index=False)\n",
    "\n",
    "# Save Optimized model predictions (PSO, GA, HHO)\n",
    "optimized_results_train_pso = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_pso})\n",
    "optimized_results_test_pso = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_pso})\n",
    "optimized_results_train_pso.to_excel('outputs/XGB_optimized_train_results_pso.xlsx', index=False)\n",
    "optimized_results_test_pso.to_excel('outputs/XGB_optimized_test_results_pso.xlsx', index=False)\n",
    "\n",
    "optimized_results_train_ga = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_ga})\n",
    "optimized_results_test_ga = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_ga})\n",
    "optimized_results_train_ga.to_excel('outputs/XGB_optimized_train_results_ga.xlsx', index=False)\n",
    "optimized_results_test_ga.to_excel('outputs/XGB_optimized_test_results_ga.xlsx', index=False)\n",
    "\n",
    "optimized_results_train_hho = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_hho})\n",
    "optimized_results_test_hho = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_hho})\n",
    "optimized_results_train_hho.to_excel('outputs/XGB_optimized_train_results_hho.xlsx', index=False)\n",
    "optimized_results_test_hho.to_excel('outputs/XGB_optimized_test_results_hho.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wakili/anaconda3/envs/mlenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-09-01 20:28:43,438] A new study created in memory with name: no-name-bdc399b1-04dc-4889-95ea-5f178bccb982\n",
      "[I 2024-09-01 20:28:43,986] Trial 0 finished with value: 0.6322646871367251 and parameters: {'learning_rate': 0.06196694861198709, 'max_depth': 5, 'n_estimators': 105}. Best is trial 0 with value: 0.6322646871367251.\n",
      "[I 2024-09-01 20:28:47,359] Trial 1 finished with value: 0.782335187870145 and parameters: {'learning_rate': 0.19675034038751726, 'max_depth': 10, 'n_estimators': 176}. Best is trial 0 with value: 0.6322646871367251.\n",
      "[I 2024-09-01 20:28:47,971] Trial 2 finished with value: 0.6679186281738727 and parameters: {'learning_rate': 0.17147481207296877, 'max_depth': 5, 'n_estimators': 106}. Best is trial 0 with value: 0.6322646871367251.\n",
      "[I 2024-09-01 20:28:49,368] Trial 3 finished with value: 0.643804997400329 and parameters: {'learning_rate': 0.11230684676655113, 'max_depth': 4, 'n_estimators': 191}. Best is trial 0 with value: 0.6322646871367251.\n",
      "[I 2024-09-01 20:28:52,867] Trial 4 finished with value: 0.6710179312062216 and parameters: {'learning_rate': 0.05132785540892443, 'max_depth': 10, 'n_estimators': 72}. Best is trial 0 with value: 0.6322646871367251.\n",
      "[I 2024-09-01 20:28:53,570] Trial 5 finished with value: 0.6448736953300286 and parameters: {'learning_rate': 0.14440583769434534, 'max_depth': 5, 'n_estimators': 71}. Best is trial 0 with value: 0.6322646871367251.\n",
      "[I 2024-09-01 20:28:56,227] Trial 6 finished with value: 0.7545721752435417 and parameters: {'learning_rate': 0.18178887436319766, 'max_depth': 8, 'n_estimators': 147}. Best is trial 0 with value: 0.6322646871367251.\n",
      "[I 2024-09-01 20:28:57,047] Trial 7 finished with value: 0.6569867134049804 and parameters: {'learning_rate': 0.12808110120640154, 'max_depth': 6, 'n_estimators': 74}. Best is trial 0 with value: 0.6322646871367251.\n",
      "[I 2024-09-01 20:28:58,757] Trial 8 finished with value: 0.6988023306818657 and parameters: {'learning_rate': 0.16870014083335755, 'max_depth': 6, 'n_estimators': 123}. Best is trial 0 with value: 0.6322646871367251.\n",
      "[I 2024-09-01 20:28:59,407] Trial 9 finished with value: 0.6764223934733314 and parameters: {'learning_rate': 0.1926350842130275, 'max_depth': 5, 'n_estimators': 108}. Best is trial 0 with value: 0.6322646871367251.\n",
      "[I 2024-09-01 20:28:59,932] Trial 10 finished with value: 0.6263934091534521 and parameters: {'learning_rate': 0.06048011276504301, 'max_depth': 3, 'n_estimators': 145}. Best is trial 10 with value: 0.6263934091534521.\n",
      "[I 2024-09-01 20:29:01,992] Trial 11 finished with value: 0.6279234265586319 and parameters: {'learning_rate': 0.05307314019566521, 'max_depth': 3, 'n_estimators': 153}. Best is trial 10 with value: 0.6263934091534521.\n",
      "[I 2024-09-01 20:29:02,764] Trial 12 finished with value: 0.6345477019542728 and parameters: {'learning_rate': 0.019357168002243838, 'max_depth': 3, 'n_estimators': 158}. Best is trial 10 with value: 0.6263934091534521.\n",
      "[I 2024-09-01 20:29:03,533] Trial 13 finished with value: 0.623630506009646 and parameters: {'learning_rate': 0.07718492679391839, 'max_depth': 3, 'n_estimators': 147}. Best is trial 13 with value: 0.623630506009646.\n",
      "[I 2024-09-01 20:29:04,146] Trial 14 finished with value: 0.6268928840754491 and parameters: {'learning_rate': 0.07931308963025065, 'max_depth': 3, 'n_estimators': 137}. Best is trial 13 with value: 0.623630506009646.\n",
      "[I 2024-09-01 20:29:10,272] Trial 15 finished with value: 0.7237443393191991 and parameters: {'learning_rate': 0.08763109995610749, 'max_depth': 8, 'n_estimators': 165}. Best is trial 13 with value: 0.623630506009646.\n",
      "[I 2024-09-01 20:29:13,732] Trial 16 finished with value: 0.6349428483860893 and parameters: {'learning_rate': 0.02113208264559341, 'max_depth': 4, 'n_estimators': 128}. Best is trial 13 with value: 0.623630506009646.\n",
      "[I 2024-09-01 20:29:22,957] Trial 17 finished with value: 0.6395667126824254 and parameters: {'learning_rate': 0.09797516605460471, 'max_depth': 4, 'n_estimators': 186}. Best is trial 13 with value: 0.623630506009646.\n",
      "[I 2024-09-01 20:29:36,629] Trial 18 finished with value: 0.6833958733710266 and parameters: {'learning_rate': 0.04159811291160319, 'max_depth': 8, 'n_estimators': 173}. Best is trial 13 with value: 0.623630506009646.\n",
      "[I 2024-09-01 20:29:42,478] Trial 19 finished with value: 0.6598661115491631 and parameters: {'learning_rate': 0.07512171723914146, 'max_depth': 7, 'n_estimators': 89}. Best is trial 13 with value: 0.623630506009646.\n",
      "[I 2024-09-01 20:29:43,727] Trial 20 finished with value: 0.6241082618537465 and parameters: {'learning_rate': 0.11630031810782349, 'max_depth': 3, 'n_estimators': 138}. Best is trial 13 with value: 0.623630506009646.\n",
      "[I 2024-09-01 20:29:45,306] Trial 21 finished with value: 0.6236278047632318 and parameters: {'learning_rate': 0.11670348717351878, 'max_depth': 3, 'n_estimators': 140}. Best is trial 21 with value: 0.6236278047632318.\n",
      "[I 2024-09-01 20:29:46,073] Trial 22 finished with value: 0.634980048958555 and parameters: {'learning_rate': 0.117295594749506, 'max_depth': 4, 'n_estimators': 127}. Best is trial 21 with value: 0.6236278047632318.\n",
      "[I 2024-09-01 20:29:48,865] Trial 23 finished with value: 0.6248433862563607 and parameters: {'learning_rate': 0.14417165379777003, 'max_depth': 3, 'n_estimators': 136}. Best is trial 21 with value: 0.6236278047632318.\n",
      "[I 2024-09-01 20:29:51,466] Trial 24 finished with value: 0.6368392241587768 and parameters: {'learning_rate': 0.13770444282021707, 'max_depth': 4, 'n_estimators': 112}. Best is trial 21 with value: 0.6236278047632318.\n",
      "[I 2024-09-01 20:29:52,290] Trial 25 finished with value: 0.6254034183682661 and parameters: {'learning_rate': 0.10034183858502553, 'max_depth': 3, 'n_estimators': 164}. Best is trial 21 with value: 0.6236278047632318.\n",
      "[I 2024-09-01 20:29:53,028] Trial 26 finished with value: 0.6231479419219642 and parameters: {'learning_rate': 0.121519327178468, 'max_depth': 4, 'n_estimators': 57}. Best is trial 26 with value: 0.6231479419219642.\n",
      "[I 2024-09-01 20:29:53,372] Trial 27 finished with value: 0.6206264112491303 and parameters: {'learning_rate': 0.15366197158231837, 'max_depth': 4, 'n_estimators': 53}. Best is trial 27 with value: 0.6206264112491303.\n",
      "[I 2024-09-01 20:29:54,162] Trial 28 finished with value: 0.6184491126910729 and parameters: {'learning_rate': 0.1594694209220776, 'max_depth': 4, 'n_estimators': 51}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:29:54,784] Trial 29 finished with value: 0.6534909938648014 and parameters: {'learning_rate': 0.156621302193676, 'max_depth': 6, 'n_estimators': 55}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:29:56,555] Trial 30 finished with value: 0.6368770760643334 and parameters: {'learning_rate': 0.15528972649054282, 'max_depth': 5, 'n_estimators': 50}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:29:57,037] Trial 31 finished with value: 0.6251325490817262 and parameters: {'learning_rate': 0.13132857366222303, 'max_depth': 4, 'n_estimators': 60}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:29:57,597] Trial 32 finished with value: 0.653675950146178 and parameters: {'learning_rate': 0.15857547805011218, 'max_depth': 5, 'n_estimators': 90}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:29:57,996] Trial 33 finished with value: 0.6230449539708759 and parameters: {'learning_rate': 0.12252188300960523, 'max_depth': 4, 'n_estimators': 63}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:29:58,378] Trial 34 finished with value: 0.6248680645555634 and parameters: {'learning_rate': 0.17055789507965294, 'max_depth': 4, 'n_estimators': 65}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:29:58,903] Trial 35 finished with value: 0.6426084503877187 and parameters: {'learning_rate': 0.12949118063232623, 'max_depth': 5, 'n_estimators': 84}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:29:59,317] Trial 36 finished with value: 0.6371025397623249 and parameters: {'learning_rate': 0.18525302800267748, 'max_depth': 4, 'n_estimators': 80}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:29:59,972] Trial 37 finished with value: 0.6832703872793324 and parameters: {'learning_rate': 0.1482440292008334, 'max_depth': 7, 'n_estimators': 62}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:00,699] Trial 38 finished with value: 0.6358553889362858 and parameters: {'learning_rate': 0.10729056439377413, 'max_depth': 5, 'n_estimators': 50}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:02,765] Trial 39 finished with value: 0.7558605023218204 and parameters: {'learning_rate': 0.16625369517798427, 'max_depth': 10, 'n_estimators': 97}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:05,582] Trial 40 finished with value: 0.6624384785605387 and parameters: {'learning_rate': 0.13762630565520032, 'max_depth': 6, 'n_estimators': 71}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:06,274] Trial 41 finished with value: 0.6254149472467171 and parameters: {'learning_rate': 0.12516844677144104, 'max_depth': 4, 'n_estimators': 59}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:07,010] Trial 42 finished with value: 0.6388353848609086 and parameters: {'learning_rate': 0.11877273273228206, 'max_depth': 5, 'n_estimators': 66}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:07,952] Trial 43 finished with value: 0.6283233907559598 and parameters: {'learning_rate': 0.18000039605812, 'max_depth': 4, 'n_estimators': 75}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:08,762] Trial 44 finished with value: 0.6233584114657647 and parameters: {'learning_rate': 0.1075664302328975, 'max_depth': 3, 'n_estimators': 117}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:09,356] Trial 45 finished with value: 0.6752857758760916 and parameters: {'learning_rate': 0.09238551014207462, 'max_depth': 9, 'n_estimators': 55}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:10,916] Trial 46 finished with value: 0.6264783375664145 and parameters: {'learning_rate': 0.10963059480131757, 'max_depth': 4, 'n_estimators': 98}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:12,985] Trial 47 finished with value: 0.6610837807252254 and parameters: {'learning_rate': 0.14900079909225455, 'max_depth': 5, 'n_estimators': 116}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:14,330] Trial 48 finished with value: 0.6238499366793167 and parameters: {'learning_rate': 0.13859423689880201, 'max_depth': 3, 'n_estimators': 69}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:15,153] Trial 49 finished with value: 0.6268397431701273 and parameters: {'learning_rate': 0.12298719609992408, 'max_depth': 4, 'n_estimators': 79}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:17,996] Trial 50 finished with value: 0.6496647853815404 and parameters: {'learning_rate': 0.1944836030740768, 'max_depth': 3, 'n_estimators': 200}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:24,943] Trial 51 finished with value: 0.6257100060568889 and parameters: {'learning_rate': 0.09982134574879085, 'max_depth': 3, 'n_estimators': 56}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:27,843] Trial 52 finished with value: 0.6238704382562156 and parameters: {'learning_rate': 0.08770752844120022, 'max_depth': 3, 'n_estimators': 66}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:30,481] Trial 53 finished with value: 0.6293299754174604 and parameters: {'learning_rate': 0.11218763607925794, 'max_depth': 4, 'n_estimators': 50}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:34,224] Trial 54 finished with value: 0.6328763042651219 and parameters: {'learning_rate': 0.1615756192202164, 'max_depth': 3, 'n_estimators': 150}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:35,745] Trial 55 finished with value: 0.6241979742114728 and parameters: {'learning_rate': 0.10530966017911952, 'max_depth': 3, 'n_estimators': 134}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:45,302] Trial 56 finished with value: 0.6470315208898999 and parameters: {'learning_rate': 0.1765328202081064, 'max_depth': 4, 'n_estimators': 118}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:47,051] Trial 57 finished with value: 0.6260060904557162 and parameters: {'learning_rate': 0.06931319478600953, 'max_depth': 3, 'n_estimators': 144}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:48,787] Trial 58 finished with value: 0.6310237755114556 and parameters: {'learning_rate': 0.13088842123131864, 'max_depth': 4, 'n_estimators': 101}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:53,431] Trial 59 finished with value: 0.6677948633362536 and parameters: {'learning_rate': 0.11965820689780626, 'max_depth': 5, 'n_estimators': 155}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:54,093] Trial 60 finished with value: 0.6230303878522977 and parameters: {'learning_rate': 0.0936872790610628, 'max_depth': 3, 'n_estimators': 75}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:54,850] Trial 61 finished with value: 0.6243146690131182 and parameters: {'learning_rate': 0.09864625385438855, 'max_depth': 3, 'n_estimators': 61}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:57,415] Trial 62 finished with value: 0.6228868266753432 and parameters: {'learning_rate': 0.09206742389041314, 'max_depth': 3, 'n_estimators': 74}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:58,271] Trial 63 finished with value: 0.6212259505938961 and parameters: {'learning_rate': 0.08442871393481556, 'max_depth': 4, 'n_estimators': 76}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:30:59,210] Trial 64 finished with value: 0.6233717449768593 and parameters: {'learning_rate': 0.08308926189136205, 'max_depth': 4, 'n_estimators': 77}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:00,290] Trial 65 finished with value: 0.6274088497046115 and parameters: {'learning_rate': 0.06973800613583572, 'max_depth': 4, 'n_estimators': 72}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:01,471] Trial 66 finished with value: 0.6380816522699966 and parameters: {'learning_rate': 0.09205845087377075, 'max_depth': 5, 'n_estimators': 91}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:02,423] Trial 67 finished with value: 0.6273921312422998 and parameters: {'learning_rate': 0.05536739413777562, 'max_depth': 4, 'n_estimators': 84}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:03,809] Trial 68 finished with value: 0.6403557994784657 and parameters: {'learning_rate': 0.03767985050145867, 'max_depth': 6, 'n_estimators': 55}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:06,181] Trial 69 finished with value: 0.6280132827244923 and parameters: {'learning_rate': 0.07107300090276153, 'max_depth': 4, 'n_estimators': 68}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:08,760] Trial 70 finished with value: 0.6309021104239629 and parameters: {'learning_rate': 0.08122369880448087, 'max_depth': 5, 'n_estimators': 84}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:09,847] Trial 71 finished with value: 0.6251889353848918 and parameters: {'learning_rate': 0.09410725894925326, 'max_depth': 3, 'n_estimators': 63}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:10,497] Trial 72 finished with value: 0.6264231915194702 and parameters: {'learning_rate': 0.08743314439355866, 'max_depth': 3, 'n_estimators': 58}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:10,869] Trial 73 finished with value: 0.6312555919925916 and parameters: {'learning_rate': 0.06368438490835639, 'max_depth': 3, 'n_estimators': 53}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:11,707] Trial 74 finished with value: 0.6238282365605123 and parameters: {'learning_rate': 0.10346520333556702, 'max_depth': 4, 'n_estimators': 73}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:12,265] Trial 75 finished with value: 0.6271455846790719 and parameters: {'learning_rate': 0.11259324019617344, 'max_depth': 4, 'n_estimators': 63}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:13,271] Trial 76 finished with value: 0.6233332863550232 and parameters: {'learning_rate': 0.15177429405383205, 'max_depth': 3, 'n_estimators': 108}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:13,781] Trial 77 finished with value: 0.6220956417211051 and parameters: {'learning_rate': 0.14311142543879007, 'max_depth': 3, 'n_estimators': 82}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:14,643] Trial 78 finished with value: 0.6958618145701766 and parameters: {'learning_rate': 0.1440298217349562, 'max_depth': 7, 'n_estimators': 81}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:15,083] Trial 79 finished with value: 0.6300168559308761 and parameters: {'learning_rate': 0.13774284428909606, 'max_depth': 4, 'n_estimators': 87}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:15,459] Trial 80 finished with value: 0.6228989813919582 and parameters: {'learning_rate': 0.15374827927397727, 'max_depth': 3, 'n_estimators': 76}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:15,787] Trial 81 finished with value: 0.6217574916906361 and parameters: {'learning_rate': 0.16461108437117372, 'max_depth': 3, 'n_estimators': 75}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:16,515] Trial 82 finished with value: 0.6253059310414775 and parameters: {'learning_rate': 0.16410572718761415, 'max_depth': 3, 'n_estimators': 94}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:18,447] Trial 83 finished with value: 0.6190259709503784 and parameters: {'learning_rate': 0.17469962434770903, 'max_depth': 3, 'n_estimators': 70}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:20,099] Trial 84 finished with value: 0.6232628826735415 and parameters: {'learning_rate': 0.1889934379184572, 'max_depth': 3, 'n_estimators': 77}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:28,213] Trial 85 finished with value: 0.6239933170582321 and parameters: {'learning_rate': 0.19995046489689947, 'max_depth': 3, 'n_estimators': 70}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:31,728] Trial 86 finished with value: 0.621337892705673 and parameters: {'learning_rate': 0.17280622049562983, 'max_depth': 3, 'n_estimators': 75}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:35,350] Trial 87 finished with value: 0.6246551412099991 and parameters: {'learning_rate': 0.1718218852077682, 'max_depth': 3, 'n_estimators': 86}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:39,587] Trial 88 finished with value: 0.6247713791659749 and parameters: {'learning_rate': 0.17372043438760573, 'max_depth': 3, 'n_estimators': 81}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:44,303] Trial 89 finished with value: 0.6254005723466816 and parameters: {'learning_rate': 0.181066045308245, 'max_depth': 3, 'n_estimators': 67}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:49,069] Trial 90 finished with value: 0.734477775564722 and parameters: {'learning_rate': 0.15483700391196567, 'max_depth': 9, 'n_estimators': 75}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:49,308] Trial 91 finished with value: 0.6224582955685806 and parameters: {'learning_rate': 0.16715366390798242, 'max_depth': 3, 'n_estimators': 73}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:50,860] Trial 92 finished with value: 0.6222214548029359 and parameters: {'learning_rate': 0.1667910154215253, 'max_depth': 3, 'n_estimators': 72}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:51,542] Trial 93 finished with value: 0.6209730093086866 and parameters: {'learning_rate': 0.16115595376151343, 'max_depth': 3, 'n_estimators': 72}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:53,757] Trial 94 finished with value: 0.6214202102401665 and parameters: {'learning_rate': 0.16671890098101105, 'max_depth': 3, 'n_estimators': 69}. Best is trial 28 with value: 0.6184491126910729.\n",
      "[I 2024-09-01 20:31:54,453] Trial 95 finished with value: 0.6163870204704163 and parameters: {'learning_rate': 0.15967588152776493, 'max_depth': 3, 'n_estimators': 59}. Best is trial 95 with value: 0.6163870204704163.\n",
      "[I 2024-09-01 20:31:54,953] Trial 96 finished with value: 0.6192982400789454 and parameters: {'learning_rate': 0.16066820672386667, 'max_depth': 3, 'n_estimators': 60}. Best is trial 95 with value: 0.6163870204704163.\n",
      "[I 2024-09-01 20:31:59,547] Trial 97 finished with value: 0.6157543427866279 and parameters: {'learning_rate': 0.16025913224615343, 'max_depth': 3, 'n_estimators': 53}. Best is trial 97 with value: 0.6157543427866279.\n",
      "[I 2024-09-01 20:32:00,523] Trial 98 finished with value: 0.6266495895983736 and parameters: {'learning_rate': 0.1880543202786671, 'max_depth': 4, 'n_estimators': 59}. Best is trial 97 with value: 0.6157543427866279.\n",
      "[I 2024-09-01 20:32:00,782] Trial 99 finished with value: 0.613574746681466 and parameters: {'learning_rate': 0.1599579561639347, 'max_depth': 3, 'n_estimators': 53}. Best is trial 99 with value: 0.613574746681466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from BBO (Optuna): {'learning_rate': 0.1599579561639347, 'max_depth': 3, 'n_estimators': 53}\n",
      "Best MSE from BBO (Optuna): 0.613574746681466\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest values for the parameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.2)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    \n",
    "    # Create and train the model\n",
    "    xg_reg = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                              colsample_bytree=0.3, \n",
    "                              learning_rate=learning_rate, \n",
    "                              max_depth=max_depth, \n",
    "                              n_estimators=n_estimators)\n",
    "    \n",
    "    xg_reg.fit(X_train_m1, y_train_m1)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    predictions = xg_reg.predict(X_test_m1)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_test_m1, predictions)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Best parameters and the corresponding MSE\n",
    "best_params_bbo = study.best_params\n",
    "best_mse_bbo = study.best_value\n",
    "\n",
    "print(\"Best Parameters from BBO (Optuna):\", best_params_bbo)\n",
    "print(\"Best MSE from BBO (Optuna):\", best_mse_bbo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSO Optimized MSE (Train/Test): 0.6736009306703107 0.611900692378837\n",
      "GA Optimized MSE (Train/Test): 0.6495081085067926 0.6167259495562297\n",
      "HHO Optimized MSE (Train/Test): 0.675810346109813 0.6139867744446434\n",
      "BBO (Optuna) Optimized MSE (Train/Test): 0.6723477517464906 0.613574746681466\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the BBO optimized model\n",
    "mse_train_bbo, mse_test_bbo, y_train_pred_bbo, y_test_pred_bbo = train_and_evaluate(\n",
    "    [best_params_bbo['learning_rate'], best_params_bbo['max_depth'], best_params_bbo['n_estimators']], \n",
    "    X_train_m1, y_train_m1, X_test_m1, y_test_m1\n",
    ")\n",
    "\n",
    "# Compare the results with other models\n",
    "print(\"PSO Optimized MSE (Train/Test):\", mse_train_pso, mse_test_pso)\n",
    "print(\"GA Optimized MSE (Train/Test):\", mse_train_ga, mse_test_ga)\n",
    "print(\"HHO Optimized MSE (Train/Test):\", mse_train_hho, mse_test_hho)\n",
    "print(\"BBO (Optuna) Optimized MSE (Train/Test):\", mse_train_bbo, mse_test_bbo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save BBO (Optuna) optimized model predictions\n",
    "optimized_results_train_bbo = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_bbo})\n",
    "optimized_results_test_bbo = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_bbo})\n",
    "optimized_results_train_bbo.to_excel('outputs/optimized_train_results_bbo.xlsx', index=False)\n",
    "optimized_results_test_bbo.to_excel('outputs/optimized_test_results_bbo.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
