{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     effa   effc   effd      mu     T20       win    COP       WPR\n",
      "0   0.000  0.000  0.000  0.0000   0.000  0.002411  0.000  0.000000\n",
      "1   0.000  0.000  0.000  0.0000   0.000  0.002006  0.000  0.000000\n",
      "2   0.000  0.000  0.000  0.0000   0.000  0.002001  0.000  0.000000\n",
      "3   0.000  0.000  0.000  0.0000   0.000  0.002102  0.000  0.000000\n",
      "4   0.000  0.000  0.000  0.0000   0.000  0.002078  0.000  0.000000\n",
      "5   0.000  0.000  0.000  0.0000   0.000  0.002011  0.000  0.000000\n",
      "6   0.000  0.000  0.000  0.0000   0.000  0.001874  0.000  0.000000\n",
      "7   0.000  0.000  0.000  0.0000   0.000  0.001938  0.000  0.000000\n",
      "8   0.689  0.641  0.497  0.1590  -6.700  0.002231  0.698  0.100440\n",
      "9   0.666  0.641  0.478  0.2288 -13.250  0.002167  0.771  1.051920\n",
      "10  0.653  0.641  0.469  0.2544 -16.520  0.002276  0.777  1.505088\n",
      "11  0.648  0.641  0.465  0.2702 -16.210  0.002703  0.777  1.938276\n",
      "12  0.645  0.641  0.462  0.2800 -16.050  0.003149  0.776  2.405268\n",
      "13  0.649  0.641  0.465  0.2815 -13.430  0.003044  0.777  2.019600\n",
      "14  0.660  0.641  0.473  0.2762  -7.745  0.002650  0.776  0.753840\n",
      "15  0.681  0.641  0.490  0.2407   1.062  0.002726  0.738  0.000000\n",
      "16  0.000  0.000  0.000  0.0000   0.000  0.002438  0.000  0.000000\n",
      "17  0.000  0.000  0.000  0.0000   0.000  0.002110  0.000  0.000000\n",
      "18  0.000  0.000  0.000  0.0000   0.000  0.002158  0.000  0.000000\n",
      "19  0.000  0.000  0.000  0.0000   0.000  0.002018  0.000  0.000000\n",
      "X_train_m1 shape: (7008, 7)\n",
      "y_train_m1 shape: (7008,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "data_m1 = pd.read_excel('data/M2.xlsx')\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X_m1 = data_m1.drop('WPR', axis=1)\n",
    "y_m1 = data_m1['WPR']\n",
    "\n",
    "# Show the first 20 rows of the data\n",
    "print(data_m1.head(20))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_m1, X_test_m1, y_train_m1, y_test_m1 = train_test_split(X_m1, y_m1, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train_m1 shape:\", X_train_m1.shape)\n",
    "print(\"y_train_m1 shape:\", y_train_m1.shape)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_m1 = scaler.fit_transform(X_train_m1)\n",
    "X_test_m1 = scaler.transform(X_test_m1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values in X_train_m1\n",
    "imputer = SimpleImputer(strategy='mean')  # You can also use 'median' or 'constant'\n",
    "X_train_m1 = imputer.fit_transform(X_train_m1)\n",
    "X_test_m1 = imputer.transform(X_test_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF Model - Mean Squared Error: 0.4047362462462565\n",
      "Baseline RF Model - R^2 Score: 0.5755335331757621\n"
     ]
    }
   ],
   "source": [
    "# Train the baseline Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Make predictions on both training and test data\n",
    "y_train_pred = rf_model.predict(X_train_m1)\n",
    "y_test_pred = rf_model.predict(X_test_m1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "mse = mean_squared_error(y_test_m1, y_test_pred)\n",
    "r2 = r2_score(y_test_m1, y_test_pred)\n",
    "\n",
    "print(f'Baseline RF Model - Mean Squared Error: {mse}')\n",
    "print(f'Baseline RF Model - R^2 Score: {r2}')\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "baseline_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred})\n",
    "baseline_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred})\n",
    "\n",
    "baseline_train_results.to_excel('outputs/M2baseline_rf_train_predictions.xlsx', index=False)\n",
    "baseline_test_results.to_excel('outputs/M2baseline_rf_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: maximum iterations reached --> 10\n",
      "Optimized Parameters (PSO): [35.01825789  7.70033045]\n",
      "Optimized Mean Squared Error (PSO): 0.35410820046814506\n"
     ]
    }
   ],
   "source": [
    "from pyswarm import pso\n",
    "\n",
    "# Objective function to minimize\n",
    "def rf_pso(params):\n",
    "    n_estimators = int(params[0])\n",
    "    max_depth = int(params[1])\n",
    "    \n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_m1, y_train_m1)\n",
    "    y_pred = rf_model.predict(X_test_m1)\n",
    "    \n",
    "    return mean_squared_error(y_test_m1, y_pred)\n",
    "\n",
    "# PSO parameter bounds\n",
    "lb = [10, 1]  # Lower bounds for n_estimators and max_depth\n",
    "ub = [100, 20]  # Upper bounds for n_estimators and max_depth\n",
    "\n",
    "# Run PSO\n",
    "optimal_params, optimal_mse = pso(rf_pso, lb, ub, swarmsize=10, maxiter=10)\n",
    "\n",
    "print(f'Optimized Parameters (PSO): {optimal_params}')\n",
    "print(f'Optimized Mean Squared Error (PSO): {optimal_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized RF Model (PSO) - Mean Squared Error: 0.35410820046814506\n",
      "Optimized RF Model (PSO) - R^2 Score: 0.6286296121974948\n"
     ]
    }
   ],
   "source": [
    "# Retrain the Random Forest with optimized parameters from PSO\n",
    "n_estimators_optimized = int(optimal_params[0])\n",
    "max_depth_optimized = int(optimal_params[1])\n",
    "\n",
    "rf_model_optimized = RandomForestRegressor(\n",
    "    n_estimators=n_estimators_optimized, \n",
    "    max_depth=max_depth_optimized, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model_optimized.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Make predictions on both training and test data\n",
    "y_train_pred_optimized = rf_model_optimized.predict(X_train_m1)\n",
    "y_test_pred_optimized = rf_model_optimized.predict(X_test_m1)\n",
    "\n",
    "# Evaluate the optimized model on the test data\n",
    "mse_optimized = mean_squared_error(y_test_m1, y_test_pred_optimized)\n",
    "r2_optimized = r2_score(y_test_m1, y_test_pred_optimized)\n",
    "\n",
    "print(f'Optimized RF Model (PSO) - Mean Squared Error: {mse_optimized}')\n",
    "print(f'Optimized RF Model (PSO) - R^2 Score: {r2_optimized}')\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_optimized})\n",
    "optimized_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_optimized})\n",
    "\n",
    "optimized_train_results.to_excel('outputs/M2optimized_rf_pso_train_predictions.xlsx', index=False)\n",
    "optimized_test_results.to_excel('outputs/M2optimized_rf_pso_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF Model\n",
      "Mean Squared Error: 0.4047362462462565\n",
      "R^2 Score: 0.5755335331757621\n",
      "\n",
      "Optimized RF Model (PSO)\n",
      "Mean Squared Error: 0.35410820046814506\n",
      "R^2 Score: 0.6286296121974948\n"
     ]
    }
   ],
   "source": [
    "# Compare results of baseline and Optimized RF Model (PSO\n",
    "print(\"Baseline RF Model\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "print(\"\\nOptimized RF Model (PSO)\")\n",
    "print(f\"Mean Squared Error: {mse_optimized}\")\n",
    "print(f\"R^2 Score: {r2_optimized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t10    \n",
      "1  \t10    \n",
      "2  \t8     \n",
      "3  \t10    \n",
      "4  \t9     \n",
      "5  \t8     \n",
      "6  \t9     \n",
      "7  \t7     \n",
      "8  \t5     \n",
      "9  \t6     \n",
      "10 \t8     \n",
      "11 \t6     \n",
      "12 \t6     \n",
      "13 \t6     \n",
      "14 \t8     \n",
      "15 \t10    \n",
      "16 \t9     \n",
      "17 \t5     \n",
      "18 \t5     \n",
      "19 \t10    \n",
      "20 \t8     \n",
      "21 \t8     \n",
      "22 \t6     \n",
      "23 \t8     \n",
      "24 \t8     \n",
      "25 \t10    \n",
      "26 \t9     \n",
      "27 \t7     \n",
      "28 \t6     \n",
      "29 \t8     \n",
      "30 \t8     \n",
      "31 \t10    \n",
      "32 \t6     \n",
      "33 \t7     \n",
      "34 \t10    \n",
      "35 \t6     \n",
      "36 \t10    \n",
      "37 \t8     \n",
      "38 \t9     \n",
      "39 \t7     \n",
      "40 \t8     \n",
      "Optimized Parameters (GA): [0, 8]\n",
      "GA optimized parameters: [0.06800087993174751, 8.640490283125306, 121.49124043910572]\n"
     ]
    }
   ],
   "source": [
    "#Optimize Random Forest with Genetic Algorithm (GA)\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rf_ga(individual):\n",
    "    n_estimators = int(individual[1])\n",
    "    max_depth = int(individual[1])\n",
    "    \n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_m1, y_train_m1)\n",
    "    y_pred = rf_model.predict(X_test_m1)\n",
    "    \n",
    "    return mean_squared_error(y_test_m1, y_pred),\n",
    "\n",
    "# Create types\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "# Register functions\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.uniform, 0.01, 0.3)\n",
    "toolbox.register(\"attr_int\", random.randint, 3, 10)\n",
    "toolbox.register(\"attr_int2\", random.randint, 50, 300)\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_float, toolbox.attr_int, toolbox.attr_int2), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", rf_ga)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "\n",
    "# Mutation function that constrains the learning_rate to [0.01, 0.3]\n",
    "def constrained_mutation(individual, indpb):\n",
    "    if random.random() < indpb:\n",
    "        individual[0] = min(max(individual[0] + random.gauss(0, 0.05), 0.01), 0.3)\n",
    "    if random.random() < indpb:\n",
    "        individual[1] = random.randint(3, 10)\n",
    "    if random.random() < indpb:\n",
    "        individual[2] = random.randint(50, 300)\n",
    "    return individual,\n",
    "\n",
    "toolbox.register(\"mutate\", constrained_mutation, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# Define population and evolution\n",
    "population = toolbox.population(n=10)\n",
    "algorithms.eaSimple(population, toolbox, cxpb=0.7, mutpb=0.2, ngen=40, verbose=True)\n",
    "\n",
    "# Extract best individual\n",
    "best_individual = tools.selBest(population, 1)[0]\n",
    "\n",
    "# Extracting the best individual\n",
    "best_individual = tools.selBest(population, k=1)[0]\n",
    "optimal_params_ga = [int(best_individual[0]), int(best_individual[1])]\n",
    "print(f'Optimized Parameters (GA): {optimal_params_ga}')\n",
    "print(f'GA optimized parameters: {best_individual}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized RF Model (GA) - Mean Squared Error: 0.35962710430243205\n",
      "Optimized RF Model (GA) - R^2 Score: 0.6228416709567263\n"
     ]
    }
   ],
   "source": [
    "# Retrain the Random Forest with optimized parameters from GA\n",
    "rf_model_ga_optimized = RandomForestRegressor(\n",
    "    n_estimators=optimal_params_ga[1], \n",
    "    max_depth=optimal_params_ga[1], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model_ga_optimized.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Make predictions on both training and test data\n",
    "y_train_pred_ga_optimized = rf_model_ga_optimized.predict(X_train_m1)\n",
    "y_test_pred_ga_optimized = rf_model_ga_optimized.predict(X_test_m1)\n",
    "\n",
    "# Evaluate the optimized model on the test data\n",
    "mse_ga_optimized = mean_squared_error(y_test_m1, y_test_pred_ga_optimized)\n",
    "r2_ga_optimized = r2_score(y_test_m1, y_test_pred_ga_optimized)\n",
    "\n",
    "print(f'Optimized RF Model (GA) - Mean Squared Error: {mse_ga_optimized}')\n",
    "print(f'Optimized RF Model (GA) - R^2 Score: {r2_ga_optimized}')\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_ga_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_ga_optimized})\n",
    "optimized_ga_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_ga_optimized})\n",
    "\n",
    "optimized_ga_train_results.to_excel('outputs/M2optimized_rf_ga_train_predictions.xlsx', index=False)\n",
    "optimized_ga_test_results.to_excel('outputs/M2optimized_rf_ga_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimized RF Model (PSO) vs. Optimized RF Model (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wakili/anaconda3/envs/mlenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-08-31 23:18:50,630] A new study created in memory with name: no-name-b7e6ef12-1a84-4aa7-94fd-1025b9a43a0f\n",
      "[I 2024-08-31 23:18:50,759] Trial 0 finished with value: 0.35863664627367975 and parameters: {'n_estimators': 15, 'max_depth': 8}. Best is trial 0 with value: 0.35863664627367975.\n",
      "[I 2024-08-31 23:18:51,104] Trial 1 finished with value: 0.7130983551709307 and parameters: {'n_estimators': 75, 'max_depth': 1}. Best is trial 0 with value: 0.35863664627367975.\n",
      "[I 2024-08-31 23:18:51,746] Trial 2 finished with value: 0.3585013046007807 and parameters: {'n_estimators': 63, 'max_depth': 7}. Best is trial 2 with value: 0.3585013046007807.\n",
      "[I 2024-08-31 23:18:51,949] Trial 3 finished with value: 0.40272765194297144 and parameters: {'n_estimators': 13, 'max_depth': 17}. Best is trial 2 with value: 0.3585013046007807.\n",
      "[I 2024-08-31 23:18:52,353] Trial 4 finished with value: 0.3569705186864074 and parameters: {'n_estimators': 48, 'max_depth': 7}. Best is trial 4 with value: 0.3569705186864074.\n",
      "[I 2024-08-31 23:18:52,710] Trial 5 finished with value: 0.35679381597036935 and parameters: {'n_estimators': 46, 'max_depth': 7}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:53,540] Trial 6 finished with value: 0.3844909451910375 and parameters: {'n_estimators': 70, 'max_depth': 14}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:54,146] Trial 7 finished with value: 0.38434212424403397 and parameters: {'n_estimators': 51, 'max_depth': 14}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:54,543] Trial 8 finished with value: 0.36833275530663995 and parameters: {'n_estimators': 54, 'max_depth': 6}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:55,311] Trial 9 finished with value: 0.4084380837079798 and parameters: {'n_estimators': 57, 'max_depth': 20}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:55,798] Trial 10 finished with value: 0.7130776973248402 and parameters: {'n_estimators': 98, 'max_depth': 1}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:56,185] Trial 11 finished with value: 0.36328875292001755 and parameters: {'n_estimators': 34, 'max_depth': 10}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:56,417] Trial 12 finished with value: 0.4362101907432567 and parameters: {'n_estimators': 38, 'max_depth': 4}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:56,781] Trial 13 finished with value: 0.3673476488969286 and parameters: {'n_estimators': 36, 'max_depth': 11}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:57,269] Trial 14 finished with value: 0.4360332916971232 and parameters: {'n_estimators': 86, 'max_depth': 4}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:57,550] Trial 15 finished with value: 0.36378971923278974 and parameters: {'n_estimators': 27, 'max_depth': 10}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:57,832] Trial 16 finished with value: 0.43571706591007614 and parameters: {'n_estimators': 45, 'max_depth': 4}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:58,080] Trial 17 finished with value: 0.37581036356290104 and parameters: {'n_estimators': 22, 'max_depth': 13}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:58,471] Trial 18 finished with value: 0.3571279457846347 and parameters: {'n_estimators': 44, 'max_depth': 8}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:58,974] Trial 19 finished with value: 0.36761949126319643 and parameters: {'n_estimators': 66, 'max_depth': 6}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:59,258] Trial 20 finished with value: 0.36566822713421465 and parameters: {'n_estimators': 26, 'max_depth': 11}. Best is trial 5 with value: 0.35679381597036935.\n",
      "[I 2024-08-31 23:18:59,679] Trial 21 finished with value: 0.3561333885242973 and parameters: {'n_estimators': 47, 'max_depth': 8}. Best is trial 21 with value: 0.3561333885242973.\n",
      "[I 2024-08-31 23:19:00,095] Trial 22 finished with value: 0.3578356793028165 and parameters: {'n_estimators': 46, 'max_depth': 9}. Best is trial 21 with value: 0.3561333885242973.\n",
      "[I 2024-08-31 23:19:00,533] Trial 23 finished with value: 0.3928407998464463 and parameters: {'n_estimators': 60, 'max_depth': 5}. Best is trial 21 with value: 0.3561333885242973.\n",
      "[I 2024-08-31 23:19:01,120] Trial 24 finished with value: 0.37192285776267714 and parameters: {'n_estimators': 51, 'max_depth': 12}. Best is trial 21 with value: 0.3561333885242973.\n",
      "[I 2024-08-31 23:19:01,844] Trial 25 finished with value: 0.35565956071691146 and parameters: {'n_estimators': 77, 'max_depth': 8}. Best is trial 25 with value: 0.35565956071691146.\n",
      "[I 2024-08-31 23:19:02,212] Trial 26 finished with value: 0.4775742951096454 and parameters: {'n_estimators': 80, 'max_depth': 3}. Best is trial 25 with value: 0.35565956071691146.\n",
      "[I 2024-08-31 23:19:03,080] Trial 27 finished with value: 0.3557347657149056 and parameters: {'n_estimators': 90, 'max_depth': 9}. Best is trial 25 with value: 0.35565956071691146.\n",
      "[I 2024-08-31 23:19:03,856] Trial 28 finished with value: 0.3557951769736755 and parameters: {'n_estimators': 91, 'max_depth': 9}. Best is trial 25 with value: 0.35565956071691146.\n",
      "[I 2024-08-31 23:19:05,139] Trial 29 finished with value: 0.38623836959130753 and parameters: {'n_estimators': 100, 'max_depth': 16}. Best is trial 25 with value: 0.35565956071691146.\n",
      "[I 2024-08-31 23:19:06,068] Trial 30 finished with value: 0.3557347657149056 and parameters: {'n_estimators': 90, 'max_depth': 9}. Best is trial 25 with value: 0.35565956071691146.\n",
      "[I 2024-08-31 23:19:06,955] Trial 31 finished with value: 0.35973241855591653 and parameters: {'n_estimators': 91, 'max_depth': 10}. Best is trial 25 with value: 0.35565956071691146.\n",
      "[I 2024-08-31 23:19:07,832] Trial 32 finished with value: 0.35591560324096905 and parameters: {'n_estimators': 88, 'max_depth': 9}. Best is trial 25 with value: 0.35565956071691146.\n",
      "[I 2024-08-31 23:19:08,611] Trial 33 finished with value: 0.3571215019232343 and parameters: {'n_estimators': 78, 'max_depth': 9}. Best is trial 25 with value: 0.35565956071691146.\n",
      "[I 2024-08-31 23:19:09,660] Trial 34 finished with value: 0.36651520310146535 and parameters: {'n_estimators': 94, 'max_depth': 12}. Best is trial 25 with value: 0.35565956071691146.\n",
      "[I 2024-08-31 23:19:10,361] Trial 35 finished with value: 0.35562594629454164 and parameters: {'n_estimators': 84, 'max_depth': 8}. Best is trial 35 with value: 0.35562594629454164.\n",
      "[I 2024-08-31 23:19:10,972] Trial 36 finished with value: 0.3662058604522227 and parameters: {'n_estimators': 81, 'max_depth': 6}. Best is trial 35 with value: 0.35562594629454164.\n",
      "[I 2024-08-31 23:19:11,692] Trial 37 finished with value: 0.3585407955374056 and parameters: {'n_estimators': 72, 'max_depth': 7}. Best is trial 35 with value: 0.35562594629454164.\n",
      "[I 2024-08-31 23:19:13,262] Trial 38 finished with value: 0.3551111057971758 and parameters: {'n_estimators': 86, 'max_depth': 8}. Best is trial 38 with value: 0.3551111057971758.\n",
      "[I 2024-08-31 23:19:14,456] Trial 39 finished with value: 0.3575938172312474 and parameters: {'n_estimators': 84, 'max_depth': 7}. Best is trial 38 with value: 0.3551111057971758.\n",
      "[I 2024-08-31 23:19:15,717] Trial 40 finished with value: 0.3556511872704439 and parameters: {'n_estimators': 75, 'max_depth': 8}. Best is trial 38 with value: 0.3551111057971758.\n",
      "[I 2024-08-31 23:19:16,621] Trial 41 finished with value: 0.3580504640921933 and parameters: {'n_estimators': 75, 'max_depth': 7}. Best is trial 38 with value: 0.3551111057971758.\n",
      "[I 2024-08-31 23:19:17,624] Trial 42 finished with value: 0.35576240324872355 and parameters: {'n_estimators': 68, 'max_depth': 8}. Best is trial 38 with value: 0.3551111057971758.\n",
      "[I 2024-08-31 23:19:18,517] Trial 43 finished with value: 0.39238265497133556 and parameters: {'n_estimators': 75, 'max_depth': 5}. Best is trial 38 with value: 0.3551111057971758.\n",
      "[I 2024-08-31 23:19:19,646] Trial 44 finished with value: 0.3544129356777026 and parameters: {'n_estimators': 95, 'max_depth': 8}. Best is trial 44 with value: 0.3544129356777026.\n",
      "[I 2024-08-31 23:19:20,496] Trial 45 finished with value: 0.3650352428828832 and parameters: {'n_estimators': 96, 'max_depth': 6}. Best is trial 44 with value: 0.3544129356777026.\n",
      "[I 2024-08-31 23:19:21,209] Trial 46 finished with value: 0.35562594629454164 and parameters: {'n_estimators': 84, 'max_depth': 8}. Best is trial 44 with value: 0.3544129356777026.\n",
      "[I 2024-08-31 23:19:21,731] Trial 47 finished with value: 0.392217312892682 and parameters: {'n_estimators': 82, 'max_depth': 5}. Best is trial 44 with value: 0.3544129356777026.\n",
      "[I 2024-08-31 23:19:22,540] Trial 48 finished with value: 0.36482510510058264 and parameters: {'n_estimators': 85, 'max_depth': 11}. Best is trial 44 with value: 0.3544129356777026.\n",
      "[I 2024-08-31 23:19:22,919] Trial 49 finished with value: 0.5793759692461337 and parameters: {'n_estimators': 94, 'max_depth': 2}. Best is trial 44 with value: 0.3544129356777026.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Parameters (Optuna): {'n_estimators': 95, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train_m1, y_train_m1)\n",
    "    y_pred = rf_model.predict(X_test_m1)\n",
    "    \n",
    "    mse = mean_squared_error(y_test_m1, y_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "optimal_params_optuna = study.best_params\n",
    "print(f'Optimized Parameters (Optuna): {optimal_params_optuna}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the optimized parameters\n",
    "rf_model_optuna_optimized = RandomForestRegressor(\n",
    "    n_estimators=optimal_params_optuna['n_estimators'],\n",
    "    max_depth=optimal_params_optuna['max_depth'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model_optuna_optimized.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Make predictions on both training and test data\n",
    "y_train_pred_optuna_optimized = rf_model_optuna_optimized.predict(X_train_m1)\n",
    "y_test_pred_optuna_optimized = rf_model_optuna_optimized.predict(X_test_m1)\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_optuna_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_optuna_optimized})\n",
    "optimized_optuna_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_optuna_optimized})\n",
    "\n",
    "optimized_optuna_train_results.to_excel('outputs/M2optimized_rf_optuna_train_predictions.xlsx', index=False)\n",
    "optimized_optuna_test_results.to_excel('outputs/M2optimized_rf_optuna_test_predictions.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from niapy.task import Task\n",
    "from niapy.algorithms.basic import HarrisHawksOptimization\n",
    "from niapy.problems.problem import Problem\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define a custom benchmark problem\n",
    "class RandomForestOptimizationProblem(Problem):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        # Define the problem dimension and bounds (2 parameters to optimize)\n",
    "        super().__init__(dimension=2, lower=[10, 1], upper=[100, 20])\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        # Extract the parameters\n",
    "        n_estimators = int(x[0])\n",
    "        max_depth = int(x[1])\n",
    "\n",
    "        # Create and train the Random Forest model\n",
    "        rf_model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        rf_model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # Predict and calculate the mean squared error\n",
    "        y_pred = rf_model.predict(self.X_test)\n",
    "        mse = mean_squared_error(self.y_test, y_pred)\n",
    "        \n",
    "        return mse\n",
    "\n",
    "# Initialize the problem with your dataset\n",
    "problem = RandomForestOptimizationProblem(X_train_m1, y_train_m1, X_test_m1, y_test_m1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Parameters (HHO): n_estimators = 21, max_depth = 7\n",
      "Best MSE achieved: 0.35303886323718014\n"
     ]
    }
   ],
   "source": [
    "# Define the task for the HHO algorithm\n",
    "task = Task(problem=problem, max_iters=100)\n",
    "\n",
    "# Initialize the HHO algorithm\n",
    "algo = HarrisHawksOptimization(population_size=30)\n",
    "\n",
    "# Run the optimization\n",
    "best_params, best_mse = algo.run(task)\n",
    "\n",
    "print(f'Optimized Parameters (HHO): n_estimators = {int(best_params[0])}, max_depth = {int(best_params[1])}')\n",
    "print(f'Best MSE achieved: {best_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the optimized parameters\n",
    "rf_model_hho_optimized = RandomForestRegressor(\n",
    "    n_estimators=int(best_params[0]),\n",
    "    max_depth=int(best_params[1]),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model_hho_optimized.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Make predictions on both training and test data\n",
    "y_train_pred_hho_optimized = rf_model_hho_optimized.predict(X_train_m1)\n",
    "y_test_pred_hho_optimized = rf_model_hho_optimized.predict(X_test_m1)\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_hho_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_hho_optimized})\n",
    "optimized_hho_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_hho_optimized})\n",
    "\n",
    "optimized_hho_train_results.to_excel('outputs/M2optimized_rf_hho_train_predictions.xlsx', index=False)\n",
    "optimized_hho_test_results.to_excel('outputs/M2optimized_rf_hho_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
