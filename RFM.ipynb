{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Qa     Qc     Qd   Qhx   Ir     Qe       WPR\n",
      "0   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "1   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "2   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "3   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "4   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "5   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "6   0.000  0.000  0.000  0.00    6  0.000  0.000000\n",
      "7   0.000  0.000  0.000  0.00  122  0.000  0.000000\n",
      "8   2.601  1.889  2.645  1.24  333  1.845  0.100440\n",
      "9   5.770  4.702  5.911  1.70  517  4.560  1.051920\n",
      "10  7.868  6.516  8.093  1.99  636  6.292  1.505088\n",
      "11  8.792  7.302  9.057  2.11  670  7.037  1.938276\n",
      "12  9.446  7.855  9.742  2.19  695  7.560  2.405268\n",
      "13  8.669  7.198  8.928  2.09  634  6.938  2.019600\n",
      "14  6.688  5.500  6.864  1.83  497  5.324  0.753840\n",
      "15  3.562  2.751  3.632  1.39  302  2.681  0.000000\n",
      "16  0.000  0.000  0.000  0.00   91  0.000  0.000000\n",
      "17  0.000  0.000  0.000  0.00    2  0.000  0.000000\n",
      "18  0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "19  0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "X_train_m1 shape: (7008, 6)\n",
      "y_train_m1 shape: (7008,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data_m1 = pd.read_excel('data/M1.xlsx')\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X_m1 = data_m1.drop('WPR', axis=1)\n",
    "y_m1 = data_m1['WPR']\n",
    "\n",
    "# Show the first 20 rows of the data\n",
    "print(data_m1.head(20))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_m1, X_test_m1, y_train_m1, y_test_m1 = train_test_split(X_m1, y_m1, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train_m1 shape:\", X_train_m1.shape)\n",
    "print(\"y_train_m1 shape:\", y_train_m1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF Model - Mean Squared Error: 0.7181106254132201\n",
      "Baseline RF Model - R^2 Score: 0.24688267288857202\n"
     ]
    }
   ],
   "source": [
    "# Train the baseline Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Make predictions on both training and test data\n",
    "y_train_pred = rf_model.predict(X_train_m1)\n",
    "y_test_pred = rf_model.predict(X_test_m1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "mse = mean_squared_error(y_test_m1, y_test_pred)\n",
    "r2 = r2_score(y_test_m1, y_test_pred)\n",
    "\n",
    "print(f'Baseline RF Model - Mean Squared Error: {mse}')\n",
    "print(f'Baseline RF Model - R^2 Score: {r2}')\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "baseline_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred})\n",
    "baseline_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred})\n",
    "\n",
    "baseline_train_results.to_excel('outputs/baseline_rf_train_predictions.xlsx', index=False)\n",
    "baseline_test_results.to_excel('outputs/baseline_rf_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: maximum iterations reached --> 10\n",
      "Optimized Parameters (PSO): [41.70629072  3.85779957]\n",
      "Optimized Mean Squared Error (PSO): 0.5905351801080733\n"
     ]
    }
   ],
   "source": [
    "from pyswarm import pso\n",
    "\n",
    "# Objective function to minimize\n",
    "def rf_pso(params):\n",
    "    n_estimators = int(params[0])\n",
    "    max_depth = int(params[1])\n",
    "    \n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_m1, y_train_m1)\n",
    "    y_pred = rf_model.predict(X_test_m1)\n",
    "    \n",
    "    return mean_squared_error(y_test_m1, y_pred)\n",
    "\n",
    "# PSO parameter bounds\n",
    "lb = [10, 1]  # Lower bounds for n_estimators and max_depth\n",
    "ub = [100, 20]  # Upper bounds for n_estimators and max_depth\n",
    "\n",
    "# Run PSO\n",
    "optimal_params, optimal_mse = pso(rf_pso, lb, ub, swarmsize=10, maxiter=10)\n",
    "\n",
    "print(f'Optimized Parameters (PSO): {optimal_params}')\n",
    "print(f'Optimized Mean Squared Error (PSO): {optimal_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized RF Model (PSO) - Mean Squared Error: 0.5926641543108092\n",
      "Optimized RF Model (PSO) - R^2 Score: 0.37844445135111004\n"
     ]
    }
   ],
   "source": [
    "# Retrain the Random Forest with optimized parameters from PSO\n",
    "n_estimators_optimized = int(optimal_params[0])\n",
    "max_depth_optimized = int(optimal_params[1])\n",
    "\n",
    "rf_model_optimized = RandomForestRegressor(\n",
    "    n_estimators=n_estimators_optimized, \n",
    "    max_depth=max_depth_optimized, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model_optimized.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Make predictions on both training and test data\n",
    "y_train_pred_optimized = rf_model_optimized.predict(X_train_m1)\n",
    "y_test_pred_optimized = rf_model_optimized.predict(X_test_m1)\n",
    "\n",
    "# Evaluate the optimized model on the test data\n",
    "mse_optimized = mean_squared_error(y_test_m1, y_test_pred_optimized)\n",
    "r2_optimized = r2_score(y_test_m1, y_test_pred_optimized)\n",
    "\n",
    "print(f'Optimized RF Model (PSO) - Mean Squared Error: {mse_optimized}')\n",
    "print(f'Optimized RF Model (PSO) - R^2 Score: {r2_optimized}')\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_optimized})\n",
    "optimized_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_optimized})\n",
    "\n",
    "optimized_train_results.to_excel('outputs/optimized_rf_pso_train_predictions.xlsx', index=False)\n",
    "optimized_test_results.to_excel('outputs/optimized_rf_pso_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF Model\n",
      "Mean Squared Error: 0.7181106254132201\n",
      "R^2 Score: 0.24688267288857202\n",
      "\n",
      "Optimized RF Model (PSO)\n",
      "Mean Squared Error: 0.5926641543108092\n",
      "R^2 Score: 0.37844445135111004\n"
     ]
    }
   ],
   "source": [
    "# Compare results of baseline and Optimized RF Model (PSO\n",
    "print(\"Baseline RF Model\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "print(\"\\nOptimized RF Model (PSO)\")\n",
    "print(f\"Mean Squared Error: {mse_optimized}\")\n",
    "print(f\"R^2 Score: {r2_optimized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t10    \n",
      "1  \t3     \n",
      "2  \t10    \n",
      "3  \t9     \n",
      "4  \t9     \n",
      "5  \t8     \n",
      "6  \t6     \n",
      "7  \t10    \n",
      "8  \t7     \n",
      "9  \t9     \n",
      "10 \t9     \n",
      "11 \t9     \n",
      "12 \t9     \n",
      "13 \t9     \n",
      "14 \t7     \n",
      "15 \t8     \n",
      "16 \t8     \n",
      "17 \t6     \n",
      "18 \t8     \n",
      "19 \t5     \n",
      "20 \t9     \n",
      "21 \t10    \n",
      "22 \t8     \n",
      "23 \t6     \n",
      "24 \t8     \n",
      "25 \t4     \n",
      "26 \t9     \n",
      "27 \t8     \n",
      "28 \t8     \n",
      "29 \t7     \n",
      "30 \t5     \n",
      "31 \t9     \n",
      "32 \t8     \n",
      "33 \t8     \n",
      "34 \t8     \n",
      "35 \t8     \n",
      "36 \t7     \n",
      "37 \t8     \n",
      "38 \t6     \n",
      "39 \t5     \n",
      "40 \t7     \n",
      "Optimized Parameters (GA): [0, 4]\n",
      "GA optimized parameters: [0.1781056152379834, 4.250662476314364, 226.21730517442415]\n"
     ]
    }
   ],
   "source": [
    "#Optimize Random Forest with Genetic Algorithm (GA)\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rf_ga(individual):\n",
    "    n_estimators = int(individual[1])\n",
    "    max_depth = int(individual[1])\n",
    "    \n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_m1, y_train_m1)\n",
    "    y_pred = rf_model.predict(X_test_m1)\n",
    "    \n",
    "    return mean_squared_error(y_test_m1, y_pred),\n",
    "\n",
    "# Create types\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "# Register functions\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.uniform, 0.01, 0.3)\n",
    "toolbox.register(\"attr_int\", random.randint, 3, 10)\n",
    "toolbox.register(\"attr_int2\", random.randint, 50, 300)\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_float, toolbox.attr_int, toolbox.attr_int2), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", rf_ga)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "\n",
    "# Mutation function that constrains the learning_rate to [0.01, 0.3]\n",
    "def constrained_mutation(individual, indpb):\n",
    "    if random.random() < indpb:\n",
    "        individual[0] = min(max(individual[0] + random.gauss(0, 0.05), 0.01), 0.3)\n",
    "    if random.random() < indpb:\n",
    "        individual[1] = random.randint(3, 10)\n",
    "    if random.random() < indpb:\n",
    "        individual[2] = random.randint(50, 300)\n",
    "    return individual,\n",
    "\n",
    "toolbox.register(\"mutate\", constrained_mutation, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# Define population and evolution\n",
    "population = toolbox.population(n=10)\n",
    "algorithms.eaSimple(population, toolbox, cxpb=0.7, mutpb=0.2, ngen=40, verbose=True)\n",
    "\n",
    "# Extract best individual\n",
    "best_individual = tools.selBest(population, 1)[0]\n",
    "\n",
    "# Extracting the best individual\n",
    "best_individual = tools.selBest(population, k=1)[0]\n",
    "optimal_params_ga = [int(best_individual[0]), int(best_individual[1])]\n",
    "print(f'Optimized Parameters (GA): {optimal_params_ga}')\n",
    "print(f'GA optimized parameters: {best_individual}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized RF Model (GA) - Mean Squared Error: 0.5920059751706191\n",
      "Optimized RF Model (GA) - R^2 Score: 0.37913471563251544\n"
     ]
    }
   ],
   "source": [
    "# Retrain the Random Forest with optimized parameters from GA\n",
    "rf_model_ga_optimized = RandomForestRegressor(\n",
    "    n_estimators=optimal_params_ga[1], \n",
    "    max_depth=optimal_params_ga[1], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model_ga_optimized.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Make predictions on both training and test data\n",
    "y_train_pred_ga_optimized = rf_model_ga_optimized.predict(X_train_m1)\n",
    "y_test_pred_ga_optimized = rf_model_ga_optimized.predict(X_test_m1)\n",
    "\n",
    "# Evaluate the optimized model on the test data\n",
    "mse_ga_optimized = mean_squared_error(y_test_m1, y_test_pred_ga_optimized)\n",
    "r2_ga_optimized = r2_score(y_test_m1, y_test_pred_ga_optimized)\n",
    "\n",
    "print(f'Optimized RF Model (GA) - Mean Squared Error: {mse_ga_optimized}')\n",
    "print(f'Optimized RF Model (GA) - R^2 Score: {r2_ga_optimized}')\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_ga_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_ga_optimized})\n",
    "optimized_ga_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_ga_optimized})\n",
    "\n",
    "optimized_ga_train_results.to_excel('outputs/optimized_rf_ga_train_predictions.xlsx', index=False)\n",
    "optimized_ga_test_results.to_excel('outputs/optimized_rf_ga_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimized RF Model (PSO) vs. Optimized RF Model (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-31 09:52:05,572] A new study created in memory with name: no-name-39bef4b7-6876-45bb-84c8-b3f2e722b3fd\n",
      "[I 2024-08-31 09:52:05,870] Trial 0 finished with value: 0.6055196711348385 and parameters: {'n_estimators': 27, 'max_depth': 6}. Best is trial 0 with value: 0.6055196711348385.\n",
      "[I 2024-08-31 09:52:06,577] Trial 1 finished with value: 0.6113878942635281 and parameters: {'n_estimators': 77, 'max_depth': 7}. Best is trial 0 with value: 0.6055196711348385.\n",
      "[I 2024-08-31 09:52:06,661] Trial 2 finished with value: 0.6153310681176575 and parameters: {'n_estimators': 29, 'max_depth': 1}. Best is trial 0 with value: 0.6055196711348385.\n",
      "[I 2024-08-31 09:52:07,517] Trial 3 finished with value: 0.6925110642253975 and parameters: {'n_estimators': 64, 'max_depth': 14}. Best is trial 0 with value: 0.6055196711348385.\n",
      "[I 2024-08-31 09:52:08,511] Trial 4 finished with value: 0.6581772870716005 and parameters: {'n_estimators': 83, 'max_depth': 11}. Best is trial 0 with value: 0.6055196711348385.\n",
      "[I 2024-08-31 09:52:08,684] Trial 5 finished with value: 0.6224357477288021 and parameters: {'n_estimators': 18, 'max_depth': 7}. Best is trial 0 with value: 0.6055196711348385.\n",
      "[I 2024-08-31 09:52:09,649] Trial 6 finished with value: 0.6895972538549556 and parameters: {'n_estimators': 72, 'max_depth': 14}. Best is trial 0 with value: 0.6055196711348385.\n",
      "[I 2024-08-31 09:52:09,821] Trial 7 finished with value: 0.6159903581190325 and parameters: {'n_estimators': 62, 'max_depth': 1}. Best is trial 0 with value: 0.6055196711348385.\n",
      "[I 2024-08-31 09:52:10,726] Trial 8 finished with value: 0.7076564997338753 and parameters: {'n_estimators': 64, 'max_depth': 17}. Best is trial 0 with value: 0.6055196711348385.\n",
      "[I 2024-08-31 09:52:10,947] Trial 9 finished with value: 0.7344837762368466 and parameters: {'n_estimators': 15, 'max_depth': 20}. Best is trial 0 with value: 0.6055196711348385.\n",
      "[I 2024-08-31 09:52:11,308] Trial 10 finished with value: 0.6034982519807087 and parameters: {'n_estimators': 42, 'max_depth': 6}. Best is trial 10 with value: 0.6034982519807087.\n",
      "[I 2024-08-31 09:52:11,674] Trial 11 finished with value: 0.6034982519807087 and parameters: {'n_estimators': 42, 'max_depth': 6}. Best is trial 10 with value: 0.6034982519807087.\n",
      "[I 2024-08-31 09:52:11,962] Trial 12 finished with value: 0.5933006852857821 and parameters: {'n_estimators': 43, 'max_depth': 4}. Best is trial 12 with value: 0.5933006852857821.\n",
      "[I 2024-08-31 09:52:12,191] Trial 13 finished with value: 0.5905351801080733 and parameters: {'n_estimators': 41, 'max_depth': 3}. Best is trial 13 with value: 0.5905351801080733.\n",
      "[I 2024-08-31 09:52:12,714] Trial 14 finished with value: 0.5880554909127201 and parameters: {'n_estimators': 97, 'max_depth': 3}. Best is trial 14 with value: 0.5880554909127201.\n",
      "[I 2024-08-31 09:52:13,220] Trial 15 finished with value: 0.5883023212185099 and parameters: {'n_estimators': 94, 'max_depth': 3}. Best is trial 14 with value: 0.5880554909127201.\n",
      "[I 2024-08-31 09:52:14,266] Trial 16 finished with value: 0.6388046136153093 and parameters: {'n_estimators': 99, 'max_depth': 9}. Best is trial 14 with value: 0.5880554909127201.\n",
      "[I 2024-08-31 09:52:14,803] Trial 17 finished with value: 0.5880554909127201 and parameters: {'n_estimators': 97, 'max_depth': 3}. Best is trial 14 with value: 0.5880554909127201.\n",
      "[I 2024-08-31 09:52:15,794] Trial 18 finished with value: 0.6503983669405053 and parameters: {'n_estimators': 87, 'max_depth': 10}. Best is trial 14 with value: 0.5880554909127201.\n",
      "[I 2024-08-31 09:52:16,285] Trial 19 finished with value: 0.5884940094749913 and parameters: {'n_estimators': 91, 'max_depth': 3}. Best is trial 14 with value: 0.5880554909127201.\n",
      "[I 2024-08-31 09:52:17,291] Trial 20 finished with value: 0.6718385195622071 and parameters: {'n_estimators': 80, 'max_depth': 12}. Best is trial 14 with value: 0.5880554909127201.\n",
      "[I 2024-08-31 09:52:17,939] Trial 21 finished with value: 0.5943616380421858 and parameters: {'n_estimators': 97, 'max_depth': 4}. Best is trial 14 with value: 0.5880554909127201.\n",
      "[I 2024-08-31 09:52:18,207] Trial 22 finished with value: 0.6136671170518877 and parameters: {'n_estimators': 93, 'max_depth': 1}. Best is trial 14 with value: 0.5880554909127201.\n",
      "[I 2024-08-31 09:52:18,753] Trial 23 finished with value: 0.5880480472026909 and parameters: {'n_estimators': 100, 'max_depth': 3}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:19,479] Trial 24 finished with value: 0.6216225085357714 and parameters: {'n_estimators': 73, 'max_depth': 8}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:20,123] Trial 25 finished with value: 0.5946005829066886 and parameters: {'n_estimators': 100, 'max_depth': 4}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:20,766] Trial 26 finished with value: 0.5990342961591281 and parameters: {'n_estimators': 87, 'max_depth': 5}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:21,113] Trial 27 finished with value: 0.6080352651131632 and parameters: {'n_estimators': 83, 'max_depth': 2}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:21,523] Trial 28 finished with value: 0.5968952193221662 and parameters: {'n_estimators': 55, 'max_depth': 5}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:21,893] Trial 29 finished with value: 0.6081223707116639 and parameters: {'n_estimators': 88, 'max_depth': 2}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:22,662] Trial 30 finished with value: 0.6355646683655861 and parameters: {'n_estimators': 72, 'max_depth': 9}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:23,168] Trial 31 finished with value: 0.5883023212185099 and parameters: {'n_estimators': 94, 'max_depth': 3}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:23,904] Trial 32 finished with value: 0.6005930495580472 and parameters: {'n_estimators': 100, 'max_depth': 5}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:24,289] Trial 33 finished with value: 0.6079797115949669 and parameters: {'n_estimators': 93, 'max_depth': 2}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:25,015] Trial 34 finished with value: 0.6123360017491064 and parameters: {'n_estimators': 80, 'max_depth': 7}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:25,267] Trial 35 finished with value: 0.6149052947984318 and parameters: {'n_estimators': 88, 'max_depth': 1}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:25,783] Trial 36 finished with value: 0.5880824174259182 and parameters: {'n_estimators': 95, 'max_depth': 3}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:26,341] Trial 37 finished with value: 0.5991954545893944 and parameters: {'n_estimators': 75, 'max_depth': 5}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:27,170] Trial 38 finished with value: 0.6255279022075421 and parameters: {'n_estimators': 84, 'max_depth': 8}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:28,040] Trial 39 finished with value: 0.6670345632054574 and parameters: {'n_estimators': 68, 'max_depth': 12}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:28,296] Trial 40 finished with value: 0.6166047246814406 and parameters: {'n_estimators': 23, 'max_depth': 7}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:29,002] Trial 41 finished with value: 0.5880759809794034 and parameters: {'n_estimators': 96, 'max_depth': 3}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:29,644] Trial 42 finished with value: 0.6078550482493345 and parameters: {'n_estimators': 96, 'max_depth': 2}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:30,370] Trial 43 finished with value: 0.5942897094479193 and parameters: {'n_estimators': 90, 'max_depth': 4}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:30,866] Trial 44 finished with value: 0.6135412153818927 and parameters: {'n_estimators': 100, 'max_depth': 1}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:31,890] Trial 45 finished with value: 0.7030589135140168 and parameters: {'n_estimators': 57, 'max_depth': 17}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:32,850] Trial 46 finished with value: 0.6052952444761808 and parameters: {'n_estimators': 80, 'max_depth': 6}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:32,979] Trial 47 finished with value: 0.5937992243321103 and parameters: {'n_estimators': 10, 'max_depth': 3}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:33,690] Trial 48 finished with value: 0.5943498769114165 and parameters: {'n_estimators': 96, 'max_depth': 4}. Best is trial 23 with value: 0.5880480472026909.\n",
      "[I 2024-08-31 09:52:34,529] Trial 49 finished with value: 0.6059172390260567 and parameters: {'n_estimators': 84, 'max_depth': 6}. Best is trial 23 with value: 0.5880480472026909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Parameters (Optuna): {'n_estimators': 100, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train_m1, y_train_m1)\n",
    "    y_pred = rf_model.predict(X_test_m1)\n",
    "    \n",
    "    mse = mean_squared_error(y_test_m1, y_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "optimal_params_optuna = study.best_params\n",
    "print(f'Optimized Parameters (Optuna): {optimal_params_optuna}')\n",
    "\n",
    "# Retrain the model with the optimized parameters\n",
    "rf_model_optuna_optimized = RandomForestRegressor(\n",
    "    n_estimators=optimal_params_optuna['n_estimators'],\n",
    "    max_depth=optimal_params_optuna['max_depth'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model_optuna_optimized.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Make predictions on both training and test data\n",
    "y_train_pred_optuna_optimized = rf_model_optuna_optimized.predict(X_train_m1)\n",
    "y_test_pred_optuna_optimized = rf_model_optuna_optimized.predict(X_test_m1)\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_optuna_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_optuna_optimized})\n",
    "optimized_optuna_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_optuna_optimized})\n",
    "\n",
    "optimized_optuna_train_results.to_excel('outputs/optimized_rf_optuna_train_predictions.xlsx', index=False)\n",
    "optimized_optuna_test_results.to_excel('outputs/optimized_rf_optuna_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from niapy.task import Task\n",
    "from niapy.algorithms.basic import HarrisHawksOptimization\n",
    "from niapy.problems.problem import Problem\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define a custom benchmark problem\n",
    "class RandomForestOptimizationProblem(Problem):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        # Define the problem dimension and bounds (2 parameters to optimize)\n",
    "        super().__init__(dimension=2, lower=[10, 1], upper=[100, 20])\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        # Extract the parameters\n",
    "        n_estimators = int(x[0])\n",
    "        max_depth = int(x[1])\n",
    "\n",
    "        # Create and train the Random Forest model\n",
    "        rf_model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        rf_model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # Predict and calculate the mean squared error\n",
    "        y_pred = rf_model.predict(self.X_test)\n",
    "        mse = mean_squared_error(self.y_test, y_pred)\n",
    "        \n",
    "        return mse\n",
    "\n",
    "# Initialize the problem with your dataset\n",
    "problem = RandomForestOptimizationProblem(X_train_m1, y_train_m1, X_test_m1, y_test_m1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Parameters (HHO): n_estimators = 99, max_depth = 3\n",
      "Best MSE achieved: 0.58787776732519\n"
     ]
    }
   ],
   "source": [
    "# Define the task for the HHO algorithm\n",
    "task = Task(problem=problem, max_iters=100)\n",
    "\n",
    "# Initialize the HHO algorithm\n",
    "algo = HarrisHawksOptimization(population_size=30)\n",
    "\n",
    "# Run the optimization\n",
    "best_params, best_mse = algo.run(task)\n",
    "\n",
    "print(f'Optimized Parameters (HHO): n_estimators = {int(best_params[0])}, max_depth = {int(best_params[1])}')\n",
    "print(f'Best MSE achieved: {best_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the optimized parameters\n",
    "rf_model_hho_optimized = RandomForestRegressor(\n",
    "    n_estimators=int(best_params[0]),\n",
    "    max_depth=int(best_params[1]),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model_hho_optimized.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Make predictions on both training and test data\n",
    "y_train_pred_hho_optimized = rf_model_hho_optimized.predict(X_train_m1)\n",
    "y_test_pred_hho_optimized = rf_model_hho_optimized.predict(X_test_m1)\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_hho_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_hho_optimized})\n",
    "optimized_hho_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_hho_optimized})\n",
    "\n",
    "optimized_hho_train_results.to_excel('outputs/optimized_rf_hho_train_predictions.xlsx', index=False)\n",
    "optimized_hho_test_results.to_excel('outputs/optimized_rf_hho_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
