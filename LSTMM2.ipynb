{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     effa   effc   effd      mu     T20       win    COP       WPR\n",
      "0   0.000  0.000  0.000  0.0000   0.000  0.002411  0.000  0.000000\n",
      "1   0.000  0.000  0.000  0.0000   0.000  0.002006  0.000  0.000000\n",
      "2   0.000  0.000  0.000  0.0000   0.000  0.002001  0.000  0.000000\n",
      "3   0.000  0.000  0.000  0.0000   0.000  0.002102  0.000  0.000000\n",
      "4   0.000  0.000  0.000  0.0000   0.000  0.002078  0.000  0.000000\n",
      "5   0.000  0.000  0.000  0.0000   0.000  0.002011  0.000  0.000000\n",
      "6   0.000  0.000  0.000  0.0000   0.000  0.001874  0.000  0.000000\n",
      "7   0.000  0.000  0.000  0.0000   0.000  0.001938  0.000  0.000000\n",
      "8   0.689  0.641  0.497  0.1590  -6.700  0.002231  0.698  0.100440\n",
      "9   0.666  0.641  0.478  0.2288 -13.250  0.002167  0.771  1.051920\n",
      "10  0.653  0.641  0.469  0.2544 -16.520  0.002276  0.777  1.505088\n",
      "11  0.648  0.641  0.465  0.2702 -16.210  0.002703  0.777  1.938276\n",
      "12  0.645  0.641  0.462  0.2800 -16.050  0.003149  0.776  2.405268\n",
      "13  0.649  0.641  0.465  0.2815 -13.430  0.003044  0.777  2.019600\n",
      "14  0.660  0.641  0.473  0.2762  -7.745  0.002650  0.776  0.753840\n",
      "15  0.681  0.641  0.490  0.2407   1.062  0.002726  0.738  0.000000\n",
      "16  0.000  0.000  0.000  0.0000   0.000  0.002438  0.000  0.000000\n",
      "17  0.000  0.000  0.000  0.0000   0.000  0.002110  0.000  0.000000\n",
      "18  0.000  0.000  0.000  0.0000   0.000  0.002158  0.000  0.000000\n",
      "19  0.000  0.000  0.000  0.0000   0.000  0.002018  0.000  0.000000\n",
      "X_train_m1 shape: (7008, 7)\n",
      "y_train_m1 shape: (7008,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data_m1 = pd.read_excel('data/M2.xlsx')\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X_m1 = data_m1.drop('WPR', axis=1)\n",
    "y_m1 = data_m1['WPR']\n",
    "\n",
    "# Show the first 20 rows of the data\n",
    "print(data_m1.head(20))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_m1, X_test_m1, y_train_m1, y_test_m1 = train_test_split(X_m1, y_m1, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train_m1 shape:\", X_train_m1.shape)\n",
    "print(\"y_train_m1 shape:\", y_train_m1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 16:53:16.653662: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-02 16:53:16.922765: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-02 16:53:16.925244: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-02 16:53:20.453874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_m1_lstm shape: (7008, 1, 7)\n",
      "X_test_m1_lstm shape: (1752, 1, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_m1_scaled = scaler.fit_transform(X_train_m1)\n",
    "X_test_m1_scaled = scaler.transform(X_test_m1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # You can choose 'median', 'most_frequent', or 'constant'\n",
    "X_train_m1_scaled = imputer.fit_transform(X_train_m1_scaled)\n",
    "X_test_m1_scaled = imputer.transform(X_test_m1_scaled)\n",
    "\n",
    "# Reshape the input to be 3D [samples, timesteps, features]\n",
    "X_train_m1_lstm = np.reshape(X_train_m1_scaled, (X_train_m1_scaled.shape[0], 1, X_train_m1_scaled.shape[1]))\n",
    "X_test_m1_lstm = np.reshape(X_test_m1_scaled, (X_test_m1_scaled.shape[0], 1, X_test_m1_scaled.shape[1]))\n",
    "\n",
    "print(\"X_train_m1_lstm shape:\", X_train_m1_lstm.shape)\n",
    "print(\"X_test_m1_lstm shape:\", X_test_m1_lstm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.isnan(X_test_m1_lstm).sum())  # Count NaNs in training features\n",
    "print(np.isnan(X_test_m1_lstm).sum())   # Count NaNs in testing features\n",
    "print(np.isnan(y_train_m1).sum())  # Count NaNs in training labels\n",
    "print(np.isnan(y_test_m1).sum())   # Count NaNs in testing labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 16:53:24.869825: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 22s 32ms/step - loss: 0.9121 - val_loss: 0.7287\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.7901 - val_loss: 0.6417\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.6537 - val_loss: 0.5572\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 0.5796 - val_loss: 0.5154\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.5586 - val_loss: 0.5124\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.5496 - val_loss: 0.5071\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.5349 - val_loss: 0.4878\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.5233 - val_loss: 0.4760\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.5196 - val_loss: 0.4732\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.5182 - val_loss: 0.4705\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.5128 - val_loss: 0.4616\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.5056 - val_loss: 0.4641\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.5003 - val_loss: 0.4573\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.4980 - val_loss: 0.4509\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.4941 - val_loss: 0.4488\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.4933 - val_loss: 0.4661\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.4904 - val_loss: 0.4370\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 0.4803 - val_loss: 0.4315\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.4779 - val_loss: 0.4257\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.4802 - val_loss: 0.4288\n",
      "219/219 [==============================] - 6s 11ms/step\n",
      "55/55 [==============================] - 4s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build the baseline LSTM model\n",
    "\n",
    "# Define the baseline LSTM model\n",
    "def create_lstm_model(units=50, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_m1_lstm.shape[1], X_train_m1_lstm.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "baseline_lstm_model = create_lstm_model()\n",
    "\n",
    "\n",
    "# Train the baseline LSTM model\n",
    "baseline_lstm_model.fit(X_train_m1_lstm, y_train_m1, epochs=20, batch_size=32, validation_data=(X_test_m1_lstm, y_test_m1), verbose=1)\n",
    "\n",
    "# Predict on the training and test data\n",
    "y_train_pred_lstm_baseline = baseline_lstm_model.predict(X_train_m1_lstm)\n",
    "y_test_pred_lstm_baseline = baseline_lstm_model.predict(X_test_m1_lstm)\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "baseline_lstm_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_lstm_baseline.flatten()})\n",
    "baseline_lstm_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_lstm_baseline.flatten()})\n",
    "\n",
    "baseline_lstm_train_results.to_excel('outputs/M2baseline_lstm_train_predictions.xlsx', index=False)\n",
    "baseline_lstm_test_results.to_excel('outputs/M2baseline_lstm_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7008, 1, 7)\n",
      "(7008, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_m1_lstm.shape)\n",
    "print(X_train_m1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 5s 17ms/step\n",
      "55/55 [==============================] - 5s 11ms/step\n",
      "55/55 [==============================] - 4s 5ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 4s 17ms/step\n",
      "55/55 [==============================] - 3s 12ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 4s 14ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 4s 15ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 3s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 11ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 5s 9ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 2s 9ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 3s 10ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 5ms/step\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 3s 11ms/step\n",
      "55/55 [==============================] - 2s 10ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 9ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 4s 11ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 13ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 5s 13ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 5s 18ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 3s 5ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 9s 41ms/step\n",
      "55/55 [==============================] - 2s 9ms/step\n",
      "55/55 [==============================] - 4s 10ms/step\n",
      "55/55 [==============================] - 4s 12ms/step\n",
      "55/55 [==============================] - 6s 11ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 3s 14ms/step\n",
      "55/55 [==============================] - 8s 18ms/step\n",
      "55/55 [==============================] - 3s 10ms/step\n",
      "55/55 [==============================] - 7s 15ms/step\n",
      "55/55 [==============================] - 6s 11ms/step\n",
      "55/55 [==============================] - 6s 22ms/step\n",
      "55/55 [==============================] - 4s 10ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 3s 5ms/step\n",
      "55/55 [==============================] - 4s 19ms/step\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 4s 15ms/step\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 3s 5ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 4s 10ms/step\n",
      "55/55 [==============================] - 3s 10ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 3s 11ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 4s 9ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 4s 15ms/step\n",
      "55/55 [==============================] - 4s 8ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 8s 15ms/step\n",
      "55/55 [==============================] - 4s 10ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 7s 11ms/step\n",
      "55/55 [==============================] - 7s 16ms/step\n",
      "55/55 [==============================] - 6s 13ms/step\n",
      "55/55 [==============================] - 4s 9ms/step\n",
      "55/55 [==============================] - 4s 13ms/step\n",
      "55/55 [==============================] - 7s 11ms/step\n",
      "55/55 [==============================] - 4s 10ms/step\n",
      "55/55 [==============================] - 7s 19ms/step\n",
      "55/55 [==============================] - 6s 16ms/step\n",
      "55/55 [==============================] - 6s 15ms/step\n",
      "55/55 [==============================] - 4s 10ms/step\n",
      "55/55 [==============================] - 6s 13ms/step\n",
      "55/55 [==============================] - 9s 14ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 5s 26ms/step\n",
      "55/55 [==============================] - 4s 10ms/step\n",
      "55/55 [==============================] - 8s 15ms/step\n",
      "55/55 [==============================] - 6s 14ms/step\n",
      "55/55 [==============================] - 4s 9ms/step\n",
      "55/55 [==============================] - 12s 18ms/step\n",
      "55/55 [==============================] - 3s 11ms/step\n",
      "55/55 [==============================] - 8s 19ms/step\n",
      "55/55 [==============================] - 4s 15ms/step\n",
      "55/55 [==============================] - 5s 16ms/step\n",
      "55/55 [==============================] - 3s 10ms/step\n",
      "55/55 [==============================] - 7s 13ms/step\n",
      "55/55 [==============================] - 8s 21ms/step\n",
      "55/55 [==============================] - 6s 15ms/step\n",
      "55/55 [==============================] - 11s 18ms/step\n",
      "55/55 [==============================] - 10s 14ms/step\n",
      "55/55 [==============================] - 4s 9ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 3s 10ms/step\n",
      "55/55 [==============================] - 4s 10ms/step\n",
      "55/55 [==============================] - 4s 9ms/step\n",
      "55/55 [==============================] - 4s 10ms/step\n",
      "55/55 [==============================] - 7s 12ms/step\n",
      "55/55 [==============================] - 5s 12ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 5s 13ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 4s 9ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 3s 5ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 6s 11ms/step\n",
      "55/55 [==============================] - 3s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 3s 4ms/step\n",
      "Stopping search: maximum iterations reached --> 10\n",
      "Optimized Parameters (PSO): lstm_units = 71, dropout_rate = 0.11513715956089554, learning_rate = 0.006586013981843674, batch_size = 16\n",
      "Best MSE achieved: 0.37178456609366867\n"
     ]
    }
   ],
   "source": [
    "from pyswarm import pso  # This is a placeholder, replace with actual PSO implementation\n",
    "\n",
    "# Define the fitness function for LSTM model\n",
    "def lstm_fitness_function(params):\n",
    "    # Unpack parameters\n",
    "    lstm_units = int(params[0])\n",
    "    dropout_rate = params[1]\n",
    "    learning_rate = params[2]\n",
    "    batch_size = int(params[3])\n",
    "    \n",
    "    # Build the LSTM model with the parameters\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True, input_shape=(1, 7)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_m1_lstm, y_train_m1, epochs=10, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_pred = model.predict(X_test_m1_lstm)\n",
    "    mse = mean_squared_error(y_test_m1, y_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Set the bounds for parameters: [lstm_units, dropout_rate, learning_rate, batch_size]\n",
    "bounds = ([10, 0.1, 0.0001, 16], [100, 0.5, 0.01, 128])\n",
    "\n",
    "# Run the PSO\n",
    "best_params, best_mse = pso(lstm_fitness_function, bounds[0], bounds[1], swarmsize=20, maxiter=10)\n",
    "\n",
    "print(f'Optimized Parameters (PSO): lstm_units = {int(best_params[0])}, dropout_rate = {best_params[1]}, learning_rate = {best_params[2]}, batch_size = {int(best_params[3])}')\n",
    "print(f'Best MSE achieved: {best_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "438/438 [==============================] - 23s 29ms/step - loss: 0.7247\n",
      "Epoch 2/20\n",
      "438/438 [==============================] - 13s 31ms/step - loss: 0.5477\n",
      "Epoch 3/20\n",
      "438/438 [==============================] - 12s 27ms/step - loss: 0.5255\n",
      "Epoch 4/20\n",
      "438/438 [==============================] - 10s 22ms/step - loss: 0.5102\n",
      "Epoch 5/20\n",
      "438/438 [==============================] - 7s 16ms/step - loss: 0.4960\n",
      "Epoch 6/20\n",
      "438/438 [==============================] - 5s 11ms/step - loss: 0.4945\n",
      "Epoch 7/20\n",
      "438/438 [==============================] - 4s 9ms/step - loss: 0.4850\n",
      "Epoch 8/20\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.4663\n",
      "Epoch 9/20\n",
      "438/438 [==============================] - 5s 12ms/step - loss: 0.4696\n",
      "Epoch 10/20\n",
      "438/438 [==============================] - 4s 8ms/step - loss: 0.4614\n",
      "Epoch 11/20\n",
      "438/438 [==============================] - 3s 8ms/step - loss: 0.4581\n",
      "Epoch 12/20\n",
      "438/438 [==============================] - 4s 8ms/step - loss: 0.4532\n",
      "Epoch 13/20\n",
      "438/438 [==============================] - 3s 7ms/step - loss: 0.4436\n",
      "Epoch 14/20\n",
      "438/438 [==============================] - 3s 8ms/step - loss: 0.4614\n",
      "Epoch 15/20\n",
      "438/438 [==============================] - 3s 7ms/step - loss: 0.4493\n",
      "Epoch 16/20\n",
      "438/438 [==============================] - 3s 7ms/step - loss: 0.4401\n",
      "Epoch 17/20\n",
      "438/438 [==============================] - 4s 9ms/step - loss: 0.4417\n",
      "Epoch 18/20\n",
      "438/438 [==============================] - 4s 9ms/step - loss: 0.4259\n",
      "Epoch 19/20\n",
      "438/438 [==============================] - 5s 10ms/step - loss: 0.4333\n",
      "Epoch 20/20\n",
      "438/438 [==============================] - 5s 12ms/step - loss: 0.4442\n",
      "219/219 [==============================] - 5s 8ms/step\n",
      "55/55 [==============================] - 4s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model with the optimized parameters\n",
    "optimized_lstm_model = Sequential()\n",
    "optimized_lstm_model.add(LSTM(units=int(best_params[0]), return_sequences=True, input_shape=(X_train_m1_lstm.shape[1], X_train_m1_lstm.shape[2])))\n",
    "optimized_lstm_model.add(Dropout(best_params[1]))\n",
    "optimized_lstm_model.add(LSTM(units=int(best_params[0])))\n",
    "optimized_lstm_model.add(Dropout(best_params[1]))\n",
    "optimized_lstm_model.add(Dense(1))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=best_params[2])\n",
    "optimized_lstm_model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the optimized model\n",
    "optimized_lstm_model.fit(X_train_m1_lstm, y_train_m1, epochs=20, batch_size=int(best_params[3]), verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_lstm_optimized = optimized_lstm_model.predict(X_train_m1_lstm)\n",
    "y_test_pred_lstm_optimized = optimized_lstm_model.predict(X_test_m1_lstm)\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_lstm_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_lstm_optimized.flatten()})\n",
    "optimized_lstm_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_lstm_optimized.flatten()})\n",
    "\n",
    "optimized_lstm_train_results.to_excel('outputs/M2optimized_lstm_train_predictions_PSO.xlsx', index=False)\n",
    "optimized_lstm_test_results.to_excel('outputs/M2optimized_lstm_test_predictions_PSO.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 5s 32ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 4s 9ms/step\n",
      "55/55 [==============================] - 5s 20ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 4s 13ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 4s 11ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step.0% GA is \n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 4s 9ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step.0% GA is run\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step.0% GA is ru\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 4s 16ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 6s 11ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 4s 9ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step.0% GA is run\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 3s 11ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 4ms/step0.0% GA is \n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 3s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 5ms/step2.0% GA i\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 6ms/step4.0% GA\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 4ms/step6.0% GA is \n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 11ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step8.0% GA is run\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 6ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 3s 9ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 1s 3ms/step0.0% GA is ru\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step2.0% GA is run\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 3s 8ms/step4.0\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 4s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 4s 7ms/step\n",
      "55/55 [==============================] - 1s 4ms/step6.0% GA is ru\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 4s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step8.0% GA is ru\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      " The best solution found:                                                                           \n",
      " [5.42172689e+01 1.25043518e-01 6.41399247e-03 3.08938159e+01]\n",
      "\n",
      " Objective function:\n",
      " 0.3811447752328437\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: GA is terminated due to the maximum number of iterations without improvement was met!Optimized Parameters (GA): lstm_units = 54, dropout_rate = 0.1250435183504109, learning_rate = 0.006413992468161486, batch_size = 30\n"
     ]
    }
   ],
   "source": [
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "\n",
    "# Define the fitness function for LSTM model\n",
    "def lstm_fitness_function_ga(params):\n",
    "    lstm_units = int(params[0])\n",
    "    dropout_rate = params[1]\n",
    "    learning_rate = params[2]\n",
    "    batch_size = int(params[3])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True, input_shape=(X_train_m1_lstm.shape[1], X_train_m1_lstm.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    model.fit(X_train_m1_lstm, y_train_m1, epochs=10, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(X_test_m1_lstm)\n",
    "    mse = mean_squared_error(y_test_m1, y_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Set the bounds for GA: [lstm_units, dropout_rate, learning_rate, batch_size]\n",
    "varbound = np.array([[10, 100], [0.1, 0.5], [0.0001, 0.01], [16, 128]])\n",
    "\n",
    "algorithm_param = {'max_num_iteration': 50, 'population_size': 20, 'mutation_probability': 0.1, 'elit_ratio': 0.01, 'crossover_probability': 0.5, 'parents_portion': 0.3, 'crossover_type':'uniform', 'max_iteration_without_improv':10}\n",
    "\n",
    "model = model = ga(function=lstm_fitness_function_ga, \n",
    "           dimension=4, \n",
    "           variable_type='real', \n",
    "           variable_boundaries=varbound, \n",
    "           algorithm_parameters=algorithm_param,\n",
    "           function_timeout=300)  # Increase the timeout\n",
    "\n",
    "model.run()\n",
    "\n",
    "best_params_ga = model.output_dict['variable']\n",
    "\n",
    "print(f'Optimized Parameters (GA): lstm_units = {int(best_params_ga[0])}, dropout_rate = {best_params_ga[1]}, learning_rate = {best_params_ga[2]}, batch_size = {int(best_params_ga[3])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "234/234 [==============================] - 10s 8ms/step - loss: 0.7820\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 0.5642\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 0.5193\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 0.5063\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 2s 9ms/step - loss: 0.5027\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 0.4885\n",
      "Epoch 7/20\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 0.4944\n",
      "Epoch 8/20\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.4695\n",
      "Epoch 9/20\n",
      "234/234 [==============================] - 2s 10ms/step - loss: 0.4805\n",
      "Epoch 10/20\n",
      "234/234 [==============================] - 4s 18ms/step - loss: 0.4729\n",
      "Epoch 11/20\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.4672\n",
      "Epoch 12/20\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.4452\n",
      "Epoch 13/20\n",
      "234/234 [==============================] - 4s 17ms/step - loss: 0.4510\n",
      "Epoch 14/20\n",
      "234/234 [==============================] - 7s 28ms/step - loss: 0.4513\n",
      "Epoch 15/20\n",
      "234/234 [==============================] - 8s 33ms/step - loss: 0.4466\n",
      "Epoch 16/20\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.4370\n",
      "Epoch 17/20\n",
      "234/234 [==============================] - 4s 18ms/step - loss: 0.4486\n",
      "Epoch 18/20\n",
      "234/234 [==============================] - 5s 21ms/step - loss: 0.4426\n",
      "Epoch 19/20\n",
      "234/234 [==============================] - 6s 26ms/step - loss: 0.4327\n",
      "Epoch 20/20\n",
      "234/234 [==============================] - 3s 15ms/step - loss: 0.4252\n",
      "219/219 [==============================] - 5s 10ms/step\n",
      "55/55 [==============================] - 6s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model with the GA-optimized parameters\n",
    "optimized_lstm_model_ga = Sequential()\n",
    "optimized_lstm_model_ga.add(LSTM(units=int(best_params_ga[0]), return_sequences=True, input_shape=(X_train_m1_lstm.shape[1], X_train_m1_lstm.shape[2])))\n",
    "optimized_lstm_model_ga.add(Dropout(best_params_ga[1]))\n",
    "optimized_lstm_model_ga.add(LSTM(units=int(best_params_ga[0])))\n",
    "optimized_lstm_model_ga.add(Dropout(best_params_ga[1]))\n",
    "optimized_lstm_model_ga.add(Dense(1))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=best_params_ga[2])\n",
    "optimized_lstm_model_ga.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "optimized_lstm_model_ga.fit(X_train_m1_lstm, y_train_m1, epochs=20, batch_size=int(best_params_ga[3]), verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_lstm_ga = optimized_lstm_model_ga.predict(X_train_m1_lstm)\n",
    "y_test_pred_lstm_ga = optimized_lstm_model_ga.predict(X_test_m1_lstm)\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_lstm_train_results_ga = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_lstm_ga.flatten()})\n",
    "optimized_lstm_test_results_ga = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_lstm_ga.flatten()})\n",
    "\n",
    "optimized_lstm_train_results_ga.to_excel('outputs/M2optimized_lstm_train_predictions_ga.xlsx', index=False)\n",
    "optimized_lstm_test_results_ga.to_excel('outputs/M2optimized_lstm_test_predictions_ga.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 2s 9ms/step\n",
      "55/55 [==============================] - 2s 10ms/step\n",
      "55/55 [==============================] - 3s 14ms/step\n",
      "55/55 [==============================] - 2s 12ms/step\n",
      "55/55 [==============================] - 2s 10ms/step\n",
      "55/55 [==============================] - 2s 9ms/step\n",
      "55/55 [==============================] - 2s 9ms/step\n",
      "55/55 [==============================] - 2s 9ms/step\n",
      "55/55 [==============================] - 2s 10ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "Optimized Parameters (HHO): lstm_units = 71, dropout_rate = 0.1\n",
      "219/219 [==============================] - 4s 9ms/step\n",
      "55/55 [==============================] - 3s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "from niapy.algorithms.basic import HarrisHawksOptimization\n",
    "from niapy.task import Task\n",
    "from niapy.problems import Problem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def create_lstm_model(units, dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(1, 7)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "X_train_m1_lstm = X_train_m1_scaled.reshape((X_train_m1_scaled.shape[0], 1, X_train_m1_scaled.shape[1]))\n",
    "X_test_m1_lstm = X_test_m1_scaled.reshape((X_test_m1_scaled.shape[0], 1, X_test_m1_scaled.shape[1]))\n",
    "\n",
    "class CustomLSTMBenchmark(Problem):\n",
    "    def __init__(self):\n",
    "        super().__init__(dimension=2, lower=[10, 0.1], upper=[100, 0.5])\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        units = int(x[0])  # Ensure units is an integer\n",
    "        dropout_rate = x[1]\n",
    "        \n",
    "        lstm_model = create_lstm_model(units=units, dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Use early stopping to reduce training time\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=0)\n",
    "        \n",
    "        lstm_model.fit(X_train_m1_lstm, y_train_m1, epochs=20, batch_size=32, verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        y_pred = lstm_model.predict(X_test_m1_lstm)\n",
    "        return mean_squared_error(y_test_m1, y_pred.flatten())\n",
    "\n",
    "task = Task(problem=CustomLSTMBenchmark(), max_evals=30) \n",
    "algo = HarrisHawksOptimization(population_size=10)  \n",
    "\n",
    "best_params_hho, best_loss = algo.run(task)\n",
    "\n",
    "# Extracting the parameters from the first element of the tuple\n",
    "best_units_hho = int(best_params_hho[0])\n",
    "best_dropout_rate_hho = best_params_hho[1]\n",
    "\n",
    "print(f\"Optimized Parameters (HHO): lstm_units = {best_units_hho}, dropout_rate = {best_dropout_rate_hho}\")\n",
    "\n",
    "# Train LSTM with HHO optimized parameters\n",
    "lstm_hho_model = create_lstm_model(units=best_units_hho, dropout_rate=best_dropout_rate_hho)\n",
    "lstm_hho_model.fit(X_train_m1_lstm, y_train_m1, epochs=2, batch_size=32, verbose=0)\n",
    "\n",
    "y_train_pred_hho = lstm_hho_model.predict(X_train_m1_lstm)\n",
    "y_test_pred_hho = lstm_hho_model.predict(X_test_m1_lstm)\n",
    "\n",
    "# Save the predictions\n",
    "results_train_hho = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_hho.flatten()})\n",
    "results_test_hho = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_hho.flatten()})\n",
    "\n",
    "results_train_hho.to_excel('outputs/M2lstm_hho_train_predictions_hho.xlsx', index=False)\n",
    "results_test_hho.to_excel('outputs/M2lstm_hho_test_predictions_hho.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wakili/anaconda3/envs/mlenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-09-02 17:30:52,379] A new study created in memory with name: no-name-608ee200-c21d-409c-8edf-0389568190b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:32:32,494] Trial 0 finished with value: 0.4078194315953082 and parameters: {'units': 59, 'dropout_rate': 0.3044719536137639}. Best is trial 0 with value: 0.4078194315953082.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:34:09,604] Trial 1 finished with value: 0.4192047166377434 and parameters: {'units': 49, 'dropout_rate': 0.4815700118079226}. Best is trial 0 with value: 0.4078194315953082.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:35:42,579] Trial 2 finished with value: 0.40176714838853783 and parameters: {'units': 49, 'dropout_rate': 0.14850855633816537}. Best is trial 2 with value: 0.40176714838853783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:36:48,290] Trial 3 finished with value: 0.412160800751412 and parameters: {'units': 72, 'dropout_rate': 0.2754921262764236}. Best is trial 2 with value: 0.40176714838853783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:37:41,861] Trial 4 finished with value: 0.42780252661055357 and parameters: {'units': 52, 'dropout_rate': 0.4942620927091741}. Best is trial 2 with value: 0.40176714838853783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:38:42,047] Trial 5 finished with value: 0.4137837070217592 and parameters: {'units': 89, 'dropout_rate': 0.27626983062494037}. Best is trial 2 with value: 0.40176714838853783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:39:36,328] Trial 6 finished with value: 0.4229238886899152 and parameters: {'units': 46, 'dropout_rate': 0.45087046061203984}. Best is trial 2 with value: 0.40176714838853783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:41:05,391] Trial 7 finished with value: 0.42167422329368737 and parameters: {'units': 32, 'dropout_rate': 0.25943558598914895}. Best is trial 2 with value: 0.40176714838853783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:41:58,116] Trial 8 finished with value: 0.4240322630863694 and parameters: {'units': 23, 'dropout_rate': 0.34743186083124106}. Best is trial 2 with value: 0.40176714838853783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:43:39,867] Trial 9 finished with value: 0.42004761438526833 and parameters: {'units': 35, 'dropout_rate': 0.43203687895411036}. Best is trial 2 with value: 0.40176714838853783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:45:18,717] Trial 10 finished with value: 0.41776211296831994 and parameters: {'units': 13, 'dropout_rate': 0.10845643354330795}. Best is trial 2 with value: 0.40176714838853783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:46:37,833] Trial 11 finished with value: 0.40603613479715717 and parameters: {'units': 70, 'dropout_rate': 0.15657449238759122}. Best is trial 2 with value: 0.40176714838853783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 3s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:49:12,082] Trial 12 finished with value: 0.39839643233537836 and parameters: {'units': 74, 'dropout_rate': 0.12238145833133449}. Best is trial 12 with value: 0.39839643233537836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:51:09,264] Trial 13 finished with value: 0.39886752885143956 and parameters: {'units': 95, 'dropout_rate': 0.1873696984684587}. Best is trial 12 with value: 0.39839643233537836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 3s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:53:03,559] Trial 14 finished with value: 0.406744335803152 and parameters: {'units': 97, 'dropout_rate': 0.19988689332312543}. Best is trial 12 with value: 0.39839643233537836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:54:56,078] Trial 15 finished with value: 0.4273594074393848 and parameters: {'units': 83, 'dropout_rate': 0.2087251945423628}. Best is trial 12 with value: 0.39839643233537836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:56:45,984] Trial 16 finished with value: 0.3995792215105531 and parameters: {'units': 78, 'dropout_rate': 0.11524967002062508}. Best is trial 12 with value: 0.39839643233537836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:58:50,480] Trial 17 finished with value: 0.4075756897205974 and parameters: {'units': 100, 'dropout_rate': 0.2093095593002582}. Best is trial 12 with value: 0.39839643233537836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:00:41,045] Trial 18 finished with value: 0.40774061818771645 and parameters: {'units': 63, 'dropout_rate': 0.16350424680142986}. Best is trial 12 with value: 0.39839643233537836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:02:37,386] Trial 19 finished with value: 0.40709425177764086 and parameters: {'units': 91, 'dropout_rate': 0.3768840595594606}. Best is trial 12 with value: 0.39839643233537836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:04:36,757] Trial 20 finished with value: 0.40327270446814584 and parameters: {'units': 83, 'dropout_rate': 0.23562132390559692}. Best is trial 12 with value: 0.39839643233537836.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:06:27,801] Trial 21 finished with value: 0.39690712337059786 and parameters: {'units': 76, 'dropout_rate': 0.10125538902125565}. Best is trial 21 with value: 0.39690712337059786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:08:15,740] Trial 22 finished with value: 0.3970602652173451 and parameters: {'units': 70, 'dropout_rate': 0.10394225069231891}. Best is trial 21 with value: 0.39690712337059786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:10:05,943] Trial 23 finished with value: 0.40019314100961073 and parameters: {'units': 66, 'dropout_rate': 0.10746173223675884}. Best is trial 21 with value: 0.39690712337059786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:11:41,871] Trial 24 finished with value: 0.40033695413898857 and parameters: {'units': 75, 'dropout_rate': 0.1495070222769202}. Best is trial 21 with value: 0.39690712337059786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:12:49,921] Trial 25 finished with value: 0.39833920643401494 and parameters: {'units': 82, 'dropout_rate': 0.10068388130901487}. Best is trial 21 with value: 0.39690712337059786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:13:55,774] Trial 26 finished with value: 0.39321996415113786 and parameters: {'units': 83, 'dropout_rate': 0.10116189422607359}. Best is trial 26 with value: 0.39321996415113786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:14:59,317] Trial 27 finished with value: 0.4040026379660742 and parameters: {'units': 62, 'dropout_rate': 0.14628752511378032}. Best is trial 26 with value: 0.39321996415113786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:16:05,494] Trial 28 finished with value: 0.4054757863279402 and parameters: {'units': 89, 'dropout_rate': 0.17113609470950453}. Best is trial 26 with value: 0.39321996415113786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 18:17:02,811] Trial 29 finished with value: 0.4107366669651621 and parameters: {'units': 55, 'dropout_rate': 0.3237540321041719}. Best is trial 26 with value: 0.39321996415113786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define the LSTM model creation function\n",
    "def create_lstm_model(units, dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=False, input_shape=(1, X_train_m1_lstm.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))  # Assuming your output is a single continuous value\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Reshape input data to 3D for LSTM\n",
    "X_train_m1_lstm = X_train_m1_scaled.reshape((X_train_m1_scaled.shape[0], 1, X_train_m1_scaled.shape[1]))\n",
    "X_test_m1_lstm = X_test_m1_scaled.reshape((X_test_m1_scaled.shape[0], 1, X_test_m1_scaled.shape[1]))\n",
    "\n",
    "# Objective function for BBO\n",
    "def bbo_lstm_objective(trial):\n",
    "    units = trial.suggest_int(\"units\", 10, 100)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    \n",
    "    lstm_model = create_lstm_model(units=units, dropout_rate=dropout_rate)\n",
    "    lstm_model.fit(X_train_m1_lstm, y_train_m1, epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "    y_pred = lstm_model.predict(X_test_m1_lstm)\n",
    "    return mean_squared_error(y_test_m1, y_pred.flatten())\n",
    "\n",
    "# Create and optimize study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(bbo_lstm_objective, n_trials=30)\n",
    "\n",
    "# Retrieve best parameters\n",
    "best_units_bbo = study.best_params[\"units\"]\n",
    "best_dropout_rate_bbo = study.best_params[\"dropout_rate\"]\n",
    "\n",
    "# Train LSTM with BBO optimized parameters\n",
    "lstm_bbo_model = create_lstm_model(units=best_units_bbo, dropout_rate=best_dropout_rate_bbo)\n",
    "lstm_bbo_model.fit(X_train_m1_lstm, y_train_m1, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_bbo = lstm_bbo_model.predict(X_train_m1_lstm)\n",
    "y_test_pred_bbo = lstm_bbo_model.predict(X_test_m1_lstm)\n",
    "\n",
    "# Save the predictions\n",
    "results_train_bbo = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_bbo.flatten()})\n",
    "results_test_bbo = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_bbo.flatten()})\n",
    "\n",
    "results_train_bbo.to_excel('outputs/lstm_bbo_train_predictions.xlsx', index=False)\n",
    "results_test_bbo.to_excel('outputs/lstm_bbo_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
