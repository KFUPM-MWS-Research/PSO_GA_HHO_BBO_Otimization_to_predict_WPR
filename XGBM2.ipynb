{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data_m1 = pd.read_excel('data/M2.xlsx')\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X_m1 = data_m1.drop('WPR', axis=1)\n",
    "y_m1 = data_m1['WPR']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_m1, X_test_m1, y_train_m1, y_test_m1 = train_test_split(X_m1, y_m1, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline XGBoost MSE (Train):  0.30808851958306926\n",
      "Baseline XGBoost MSE (Test):  0.35425646964408025\n"
     ]
    }
   ],
   "source": [
    "#Baseline model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Baseline XGBoost model\n",
    "xg_reg_baseline = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                                   colsample_bytree=0.3, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth=5, \n",
    "                                   n_estimators=100)\n",
    "xg_reg_baseline.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Predictions for training and test sets\n",
    "y_train_pred_baseline = xg_reg_baseline.predict(X_train_m1)\n",
    "y_test_pred_baseline = xg_reg_baseline.predict(X_test_m1)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "mse_train_baseline = mean_squared_error(y_train_m1, y_train_pred_baseline)\n",
    "mse_test_baseline = mean_squared_error(y_test_m1, y_test_pred_baseline)\n",
    "\n",
    "print(\"Baseline XGBoost MSE (Train): \", mse_train_baseline)\n",
    "print(\"Baseline XGBoost MSE (Test): \", mse_test_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: Swarm best objective change less than 1e-08\n",
      "Best Parameters from PSO: [  0.1191119    5.20029474 102.53759398]\n",
      "Best MSE from PSO: 0.34774526853069915\n"
     ]
    }
   ],
   "source": [
    "#PSO Optimization of hyperparameters\n",
    "from pyswarm import pso\n",
    "\n",
    "# Objective function for PSO\n",
    "def pso_objective(params):\n",
    "    learning_rate, max_depth, n_estimators = params\n",
    "    xg_reg = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                              colsample_bytree=0.3, \n",
    "                              learning_rate=learning_rate, \n",
    "                              max_depth=int(max_depth), \n",
    "                              n_estimators=int(n_estimators))\n",
    "    xg_reg.fit(X_train_m1, y_train_m1)\n",
    "    predictions = xg_reg.predict(X_test_m1)\n",
    "    return mean_squared_error(y_test_m1, predictions)\n",
    "\n",
    "# Define bounds for learning_rate, max_depth, n_estimators\n",
    "bounds = ([0.01, 3, 50], [0.2, 10, 200])\n",
    "\n",
    "# Run PSO\n",
    "best_params, best_mse = pso(pso_objective, bounds[0], bounds[1], swarmsize=50, maxiter=100)\n",
    "\n",
    "print(\"Best Parameters from PSO:\", best_params)\n",
    "print(\"Best MSE from PSO:\", best_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model with the best hyperparameters from PSO\n",
    "# xg_reg_pso = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "#                               colsample_bytree=0.3, \n",
    "#                               learning_rate=best_params[0], \n",
    "#                               max_depth=int(best_params[1]), \n",
    "#                               n_estimators=int(best_params[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The best solution found:                                                                           \n",
      " [ 0.16154885  5.19808917 76.8198839 ]\n",
      "\n",
      " Objective function:\n",
      " 0.35409701517748166\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: GA is terminated due to the maximum number of iterations without improvement was met!Best Parameters from GA: [ 0.16154885  5.19808917 76.8198839 ]\n",
      "Best MSE from GA: 0.35409701517748166\n"
     ]
    }
   ],
   "source": [
    "#Genetic Algorithm Optimization of hyperparameters\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "\n",
    "def ga_objective(params):\n",
    "    learning_rate, max_depth, n_estimators = params\n",
    "    xg_reg = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                              colsample_bytree=0.3, \n",
    "                              learning_rate=learning_rate, \n",
    "                              max_depth=int(max_depth), \n",
    "                              n_estimators=int(n_estimators))\n",
    "    xg_reg.fit(X_train_m1, y_train_m1)\n",
    "    predictions = xg_reg.predict(X_test_m1)\n",
    "    return mean_squared_error(y_test_m1, predictions)\n",
    "\n",
    "varbound = np.array([[0.01, 0.2], [3, 10], [50, 200]])\n",
    "\n",
    "model = ga(function=ga_objective, \n",
    "           dimension=3, \n",
    "           variable_type='real', \n",
    "           variable_boundaries=varbound,\n",
    "           algorithm_parameters={\n",
    "               'max_num_iteration': 100,  # Fewer iterations\n",
    "               'population_size': 25,    # Smaller population\n",
    "               'mutation_probability': 0.1,\n",
    "               'elit_ratio': 0.01,\n",
    "               'crossover_probability': 0.5,\n",
    "               'parents_portion': 0.3,\n",
    "               'crossover_type':'uniform',\n",
    "               'max_iteration_without_improv': 25})\n",
    "\n",
    "model.run()\n",
    "best_params_ga = model.output_dict['variable']\n",
    "print(\"Best Parameters from GA:\", best_params_ga)\n",
    "print(\"Best MSE from GA:\", model.output_dict['function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model with the best hyperparameters from GA\n",
    "# xg_reg_ga = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "#                              colsample_bytree=0.3,\n",
    "#                              learning_rate=best_params_ga[0],\n",
    "#                              max_depth=int(best_params_ga[1]),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from HHO: [ 0.12583413  5.77638456 79.94089191]\n"
     ]
    }
   ],
   "source": [
    "from niapy.task import Task\n",
    "from niapy.algorithms.basic import HarrisHawksOptimization\n",
    "from niapy.problems import Problem\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class XGBBenchmark(Problem):\n",
    "    def __init__(self):\n",
    "        # Call the parent class constructor with the dimension, lower, and upper bounds\n",
    "        super().__init__(dimension=3, lower=[0.01, 3, 50], upper=[0.2, 10, 200])\n",
    "        self.X_train = X_train_m1\n",
    "        self.y_train = y_train_m1\n",
    "        self.X_test = X_test_m1\n",
    "        self.y_test = y_test_m1\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        learning_rate, max_depth, n_estimators = x\n",
    "        xg_reg = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                                  colsample_bytree=0.3, \n",
    "                                  learning_rate=learning_rate, \n",
    "                                  max_depth=int(max_depth), \n",
    "                                  n_estimators=int(n_estimators))\n",
    "        xg_reg.fit(self.X_train, self.y_train)\n",
    "        predictions = xg_reg.predict(self.X_test)\n",
    "        return mean_squared_error(self.y_test, predictions)\n",
    "\n",
    "# Define the task\n",
    "task = Task(problem=XGBBenchmark(), max_iters=100)\n",
    "\n",
    "# Run the HHO algorithm\n",
    "algorithm = HarrisHawksOptimization(population_size=30)\n",
    "best_params_hho = algorithm.run(task=task)\n",
    "print(\"Best Parameters from HHO:\", best_params_hho[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSO Optimized MSE (Train/Test): 0.296044715448727 0.34774526853069915\n",
      "GA Optimized MSE (Train/Test): 0.28529015105623967 0.35409701517748166\n",
      "HHO Optimized MSE (Train/Test): 0.3027804267601456 0.35018620017175756\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(params, X_train, y_train, X_test, y_test):\n",
    "    learning_rate, max_depth, n_estimators = params\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                             colsample_bytree=0.3, \n",
    "                             learning_rate=learning_rate, \n",
    "                             max_depth=int(max_depth), \n",
    "                             n_estimators=int(n_estimators))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    return mse_train, mse_test, y_train_pred, y_test_pred\n",
    "\n",
    "# Evaluate PSO optimized model\n",
    "mse_train_pso, mse_test_pso, y_train_pred_pso, y_test_pred_pso = train_and_evaluate(best_params, X_train_m1, y_train_m1, X_test_m1, y_test_m1)\n",
    "\n",
    "# Evaluate GA optimized model\n",
    "mse_train_ga, mse_test_ga, y_train_pred_ga, y_test_pred_ga = train_and_evaluate(best_params_ga, X_train_m1, y_train_m1, X_test_m1, y_test_m1)\n",
    "\n",
    "# Evaluate HHO optimized model\n",
    "mse_train_hho, mse_test_hho, y_train_pred_hho, y_test_pred_hho = train_and_evaluate(best_params_hho[0], X_train_m1, y_train_m1, X_test_m1, y_test_m1)\n",
    "\n",
    "# Compare the results\n",
    "print(\"PSO Optimized MSE (Train/Test):\", mse_train_pso, mse_test_pso)\n",
    "print(\"GA Optimized MSE (Train/Test):\", mse_train_ga, mse_test_ga)\n",
    "print(\"HHO Optimized MSE (Train/Test):\", mse_train_hho, mse_test_hho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Baseline model predictions\n",
    "baseline_results_train = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_baseline})\n",
    "baseline_results_test = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_baseline})\n",
    "baseline_results_train.to_csv('outputs/XGB_baseline_train_results.csv', index=False)\n",
    "baseline_results_test.to_csv('outputs/XGB_baseline_test_results.csv', index=False)\n",
    "\n",
    "# Save Optimized model predictions (PSO, GA, HHO)\n",
    "optimized_results_train_pso = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_pso})\n",
    "optimized_results_test_pso = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_pso})\n",
    "optimized_results_train_pso.to_excel('outputs/M2XGB_optimized_train_results_pso.xlsx', index=False)\n",
    "optimized_results_test_pso.to_excel('outputs/M2XGB_optimized_test_results_pso.xlsx', index=False)\n",
    "\n",
    "optimized_results_train_ga = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_ga})\n",
    "optimized_results_test_ga = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_ga})\n",
    "optimized_results_train_ga.to_excel('outputs/M2XGB_optimized_train_results_ga.xlsx', index=False)\n",
    "optimized_results_test_ga.to_excel('outputs/M2XGB_optimized_test_results_ga.xlsx', index=False)\n",
    "\n",
    "optimized_results_train_hho = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_hho})\n",
    "optimized_results_test_hho = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_hho})\n",
    "optimized_results_train_hho.to_excel('outputs/M2XGB_optimized_train_results_hho.xlsx', index=False)\n",
    "optimized_results_test_hho.to_excel('outputs/M2XGB_optimized_test_results_hho.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wakili/anaconda3/envs/mlenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-09-01 07:29:17,116] A new study created in memory with name: no-name-0183f538-b83e-4ec6-ab80-5a07b794e72a\n",
      "[I 2024-09-01 07:29:17,257] Trial 0 finished with value: 0.35984794340198517 and parameters: {'learning_rate': 0.15147852204010637, 'max_depth': 4, 'n_estimators': 72}. Best is trial 0 with value: 0.35984794340198517.\n",
      "[I 2024-09-01 07:29:17,717] Trial 1 finished with value: 0.44868375261598137 and parameters: {'learning_rate': 0.0957917685480718, 'max_depth': 10, 'n_estimators': 121}. Best is trial 0 with value: 0.35984794340198517.\n",
      "[I 2024-09-01 07:29:17,873] Trial 2 finished with value: 0.3980112863133231 and parameters: {'learning_rate': 0.09680989846380543, 'max_depth': 8, 'n_estimators': 66}. Best is trial 0 with value: 0.35984794340198517.\n",
      "[I 2024-09-01 07:29:17,975] Trial 3 finished with value: 0.3733086413523304 and parameters: {'learning_rate': 0.07892971159173409, 'max_depth': 5, 'n_estimators': 77}. Best is trial 0 with value: 0.35984794340198517.\n",
      "[I 2024-09-01 07:29:18,089] Trial 4 finished with value: 0.37496079028404117 and parameters: {'learning_rate': 0.08493107621794947, 'max_depth': 6, 'n_estimators': 71}. Best is trial 0 with value: 0.35984794340198517.\n",
      "[I 2024-09-01 07:29:18,324] Trial 5 finished with value: 0.39227817169881063 and parameters: {'learning_rate': 0.17848187704687393, 'max_depth': 7, 'n_estimators': 119}. Best is trial 0 with value: 0.35984794340198517.\n",
      "[I 2024-09-01 07:29:18,541] Trial 6 finished with value: 0.36012342388986057 and parameters: {'learning_rate': 0.16344372453888903, 'max_depth': 3, 'n_estimators': 148}. Best is trial 0 with value: 0.35984794340198517.\n",
      "[I 2024-09-01 07:29:19,121] Trial 7 finished with value: 0.47221855723677886 and parameters: {'learning_rate': 0.19360571406931615, 'max_depth': 9, 'n_estimators': 120}. Best is trial 0 with value: 0.35984794340198517.\n",
      "[I 2024-09-01 07:29:19,228] Trial 8 finished with value: 0.384775755598451 and parameters: {'learning_rate': 0.14503592373569646, 'max_depth': 3, 'n_estimators': 56}. Best is trial 0 with value: 0.35984794340198517.\n",
      "[I 2024-09-01 07:29:19,383] Trial 9 finished with value: 0.44335232428153415 and parameters: {'learning_rate': 0.019349695998776464, 'max_depth': 3, 'n_estimators': 176}. Best is trial 0 with value: 0.35984794340198517.\n",
      "[I 2024-09-01 07:29:19,524] Trial 10 finished with value: 0.35244896230604916 and parameters: {'learning_rate': 0.12558474963692193, 'max_depth': 5, 'n_estimators': 94}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:19,696] Trial 11 finished with value: 0.35576577388879643 and parameters: {'learning_rate': 0.12750109858411662, 'max_depth': 5, 'n_estimators': 94}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:19,835] Trial 12 finished with value: 0.35524993144357464 and parameters: {'learning_rate': 0.12301466707037952, 'max_depth': 5, 'n_estimators': 89}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:19,990] Trial 13 finished with value: 0.38568547710055695 and parameters: {'learning_rate': 0.05128753156479984, 'max_depth': 6, 'n_estimators': 99}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:20,126] Trial 14 finished with value: 0.3553219471433794 and parameters: {'learning_rate': 0.12280330996680079, 'max_depth': 5, 'n_estimators': 94}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:20,367] Trial 15 finished with value: 0.39055112703500655 and parameters: {'learning_rate': 0.1193953582376916, 'max_depth': 7, 'n_estimators': 149}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:20,563] Trial 16 finished with value: 0.3621824813952596 and parameters: {'learning_rate': 0.07294963658183738, 'max_depth': 4, 'n_estimators': 199}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:20,659] Trial 17 finished with value: 0.4619766381143523 and parameters: {'learning_rate': 0.053044176516500834, 'max_depth': 4, 'n_estimators': 50}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:20,922] Trial 18 finished with value: 0.3661056005417359 and parameters: {'learning_rate': 0.1371551415850767, 'max_depth': 6, 'n_estimators': 105}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:21,269] Trial 19 finished with value: 0.41574410411724866 and parameters: {'learning_rate': 0.10792705878803305, 'max_depth': 8, 'n_estimators': 144}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:21,453] Trial 20 finished with value: 0.3615124381160686 and parameters: {'learning_rate': 0.16220454010732305, 'max_depth': 5, 'n_estimators': 83}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:21,605] Trial 21 finished with value: 0.3544505848577842 and parameters: {'learning_rate': 0.11708580271506229, 'max_depth': 5, 'n_estimators': 94}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:21,720] Trial 22 finished with value: 0.3595631717691769 and parameters: {'learning_rate': 0.10936781123545888, 'max_depth': 4, 'n_estimators': 89}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:21,892] Trial 23 finished with value: 0.3562324895499813 and parameters: {'learning_rate': 0.13449454235792468, 'max_depth': 5, 'n_estimators': 106}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:22,108] Trial 24 finished with value: 0.36589762284431954 and parameters: {'learning_rate': 0.11710362236675308, 'max_depth': 6, 'n_estimators': 109}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:22,435] Trial 25 finished with value: 0.3735603752293714 and parameters: {'learning_rate': 0.06323762696355006, 'max_depth': 7, 'n_estimators': 138}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:22,612] Trial 26 finished with value: 0.3569651669427743 and parameters: {'learning_rate': 0.15090801715422422, 'max_depth': 4, 'n_estimators': 133}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:22,742] Trial 27 finished with value: 0.36867631253865596 and parameters: {'learning_rate': 0.09217843714956639, 'max_depth': 5, 'n_estimators': 83}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:22,849] Trial 28 finished with value: 0.37138969854367426 and parameters: {'learning_rate': 0.16898009187377763, 'max_depth': 6, 'n_estimators': 60}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:22,938] Trial 29 finished with value: 0.35805275489148436 and parameters: {'learning_rate': 0.14077896797366168, 'max_depth': 4, 'n_estimators': 75}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:23,044] Trial 30 finished with value: 0.36144380459092723 and parameters: {'learning_rate': 0.10491024754891493, 'max_depth': 4, 'n_estimators': 109}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:23,161] Trial 31 finished with value: 0.3557130366655467 and parameters: {'learning_rate': 0.12074355569520694, 'max_depth': 5, 'n_estimators': 91}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:23,283] Trial 32 finished with value: 0.35464352987603764 and parameters: {'learning_rate': 0.1273256889300346, 'max_depth': 5, 'n_estimators': 98}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:23,408] Trial 33 finished with value: 0.3595439648418916 and parameters: {'learning_rate': 0.15339719653263778, 'max_depth': 6, 'n_estimators': 82}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:23,507] Trial 34 finished with value: 0.3687455099114261 and parameters: {'learning_rate': 0.10030590904500233, 'max_depth': 5, 'n_estimators': 67}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:23,910] Trial 35 finished with value: 0.4735288898538988 and parameters: {'learning_rate': 0.13109361576503187, 'max_depth': 10, 'n_estimators': 126}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:24,136] Trial 36 finished with value: 0.3592898318837463 and parameters: {'learning_rate': 0.09052287765882891, 'max_depth': 5, 'n_estimators': 114}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:24,331] Trial 37 finished with value: 0.3990907216139191 and parameters: {'learning_rate': 0.11531035036122751, 'max_depth': 8, 'n_estimators': 97}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:24,465] Trial 38 finished with value: 0.38119571050490025 and parameters: {'learning_rate': 0.1517983866904051, 'max_depth': 7, 'n_estimators': 72}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:24,560] Trial 39 finished with value: 0.3721777817171514 and parameters: {'learning_rate': 0.17673456319493802, 'max_depth': 3, 'n_estimators': 102}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:24,757] Trial 40 finished with value: 0.36182420048213304 and parameters: {'learning_rate': 0.07897815560802568, 'max_depth': 6, 'n_estimators': 161}. Best is trial 10 with value: 0.35244896230604916.\n",
      "[I 2024-09-01 07:29:24,881] Trial 41 finished with value: 0.3516877377644093 and parameters: {'learning_rate': 0.12646417181003783, 'max_depth': 5, 'n_estimators': 90}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:24,996] Trial 42 finished with value: 0.35536601221432634 and parameters: {'learning_rate': 0.1296636727017769, 'max_depth': 5, 'n_estimators': 86}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:25,110] Trial 43 finished with value: 0.3594535966920079 and parameters: {'learning_rate': 0.14373794738479037, 'max_depth': 4, 'n_estimators': 115}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:25,252] Trial 44 finished with value: 0.3556611887649705 and parameters: {'learning_rate': 0.11038134254757648, 'max_depth': 5, 'n_estimators': 124}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:25,376] Trial 45 finished with value: 0.36531993777926264 and parameters: {'learning_rate': 0.12643927427349783, 'max_depth': 6, 'n_estimators': 75}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:25,458] Trial 46 finished with value: 0.3665021079311647 and parameters: {'learning_rate': 0.19983869395740245, 'max_depth': 4, 'n_estimators': 65}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:25,557] Trial 47 finished with value: 0.37422672761270886 and parameters: {'learning_rate': 0.10055599266076994, 'max_depth': 3, 'n_estimators': 99}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:25,663] Trial 48 finished with value: 0.36209144397611237 and parameters: {'learning_rate': 0.16053245633597343, 'max_depth': 5, 'n_estimators': 78}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:25,825] Trial 49 finished with value: 0.3840655448514967 and parameters: {'learning_rate': 0.1396818018620749, 'max_depth': 7, 'n_estimators': 91}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:25,960] Trial 50 finished with value: 0.43017920707101537 and parameters: {'learning_rate': 0.03235130463189374, 'max_depth': 6, 'n_estimators': 96}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:26,075] Trial 51 finished with value: 0.35503288271295064 and parameters: {'learning_rate': 0.12396490750268248, 'max_depth': 5, 'n_estimators': 91}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:26,194] Trial 52 finished with value: 0.35625180650712857 and parameters: {'learning_rate': 0.12378519636439783, 'max_depth': 5, 'n_estimators': 88}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:26,291] Trial 53 finished with value: 0.3619323713949979 and parameters: {'learning_rate': 0.11287399107739096, 'max_depth': 4, 'n_estimators': 80}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:26,433] Trial 54 finished with value: 0.3574972125697771 and parameters: {'learning_rate': 0.13413181047696032, 'max_depth': 5, 'n_estimators': 102}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:26,585] Trial 55 finished with value: 0.37174406198898763 and parameters: {'learning_rate': 0.14722522782695205, 'max_depth': 6, 'n_estimators': 114}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:26,705] Trial 56 finished with value: 0.35317363399693485 and parameters: {'learning_rate': 0.11957353497840256, 'max_depth': 5, 'n_estimators': 88}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:26,804] Trial 57 finished with value: 0.3725882741745804 and parameters: {'learning_rate': 0.09635463096868702, 'max_depth': 5, 'n_estimators': 66}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:26,908] Trial 58 finished with value: 0.3703481958931611 and parameters: {'learning_rate': 0.08672370563970658, 'max_depth': 4, 'n_estimators': 94}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:27,053] Trial 59 finished with value: 0.35985326671063333 and parameters: {'learning_rate': 0.10486620693149144, 'max_depth': 6, 'n_estimators': 107}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:27,163] Trial 60 finished with value: 0.35633226574167937 and parameters: {'learning_rate': 0.11901673193555685, 'max_depth': 5, 'n_estimators': 86}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:27,286] Trial 61 finished with value: 0.35482851434985263 and parameters: {'learning_rate': 0.12738390024530846, 'max_depth': 5, 'n_estimators': 100}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:27,416] Trial 62 finished with value: 0.3559989425214951 and parameters: {'learning_rate': 0.12787435604554828, 'max_depth': 5, 'n_estimators': 99}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:27,523] Trial 63 finished with value: 0.35837586795419435 and parameters: {'learning_rate': 0.13611760746043328, 'max_depth': 4, 'n_estimators': 92}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:27,651] Trial 64 finished with value: 0.35543129552717734 and parameters: {'learning_rate': 0.12072890256722664, 'max_depth': 5, 'n_estimators': 103}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:27,746] Trial 65 finished with value: 0.3621197740954176 and parameters: {'learning_rate': 0.11287799658979528, 'max_depth': 4, 'n_estimators': 84}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:27,881] Trial 66 finished with value: 0.3561363246006507 and parameters: {'learning_rate': 0.13320077651228615, 'max_depth': 5, 'n_estimators': 111}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:28,130] Trial 67 finished with value: 0.3846133535099699 and parameters: {'learning_rate': 0.15652666112595837, 'max_depth': 6, 'n_estimators': 197}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:28,257] Trial 68 finished with value: 0.3575592449982715 and parameters: {'learning_rate': 0.1434656155494273, 'max_depth': 6, 'n_estimators': 78}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:28,410] Trial 69 finished with value: 0.35706943957532983 and parameters: {'learning_rate': 0.10492256435978188, 'max_depth': 5, 'n_estimators': 129}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:28,571] Trial 70 finished with value: 0.39729464484166466 and parameters: {'learning_rate': 0.12345227617700635, 'max_depth': 8, 'n_estimators': 70}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:28,679] Trial 71 finished with value: 0.3539499856799305 and parameters: {'learning_rate': 0.11635573215735538, 'max_depth': 5, 'n_estimators': 90}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:28,922] Trial 72 finished with value: 0.422692702989162 and parameters: {'learning_rate': 0.11789481356880839, 'max_depth': 9, 'n_estimators': 94}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:29,060] Trial 73 finished with value: 0.3639825855134421 and parameters: {'learning_rate': 0.12897617252837706, 'max_depth': 5, 'n_estimators': 119}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:29,176] Trial 74 finished with value: 0.3534434986178364 and parameters: {'learning_rate': 0.11443423988989261, 'max_depth': 5, 'n_estimators': 89}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:29,276] Trial 75 finished with value: 0.36323696923844995 and parameters: {'learning_rate': 0.10105008858381662, 'max_depth': 4, 'n_estimators': 104}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:29,387] Trial 76 finished with value: 0.35402225450292324 and parameters: {'learning_rate': 0.1090655157159747, 'max_depth': 5, 'n_estimators': 86}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:29,481] Trial 77 finished with value: 0.378668368010329 and parameters: {'learning_rate': 0.10848867766586012, 'max_depth': 6, 'n_estimators': 56}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:29,587] Trial 78 finished with value: 0.36765592248384626 and parameters: {'learning_rate': 0.09208346726019125, 'max_depth': 5, 'n_estimators': 81}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:29,681] Trial 79 finished with value: 0.35563414203887234 and parameters: {'learning_rate': 0.1145117195234689, 'max_depth': 5, 'n_estimators': 74}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:29,776] Trial 80 finished with value: 0.37259701904301473 and parameters: {'learning_rate': 0.0831595435213589, 'max_depth': 4, 'n_estimators': 86}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:29,894] Trial 81 finished with value: 0.35194291227856545 and parameters: {'learning_rate': 0.11592654203456332, 'max_depth': 5, 'n_estimators': 96}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:30,020] Trial 82 finished with value: 0.3532839621260861 and parameters: {'learning_rate': 0.10910618360900079, 'max_depth': 5, 'n_estimators': 96}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:30,137] Trial 83 finished with value: 0.3564395056007458 and parameters: {'learning_rate': 0.10601291657186457, 'max_depth': 5, 'n_estimators': 88}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:30,275] Trial 84 finished with value: 0.364268139687695 and parameters: {'learning_rate': 0.09683100165222316, 'max_depth': 6, 'n_estimators': 95}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:30,380] Trial 85 finished with value: 0.35578359220493194 and parameters: {'learning_rate': 0.11041912963566777, 'max_depth': 5, 'n_estimators': 79}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:30,490] Trial 86 finished with value: 0.3540882441922622 and parameters: {'learning_rate': 0.11633586778696973, 'max_depth': 5, 'n_estimators': 89}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:30,594] Trial 87 finished with value: 0.3550405144391835 and parameters: {'learning_rate': 0.11585118010441324, 'max_depth': 5, 'n_estimators': 84}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:30,693] Trial 88 finished with value: 0.3633984377616881 and parameters: {'learning_rate': 0.1014647517903591, 'max_depth': 4, 'n_estimators': 91}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:30,781] Trial 89 finished with value: 0.3643840189203143 and parameters: {'learning_rate': 0.11985090106593826, 'max_depth': 4, 'n_estimators': 70}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:30,940] Trial 90 finished with value: 0.3656927744372562 and parameters: {'learning_rate': 0.1382997992326706, 'max_depth': 6, 'n_estimators': 107}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:31,053] Trial 91 finished with value: 0.35318142004509817 and parameters: {'learning_rate': 0.11181351307995196, 'max_depth': 5, 'n_estimators': 89}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:31,175] Trial 92 finished with value: 0.35314253552344027 and parameters: {'learning_rate': 0.11180253111169428, 'max_depth': 5, 'n_estimators': 88}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:31,288] Trial 93 finished with value: 0.3548721413542934 and parameters: {'learning_rate': 0.11083426017037468, 'max_depth': 5, 'n_estimators': 96}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:31,391] Trial 94 finished with value: 0.35999516335575077 and parameters: {'learning_rate': 0.10506711572536774, 'max_depth': 5, 'n_estimators': 76}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:31,510] Trial 95 finished with value: 0.3621354673882948 and parameters: {'learning_rate': 0.09876627766192723, 'max_depth': 5, 'n_estimators': 85}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:31,662] Trial 96 finished with value: 0.36692592528119466 and parameters: {'learning_rate': 0.09179302464900603, 'max_depth': 6, 'n_estimators': 82}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:31,813] Trial 97 finished with value: 0.35480382073659456 and parameters: {'learning_rate': 0.13173839027302897, 'max_depth': 5, 'n_estimators': 100}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:31,952] Trial 98 finished with value: 0.36049282187230397 and parameters: {'learning_rate': 0.12296548021032888, 'max_depth': 4, 'n_estimators': 88}. Best is trial 41 with value: 0.3516877377644093.\n",
      "[I 2024-09-01 07:29:32,086] Trial 99 finished with value: 0.3551076238699707 and parameters: {'learning_rate': 0.10855448943124886, 'max_depth': 5, 'n_estimators': 92}. Best is trial 41 with value: 0.3516877377644093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from BBO (Optuna): {'learning_rate': 0.12646417181003783, 'max_depth': 5, 'n_estimators': 90}\n",
      "Best MSE from BBO (Optuna): 0.3516877377644093\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest values for the parameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.2)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    \n",
    "    # Create and train the model\n",
    "    xg_reg = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                              colsample_bytree=0.3, \n",
    "                              learning_rate=learning_rate, \n",
    "                              max_depth=max_depth, \n",
    "                              n_estimators=n_estimators)\n",
    "    \n",
    "    xg_reg.fit(X_train_m1, y_train_m1)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    predictions = xg_reg.predict(X_test_m1)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_test_m1, predictions)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Best parameters and the corresponding MSE\n",
    "best_params_bbo = study.best_params\n",
    "best_mse_bbo = study.best_value\n",
    "\n",
    "print(\"Best Parameters from BBO (Optuna):\", best_params_bbo)\n",
    "print(\"Best MSE from BBO (Optuna):\", best_mse_bbo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSO Optimized MSE (Train/Test): 0.296044715448727 0.34774526853069915\n",
      "GA Optimized MSE (Train/Test): 0.28529015105623967 0.35409701517748166\n",
      "HHO Optimized MSE (Train/Test): 0.3027804267601456 0.35018620017175756\n",
      "BBO (Optuna) Optimized MSE (Train/Test): 0.2955155701937141 0.3516877377644093\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the BBO optimized model\n",
    "mse_train_bbo, mse_test_bbo, y_train_pred_bbo, y_test_pred_bbo = train_and_evaluate(\n",
    "    [best_params_bbo['learning_rate'], best_params_bbo['max_depth'], best_params_bbo['n_estimators']], \n",
    "    X_train_m1, y_train_m1, X_test_m1, y_test_m1\n",
    ")\n",
    "\n",
    "# Compare the results with other models\n",
    "print(\"PSO Optimized MSE (Train/Test):\", mse_train_pso, mse_test_pso)\n",
    "print(\"GA Optimized MSE (Train/Test):\", mse_train_ga, mse_test_ga)\n",
    "print(\"HHO Optimized MSE (Train/Test):\", mse_train_hho, mse_test_hho)\n",
    "print(\"BBO (Optuna) Optimized MSE (Train/Test):\", mse_train_bbo, mse_test_bbo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save BBO (Optuna) optimized model predictions\n",
    "optimized_results_train_bbo = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_bbo})\n",
    "optimized_results_test_bbo = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_bbo})\n",
    "optimized_results_train_bbo.to_excel('outputs/M2optimized_train_results_bbo.xlsx', index=False)\n",
    "optimized_results_test_bbo.to_excel('outputs/M2optimized_test_results_bbo.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
