{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Qa     Qc     Qd   Qhx   Ir     Qe       WPR\n",
      "0   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "1   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "2   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "3   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "4   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "5   0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "6   0.000  0.000  0.000  0.00    6  0.000  0.000000\n",
      "7   0.000  0.000  0.000  0.00  122  0.000  0.000000\n",
      "8   2.601  1.889  2.645  1.24  333  1.845  0.100440\n",
      "9   5.770  4.702  5.911  1.70  517  4.560  1.051920\n",
      "10  7.868  6.516  8.093  1.99  636  6.292  1.505088\n",
      "11  8.792  7.302  9.057  2.11  670  7.037  1.938276\n",
      "12  9.446  7.855  9.742  2.19  695  7.560  2.405268\n",
      "13  8.669  7.198  8.928  2.09  634  6.938  2.019600\n",
      "14  6.688  5.500  6.864  1.83  497  5.324  0.753840\n",
      "15  3.562  2.751  3.632  1.39  302  2.681  0.000000\n",
      "16  0.000  0.000  0.000  0.00   91  0.000  0.000000\n",
      "17  0.000  0.000  0.000  0.00    2  0.000  0.000000\n",
      "18  0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "19  0.000  0.000  0.000  0.00    0  0.000  0.000000\n",
      "X_train_m1 shape: (7008, 6)\n",
      "y_train_m1 shape: (7008,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data_m1 = pd.read_excel('data/M1.xlsx')\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X_m1 = data_m1.drop('WPR', axis=1)\n",
    "y_m1 = data_m1['WPR']\n",
    "\n",
    "# Show the first 20 rows of the data\n",
    "print(data_m1.head(20))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_m1, X_test_m1, y_train_m1, y_test_m1 = train_test_split(X_m1, y_m1, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train_m1 shape:\", X_train_m1.shape)\n",
    "print(\"y_train_m1 shape:\", y_train_m1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 16:50:59.537177: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-02 16:51:01.237284: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-02 16:51:01.243315: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-02 16:51:11.076815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_m1_lstm shape: (7008, 1, 6)\n",
      "X_test_m1_lstm shape: (1752, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_m1_scaled = scaler.fit_transform(X_train_m1)\n",
    "X_test_m1_scaled = scaler.transform(X_test_m1)\n",
    "\n",
    "# Reshape the input to be 3D [samples, timesteps, features]\n",
    "X_train_m1_lstm = np.reshape(X_train_m1_scaled, (X_train_m1_scaled.shape[0], 1, X_train_m1_scaled.shape[1]))\n",
    "X_test_m1_lstm = np.reshape(X_test_m1_scaled, (X_test_m1_scaled.shape[0], 1, X_test_m1_scaled.shape[1]))\n",
    "\n",
    "print(\"X_train_m1_lstm shape:\", X_train_m1_lstm.shape)\n",
    "print(\"X_test_m1_lstm shape:\", X_test_m1_lstm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 16:51:16.875057: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 18s 38ms/step - loss: 0.8273 - val_loss: 0.6503\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 0.7607 - val_loss: 0.6636\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 0.7555 - val_loss: 0.6556\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 4s 19ms/step - loss: 0.7531 - val_loss: 0.6446\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.7507 - val_loss: 0.6512\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.7507 - val_loss: 0.6419\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.7475 - val_loss: 0.6384\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.7398 - val_loss: 0.6362\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.7409 - val_loss: 0.6378\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.7425 - val_loss: 0.6298\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.7292 - val_loss: 0.6489\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.7259 - val_loss: 0.6234\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.7189 - val_loss: 0.6217\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.7098 - val_loss: 0.6189\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.7133 - val_loss: 0.6428\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.7032 - val_loss: 0.6197\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 8s 34ms/step - loss: 0.7095 - val_loss: 0.6321\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.7041 - val_loss: 0.6182\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.7011 - val_loss: 0.6214\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.7079 - val_loss: 0.6188\n",
      "219/219 [==============================] - 5s 9ms/step\n",
      "55/55 [==============================] - 4s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build the baseline LSTM model\n",
    "baseline_lstm_model = Sequential()\n",
    "\n",
    "# Add the LSTM layer\n",
    "baseline_lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_m1_lstm.shape[1], X_train_m1_lstm.shape[2])))\n",
    "baseline_lstm_model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
    "\n",
    "# Add another LSTM layer\n",
    "baseline_lstm_model.add(LSTM(units=50, return_sequences=False))\n",
    "baseline_lstm_model.add(Dropout(0.2))\n",
    "\n",
    "# Add the output layer\n",
    "baseline_lstm_model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "baseline_lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the baseline LSTM model\n",
    "baseline_lstm_model.fit(X_train_m1_lstm, y_train_m1, epochs=20, batch_size=32, validation_data=(X_test_m1_lstm, y_test_m1), verbose=1)\n",
    "\n",
    "# Predict on the training and test data\n",
    "y_train_pred_lstm_baseline = baseline_lstm_model.predict(X_train_m1_lstm)\n",
    "y_test_pred_lstm_baseline = baseline_lstm_model.predict(X_test_m1_lstm)\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "baseline_lstm_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_lstm_baseline.flatten()})\n",
    "baseline_lstm_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_lstm_baseline.flatten()})\n",
    "\n",
    "baseline_lstm_train_results.to_excel('outputs/baseline_lstm_train_predictions.xlsx', index=False)\n",
    "baseline_lstm_test_results.to_excel('outputs/baseline_lstm_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 2ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 3s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 2s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 3s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 2s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 1ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "Stopping search: maximum iterations reached --> 10\n",
      "Optimized Parameters (PSO): lstm_units = 100, dropout_rate = 0.1, learning_rate = 0.009061625299078394, batch_size = 52\n",
      "Best MSE achieved: 0.594499901737335\n"
     ]
    }
   ],
   "source": [
    "from pyswarm import pso  # This is a placeholder, replace with actual PSO implementation\n",
    "\n",
    "# Define the fitness function for LSTM model\n",
    "def lstm_fitness_function(params):\n",
    "    # Unpack parameters\n",
    "    lstm_units = int(params[0])\n",
    "    dropout_rate = params[1]\n",
    "    learning_rate = params[2]\n",
    "    batch_size = int(params[3])\n",
    "    \n",
    "    # Build the LSTM model with the parameters\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True, input_shape=(X_train_m1_lstm.shape[1], X_train_m1_lstm.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_m1_lstm, y_train_m1, epochs=10, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_pred = model.predict(X_test_m1_lstm)\n",
    "    mse = mean_squared_error(y_test_m1, y_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Set the bounds for parameters: [lstm_units, dropout_rate, learning_rate, batch_size]\n",
    "bounds = ([10, 0.1, 0.0001, 16], [100, 0.5, 0.01, 128])\n",
    "\n",
    "# Run the PSO\n",
    "best_params, best_mse = pso(lstm_fitness_function, bounds[0], bounds[1], swarmsize=20, maxiter=10)\n",
    "\n",
    "print(f'Optimized Parameters (PSO): lstm_units = {int(best_params[0])}, dropout_rate = {best_params[1]}, learning_rate = {best_params[2]}, batch_size = {int(best_params[3])}')\n",
    "print(f'Best MSE achieved: {best_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "135/135 [==============================] - 5s 7ms/step - loss: 0.7916\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.7636\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 1s 8ms/step - loss: 0.7624\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.7411\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.7196\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.7210\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.7185\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.7012\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.6979\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.6895\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.6919\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 1s 9ms/step - loss: 0.6982\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.6971\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.6800\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.6894\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.6936\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.6847\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.6828\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.6849\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.6931\n",
      "219/219 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model with the optimized parameters\n",
    "optimized_lstm_model = Sequential()\n",
    "optimized_lstm_model.add(LSTM(units=int(best_params[0]), return_sequences=True, input_shape=(X_train_m1_lstm.shape[1], X_train_m1_lstm.shape[2])))\n",
    "optimized_lstm_model.add(Dropout(best_params[1]))\n",
    "optimized_lstm_model.add(LSTM(units=int(best_params[0])))\n",
    "optimized_lstm_model.add(Dropout(best_params[1]))\n",
    "optimized_lstm_model.add(Dense(1))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=best_params[2])\n",
    "optimized_lstm_model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the optimized model\n",
    "optimized_lstm_model.fit(X_train_m1_lstm, y_train_m1, epochs=20, batch_size=int(best_params[3]), verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_lstm_optimized = optimized_lstm_model.predict(X_train_m1_lstm)\n",
    "y_test_pred_lstm_optimized = optimized_lstm_model.predict(X_test_m1_lstm)\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_lstm_train_results = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_lstm_optimized.flatten()})\n",
    "optimized_lstm_test_results = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_lstm_optimized.flatten()})\n",
    "\n",
    "optimized_lstm_train_results.to_excel('outputs/optimized_lstm_train_predictions_pso.xlsx', index=False)\n",
    "optimized_lstm_test_results.to_excel('outputs/optimized_lstm_test_predictions_pso.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 2s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step0.0% GA is running\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step0.0% GA is ru\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 2s 3ms/step0.0% GA is ru\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 3ms/step0.0% GA is run\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 2ms/step\n",
      "55/55 [==============================] - 1s 4ms/step0.0% GA is \n",
      "55/55 [==============================] - 4s 4ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 3s 5ms/step\n",
      "55/55 [==============================] - 2s 4ms/step0.0% GA is \n",
      "55/55 [==============================] - 3s 5ms/step\n",
      "55/55 [==============================] - 1s 3ms/step\n",
      "55/55 [==============================] - 1s 4ms/step\n",
      "55/55 [==============================] - 2s 5ms/step0.0% GA is \n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 5ms/step\n",
      "55/55 [==============================] - 4s 6ms/step\n",
      "55/55 [==============================] - 5s 7ms/step0.0% GA\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 6ms/step0.0% GA\n",
      "55/55 [==============================] - 3s 4ms/step\n",
      "55/55 [==============================] - 5s 9ms/step\n",
      "55/55 [==============================] - 5s 7ms/step\n",
      "55/55 [==============================] - 4s 6ms/step00.0% GA i\n",
      "55/55 [==============================] - 3s 6ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      " The best solution found:                                                                           \n",
      " [7.64298769e+01 2.52903339e-01 5.37689269e-03 2.05149947e+01]\n",
      "\n",
      " Objective function:\n",
      " 0.5964973436092521\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAHFCAYAAAA5VBcVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABemklEQVR4nO3deVxU9f4/8NfMwMwgyyggOw6IoCCaCmpquaW4tagZmF3X22KaSaSlmb/ccSm1TdNvLlmW3FLMq+kVN5TUMnfFHZRFEEFh2Lc5vz+QyXEAZyZwYHg9H495XOczn3POe47d5tXnfM7niARBEEBEREREBhObugAiIiKihopBioiIiMhIDFJERERERmKQIiIiIjISgxQRERGRkRikiIiIiIzEIEVERERkJAYpIiIiIiMxSBEREREZiUGKiKp07tw5/Pvf/4aPjw+srKxgZWUFX19fvPXWW/jrr79MXZ7Gb7/9hjlz5lT5mZeXF8aNG1frx+zUqRNEIhE+/fTTKj/fuHEjRCIRbt68WevH1sfNmzchEomwceNGTdvRo0cxZ84cZGdn6/T38vLC888//+QKJDIjDFJEpGPNmjUICgrCH3/8galTp2Lnzp3YtWsXwsPDcfHiRXTu3Bk3btwwdZkAKoLU3Llzq/wsOjoas2fPrtXjnTlzBqdPnwYArFu3rlb3XVtcXV1x7NgxDBkyRNN29OhRzJ07t8ogRUTGszB1AURUv/z++++YNGkShgwZgl9++QVSqVTzWd++fTF58mT8/PPPsLKyMmGV+unYsWOt7/Pbb78FAAwZMgS7du3C0aNH0b1791o/jjHKy8tRVlYGmUyGp59+2tTlEDUKHJEiIi2LFi2CRCLBmjVrtELUw1555RW4ublptf3111948cUXYW9vD7lcjo4dO+I///mPVp/KS14HDx7E22+/DUdHRzg4OGD48OG4ffu2znGioqLQrVs3WFtbw8bGBgMGDNCMBgHAuHHj8PXXXwMARCKR5lV5Sa2qS3vZ2dl4//330bJlS8hkMjg5OWHw4MG4fPnyY89NUVERfvzxRwQFBWHFihUAgPXr1z92OwAQBAGLFi2CUqmEXC5HcHAwYmJi0Lt3b/Tu3Vurb1JSEv71r3/ByckJMpkM/v7++Oyzz6BWqzV9Ki/fLV26FAsWLIC3tzdkMhkOHjyoc2lvzpw5mD59OgDA29tbc54OHTqkddw9e/agU6dOsLKyQps2bXS+W+Xf34EDB/DGG2/AwcEBdnZ2GDNmDPLz85Geno7Q0FA0bdoUrq6umDZtGkpLS/U6P0QNFUekiEijvLwcBw8eRHBwMFxdXfXe7uDBgxg4cCC6du2Kb775BgqFAlu2bEFYWBgKCgp0wszrr7+OIUOG4Mcff0RycjKmT5+Of/3rXzhw4ICmz6JFi/Dxxx9j/Pjx+Pjjj1FSUoJly5bh2WefxZ9//omAgADMnj0b+fn5+OWXX3Ds2DHNttXVnpubi2eeeQY3b97Ehx9+iK5duyIvLw+HDx9GWloa2rRpU+P33LZtG+7fv48JEybA19cXzzzzDKKiorBy5UrY2NjUuO2sWbMQGRmJN998E8OHD0dycjJef/11lJaWws/PT9Pv7t276N69O0pKSjB//nx4eXlh586dmDZtGm7cuIFVq1Zp7feLL76An58fPv30U9jZ2cHX11fn2K+//jru3buHL7/8Etu2bdOcn4CAAE2fs2fP4v3338eMGTPg7OyMb7/9Fv/+97/RqlUr9OzZU2d/w4cPx5YtW3D69Gl89NFHKCsrw5UrVzB8+HC8+eab2LdvH5YsWQI3NzdERETUeG6IGjSBiOiB9PR0AYAwcuRInc/KysqE0tJSzUutVms+a9OmjdCxY0ehtLRUa5vnn39ecHV1FcrLywVBEIQNGzYIAIRJkyZp9Vu6dKkAQEhLSxMEQRCSkpIECwsLYcqUKVr9cnNzBRcXFyE0NFTTNnnyZKG6f5UplUph7Nixmvfz5s0TAAgxMTF6nA1dffv2FeRyuXD//n2t77Nu3TqtfpXtiYmJgiAIwr179wSZTCaEhYVp9Tt27JgAQOjVq5embcaMGQIA4Y8//tDq+/bbbwsikUi4cuWKIAiCkJiYKAAQfHx8hJKSEq2+lZ9t2LBB07Zs2TKtmh6mVCoFuVwu3Lp1S9NWWFgo2NvbC2+99ZbO93r072Xo0KECAGH58uVa7R06dBA6deqkczwic8JLe0Skl6CgIFhaWmpen332GQDg+vXruHz5Ml577TUAQFlZmeY1ePBgpKWl4cqVK1r7evHFF7Xet2/fHgBw69YtAMD//vc/lJWVYcyYMVr7k8vl6NWrl84lKX3t3r0bfn5+6Nevn8HbJiYm4uDBgxg+fDiaNm0KoOISp62t7WMv7x0/fhzFxcUIDQ3Van/66afh5eWl1XbgwAEEBASgS5cuWu3jxo2DIAhao3ZAxbm0tLQ0+Ps8qkOHDmjRooXmvVwuh5+fn+bv5GGP3uHn7+8PAFqT2yvbq9qeyJzw0h4RaTg6OsLKyqrKH78ff/wRBQUFSEtL0wpCd+7cAQBMmzYN06ZNq3K/mZmZWu8dHBy03stkMgBAYWGh1j47d+5c5f7EYuP+G/Du3btaYcEQ69evhyAIGDFihNadby+++CI2b96My5cvV3tpMCsrCwDg7Oys89mjbVlZWTrhCoBmTlrlvioZcgm2Jo/+nQAVfy+VfycPs7e313pfOZeuqvaioqJaqY+ovmKQIiINiUSCvn37Yu/evUhLS9P6ka6cT/Po2kiOjo4AgJkzZ2L48OFV7rd169YG1VG5z19++QVKpdKgbWvSvHlzpKSkGLydWq3WTNyu7juuX78eS5curfKzypBSGRAflp6erhWcHBwckJaWptOvcjJ+5bmpJBKJHls/EdUdXtojIi0zZ85EeXk5Jk6cqNcdV61bt4avry/Onj2L4ODgKl+2trYG1TBgwABYWFjgxo0b1e6z0qOjWTUZNGgQrl69qnN57HH+97//ISUlBZMnT8bBgwd1Xm3btsWmTZtQVlZW5fZdu3aFTCZDVFSUVvvx48d1Rv+ee+45xMfH49SpU1rtmzZtgkgkQp8+fQyqvZIh54mI9McRKSLS0qNHD3z99deYMmUKOnXqhDfffBNt27aFWCxGWloatm7dCgCws7PTbLNmzRoMGjQIAwYMwLhx4+Du7o579+7h0qVLOHXqFH7++WeDavDy8sK8efMwa9YsJCQkYODAgWjWrBnu3LmDP//8E9bW1ppFONu1awcAWLJkCQYNGgSJRIL27dtXuXRDeHg4oqKi8NJLL2HGjBno0qULCgsLERsbi+eff77akLJu3TpYWFjgo48+0ln2AQDeeustvPvuu9i1axdeeuklnc/t7e0RERGByMhINGvWDMOGDUNKSgrmzp0LV1dXrUuV7733HjZt2oQhQ4Zg3rx5UCqV2LVrF1atWoW3335b6w4/Q1Sep88//xxjx46FpaUlWrdubXDIJaJHmHq2OxHVT2fOnBHGjx8veHt7CzKZTJDL5UKrVq2EMWPGCPv379fpf/bsWSE0NFRwcnISLC0tBRcXF6Fv377CN998o+lTedfXiRMntLY9ePCgAEA4ePCgVvv27duFPn36CHZ2doJMJhOUSqUwYsQIYd++fZo+xcXFwuuvvy40b95cEIlEWnemPXrXniAIwv3794WpU6cKLVq0ECwtLQUnJydhyJAhwuXLl6s8D3fv3hWkUqkwdOjQas/V/fv3BSsrK+GFF17Q+p4P3yGnVquFBQsWCB4eHoJUKhXat28v7Ny5U3jqqaeEYcOGae3v1q1bwqhRowQHBwfB0tJSaN26tbBs2TLN3Y+C8PedecuWLdOpp6q79gRBEGbOnCm4ubkJYrFY63wrlUphyJAhOvvp1auX1h2F1f39ffLJJwIA4e7du1rtY8eOFaytras9b0TmQCQIgmCyFEdE1IglJiaiTZs2+OSTT/DRRx+ZuhwiMgKDFBHRE3D27Fn89NNP6N69O+zs7HDlyhUsXboUKpUKFy5cqPKOPiKq/zhHiojoCbC2tsZff/2FdevWITs7GwqFAr1798bChQsZoogaMI5IERERERmJyx8QERERGYlBioiIiMhIDFJERERERuJk8zqkVqtx+/Zt2Nra8jEOREREDYQgCMjNzYWbm9tjn+3JIFWHbt++DU9PT1OXQUREREZITk6Gh4dHjX0YpOpQ5aMXkpOTtR6nQURERPWXSqWCp6enXo9QYpCqQ5WX8+zs7BikiIiIGhh9puVwsjkRERGRkRikiIiIiIzEIEVERERkJAYpIiIiIiMxSBEREREZiUGKiIiIyEgMUkRERERGYpAiIiIiMhKDFBEREZGRGKSIiIiIjMQgRURERGQkBikiIiIiIzFINUD380uQlFWAotJyU5dCRETUqFmYugAyXPTpVMzbGQ8AUFhZwtlOBmc7+YNXxZ+dbCv+7KKQw9FGBksJMzMREVFtY5BqgIrL1JBbilFUqkZOYSlyCktx9U5etf1FIsDBWvZQ4NIOXhWhSw4HaynEYtET/CZEREQNm0gQBMHURZgrlUoFhUKBnJwc2NnZ1eq+BUGAqqgMGaoi3FEV446qCOmqor/f5xYh40F7mVq/v2ILsQhOtjI46YSth97bymFnZQGRiIGLiIjMkyG/3xyRaqBEIhEUVpZQWFnC19m22n5qtYB7BSW4o/o7WN1RFf8dunIr3mfmFaNMLeB2ThFu5xTVeGyZhRjOdnK42Mnh9Mgol5OtHC6KivdNpPzHi4iIzBt/6cycWCyCo40MjjYytHWrvl9ZuRqZeSVIVxU9CF2PjnRVjHJlF5SiuEyNpHsFSLpXUOOxbWUWDwWtipfSoQlaOlqjZXMbONpIObJFREQNGoMUAQAsJGK4KCpGk2pSVFqOu7l/B6w7quIHoUs7eBWUlCO3uAy5d8tw425+lfuylVugZXMb+DS3hk9zG03AUjo0gdxSUhdfk4iIqFYxSJFB5JYSeNo3gad9kxr75RWXPQhXFaNZ6aoipOcUITEzHwmZeUi5X4jcojKcTc7G2eRsrW3FIsC9mdWDcGWDls2t0fJB2HKylXEUi4iI6g2TTzZftWoVli1bhrS0NLRt2xYrV67Es88+W23/4uJizJs3Dz/88APS09Ph4eGBWbNmYcKECQCAixcv4v/9v/+HkydP4tatW1ixYgXCw8O19hEZGYlt27bh8uXLsLKyQvfu3bFkyRK0bt1a02fcuHH47rvvtLbr2rUrjh8/rvd3q8vJ5g1dUWk5bmUV4MbdPCTczUPC3XzcyMxHwt085BaVVbudjcwC3o7W8GleMXrVsrk1WjrawNvRGlZSjmIREdE/12Amm0dFRSE8PByrVq1Cjx49sGbNGgwaNAjx8fFo0aJFlduEhobizp07WLduHVq1aoWMjAyUlf39w1tQUICWLVvilVdewXvvvVflPmJjYzF58mR07twZZWVlmDVrFkJCQhAfHw9ra2tNv4EDB2LDhg2a91KptJa+OcktJWjtYovWLtoT5QVBQGZeyYOAVRGsEh4ErKR7BcgrLsP51BycT83R2ad7UyvNyFVlwGrZ3BquCjlHsYiIqE6YdESqa9eu6NSpE1avXq1p8/f3x9ChQxEZGanTf8+ePRg5ciQSEhJgb2//2P17eXkhPDxcZ0TqUXfv3oWTkxNiY2PRs2dPABUjUtnZ2di+fbtB3+lhHJGqXcVl5UjKKsCNuxWXByuD1o27+cgpLK12uyZSCbwfzL+qmIdVEba8Ha1hLePVbSIi0tYgRqRKSkpw8uRJzJgxQ6s9JCQER48erXKbHTt2IDg4GEuXLsX3338Pa2trvPjii5g/fz6srKyMriUnp2J049FwdujQITg5OaFp06bo1asXFi5cCCcnJ6OPQ/+MzEICX2dbneUeBEHAvfwSzchVwt18TdhKyipAQUk5Lt5W4eJtlc4+XRVyrdGryrDl3tSKi5MSEdFjmSxIZWZmory8HM7Ozlrtzs7OSE9Pr3KbhIQExMXFQS6XIzo6GpmZmZg0aRLu3buH9evXG1WHIAiIiIjAM888g8DAQE37oEGD8Morr0CpVCIxMRGzZ89G3759cfLkSchksir3VVxcjOLiYs17lUr3h5tqn0gkgoONDA42MnT20g7DpeUVSzVoLhM+CFg37ubjXn4J0nKKkJZThN+vZ2ltJ7cUw8uhYuTKpgGOWonFIkglIlhKxLC0EMNSIobMQgzLyjaJGFKJGJYWj7yXPOhj8ch7iRhSi0feS8QMm0TU6Jn8F+LRuSuCIFQ7n0WtVkMkEmHz5s1QKBQAgOXLl2PEiBH4+uuvjRqVeuedd3Du3DnExcVptYeFhWn+HBgYiODgYCiVSuzatQvDhw+vcl+RkZGYO3euwTVQ3bGUiOHT3AY+zW0AaIf27IKSipGrh+Zh3bibj1tZ+SgqVeNyei4up+eapvAGQiIWaQUry4fC2cNBrDKE/d3nQbumjxgN8XGQ9tYydGrRFO09mvJmB6JGymRBytHRERKJRGf0KSMjQ2eUqpKrqyvc3d01IQqomFMlCAJSUlLg6+trUA1TpkzBjh07cPjwYXh4eNTY19XVFUqlEteuXau2z8yZMxEREaF5r1Kp4OnpaVBN9OQ0bSJFkFKKIGUzrfaycjVS7hciITMPiZkFKCotN1GFxitXCygtV6OkXI3Ssoo/a96XCygte/j9g7ZyNUrKtN//3Vbx/tHHDZWrBZSrBRSVqk30TesHC7EIAW526NSiGTq2aIogZTO4N7XiTQ5EjYDJgpRUKkVQUBBiYmIwbNgwTXtMTAxeeumlKrfp0aMHfv75Z+Tl5cHGxgYAcPXqVYjF4scGoYcJgoApU6YgOjoahw4dgre392O3ycrKQnJyMlxdXavtI5PJqr3sRw2HhUQML0dreDlaP75zI6NWCyhVVxXG/g5iFeHtoTZNWKsIdVrvywXNNuqG9thPAUi5X4iTt+4jXVWEcyk5OJeSg40Ppng62coQpGyGTi2aoZOyGQLd7SCz4KgVkbkx6aW9iIgIjB49GsHBwejWrRvWrl2LpKQkTJw4EUDFCE9qaio2bdoEABg1ahTmz5+P8ePHY+7cucjMzMT06dMxYcIEzWW9kpISxMfHa/6cmpqKM2fOwMbGBq1atQIATJ48GT/++CN+/fVX2NraakbFFAoFrKyskJeXhzlz5uDll1+Gq6srbt68iY8++giOjo5aoY+osRGLRZCJJZBZAOB/M2jczq4IVKeS7uPUrfu4eFuFjNxi7L6Qjt0XKv79IpWI0dbdDkEPglWQshmc7Wp+kgAR1X/1YkHOpUuXIi0tDYGBgVixYoXWEgQ3b97EoUOHNP0vX76MKVOm4Pfff4eDgwNCQ0OxYMECTZC6efNmlSNMvXr10uynuuH2DRs2YNy4cSgsLMTQoUNx+vRpZGdnw9XVFX369MH8+fMNulTH5Q+IGqei0nKcS8nRBKtTSfeRmVei08+9qRU6KZuhU4um6NSiGQLc7GDZECeLEZkZQ36/TR6kzBmDFBEBFdMJku8V4mTSPZy6lY1TSfdxKU2FR6acQW4pRnv3pn+HK2UzONpw6I/oSWOQqicYpIioOvnFZTibkv1gxKoiXGUX6C4sq3Roopln1alFU7R2toUFR62I6hSDVD3BIEVE+hIEAQmZ+ZpLgaduZeNqRi4e/Te0tVSCpzwrLgUGKSvuEmzahI+vIqpNDFL1BIMUEf0TqqJSnEnK1kxkP5OUjdxi3Yd6+zS31oxaBSmboVVzGy6WSvQPMEjVEwxSRFSbytUCrmfk4VTSfU24Sribr9PPVm6Bji3+nsTeoUVT2MktTVAxUcPEIFVPMEgRUV27n1+C08kPgtWtbJxNyUZBifYisiIR4Odki07KZujn74Tn/Kte9JiIKjBI1RMMUkT0pJWVVzze6LRm1CobSfcKtPrETu8NpQMXnCWqjiG/3yZ/1h4REdUeC4kYge4KBLorMLqbFwDgbm4xTiXdx5Ldl5GQmY/TSdkMUkS1hPfQEhGZuea2Mgxo64Kefs0BAOdTc0xcEZH5YJAiImokAt0rHvjOIEVUexikiIgaiXYPglT8bRXUjy6rTkRGYZAiImokfJpbQ24pRl5xGW5m6S6bQESGY5AiImokLCRi+LtW3IHEy3tEtYNBioioEam8vHeBQYqoVjBIERE1IpxwTlS7GKSIiBqRQLeKIHUxlRPOiWoDgxQRUSPi62wDqYUYucVlOiueE5HhGKSIiBoRS044J6pVDFJERI1MO/eKIMUJ50T/HIMUEVEjUzlP6sJtBimif4pBioiokQnULIGggiBwwjnRP8EgRUTUyPg520IqESOnsBTJ9wpNXQ5Rg8YgRUTUyEgtxGjjaguAE86J/ikGKSKiRqgt50kR1QoGKSKiRoiPiiGqHQxSRESNULuHHhXDCedExmOQIiJqhPxcbGApESG7oBQp9znhnMhYDFJERI2QzEICP+eKCecXOU+KyGgMUkREjdTDl/eIyDgMUkREjVSgJkipTFwJUcPFIEVE1Eg9fOceJ5wTGYdBioiokWrtYgsLsQj38kuQllNk6nKIGiQGKSKiRkpuKYGvM1c4J/onGKSIiBqxdu52ALgwJ5GxGKSIiBox3rlH9M8wSBERNWJtOeGc6B9hkCIiasQCXO0gEYuQmVeCO6piU5dD1OAwSBERNWJySwl8nWwA8PIekTEYpIiIGrlAzpMiMhqDFBFRIxfoVnHn3kUGKSKDMUgRETVy7Tw4IkVkLJMHqVWrVsHb2xtyuRxBQUE4cuRIjf2Li4sxa9YsKJVKyGQy+Pj4YP369ZrPL168iJdffhleXl4QiURYuXKlUccVBAFz5syBm5sbrKys0Lt3b1y8ePEff18iovomwFUBsQjIyC1GhoornBMZwqRBKioqCuHh4Zg1axZOnz6NZ599FoMGDUJSUlK124SGhmL//v1Yt24drly5gp9++glt2rTRfF5QUICWLVti8eLFcHFxMfq4S5cuxfLly/HVV1/hxIkTcHFxQf/+/ZGbm1t7J4CIqB6wkkrQihPOiYwjmFCXLl2EiRMnarW1adNGmDFjRpX9d+/eLSgUCiErK0uv/SuVSmHFihUGH1etVgsuLi7C4sWLNZ8XFRUJCoVC+Oabb/Q6tiAIQk5OjgBAyMnJ0XsbIiJTeG/LaUH54U5hZcxVU5dCZHKG/H6bbESqpKQEJ0+eREhIiFZ7SEgIjh49WuU2O3bsQHBwMJYuXQp3d3f4+flh2rRpKCwsrNXjJiYmIj09XauPTCZDr169qq2NiKgh4517RMaxMNWBMzMzUV5eDmdnZ612Z2dnpKenV7lNQkIC4uLiIJfLER0djczMTEyaNAn37t3Tmif1T49b+b9V9bl161a1+y4uLkZx8d8L2qlUKr1qIiIytcoJ53zmHpFhTD7ZXCQSab0XBEGnrZJarYZIJMLmzZvRpUsXDB48GMuXL8fGjRsNGpXS97iG1AYAkZGRUCgUmpenp6dBNRERmUqAqx1EIiBdVYS7uVzhnEhfJgtSjo6OkEgkOqNPGRkZOiNBlVxdXeHu7g6FQqFp8/f3hyAISElJqbXjVk5SN6Q2AJg5cyZycnI0r+TkZL1qIiIyNWuZBVo6WgMALtzmqBSRvkwWpKRSKYKCghATE6PVHhMTg+7du1e5TY8ePXD79m3k5eVp2q5evQqxWAwPD49aO663tzdcXFy0+pSUlCA2Nrba2oCKeVR2dnZaLyKihqJd5QOMUxikiPRl0kt7ERER+Pbbb7F+/XpcunQJ7733HpKSkjBx4kQAFSM8Y8aM0fQfNWoUHBwcMH78eMTHx+Pw4cOYPn06JkyYACsrKwAVgefMmTM4c+YMSkpKkJqaijNnzuD69et6H1ckEiE8PByLFi1CdHQ0Lly4gHHjxqFJkyYYNWrUEzxDRERPDiecExnOZJPNASAsLAxZWVmYN28e0tLSEBgYiN9++w1KpRIAkJaWprW2k42NDWJiYjBlyhQEBwfDwcEBoaGhWLBggabP7du30bFjR837Tz/9FJ9++il69eqFQ4cO6XVcAPjggw9QWFiISZMm4f79++jatSv27t0LW1vbOj4rRESmURmkOOGcSH8iQRAEUxdhrlQqFRQKBXJycniZj4jqvdyiUrSbsxcAcPLjfnCwkZm4IiLTMOT32+R37RERUf1gK7d8aMI5l28h0geDFBERafDyHpFhGKSIiEgj0L3iMsZ53rlHpBcGKSIi0tCMSHEtKSK9MEgREZFGZZBKuV+I+/klJq6GqP5jkCIiIg07uSW8HJoA4KgUkT4YpIiISEtbLsxJpDcGKSIi0lL5qJiLqVwCgehxGKSIiEhLO45IEemNQYqIiLQEulUEqaR7BcgpKDVxNUT1G4MUERFpUTSxhKd9xYPgOeGcqGYMUkREpKMdVzgn0guDFBER6QjkPCkivTBIERGRDo5IEemHQYqIiHRUTji/mVUAVREnnBNVh0GKiIh0NLOWwr1pxYRzridFVD0GKSIiqhIv7xE9HoMUERFVqZ0HJ5wTPQ6DFBERVamtmx0AjkgR1YRBioiIqlR5aS8hMx+5nHBOVCUGKSIiqpKDjQxuCjkAIP42J5wTVYVBioiIqsWFOYlqxiBFRETVCuSde0Q1YpAiIqJqaZZA4KU9oioxSBERUbUqR6Ru3M1DfnGZiashqn8YpIiIqFrNbWVwsZNDEID4NI5KET2KQYqIiGoU6F6xntT5FM6TInoUgxQREdWIE86JqscgRURENfp7wjmDFNGjGKSIiKhGlUHqekYeCko44ZzoYQxSRERUIyc7OZrbyqAWgEuccE6khUGKiIgeq3JUihPOibQxSBER0WMFcmFOoioxSBER0WO14517RFVikCIioseqXEvqWkYeikrLTVwNUf3BIEVERI/lYieHo40U5WqBK5wTPYRBioiIHkskEmnmSV3k5T0iDQYpIiLSi+bOPQYpIg0GKSIi0ktbt8ogxUt7RJUMDlJ37tzB6NGj4ebmBgsLC0gkEq0XERGZp3YeFUHq2p1cTjgnesDgIDVu3DicOnUKs2fPxi+//IJt27ZpvQy1atUqeHt7Qy6XIygoCEeOHKmxf3FxMWbNmgWlUgmZTAYfHx+sX79eq8/WrVsREBAAmUyGgIAAREdHa33u5eUFkUik85o8ebLW93z086efftrg70dEZC7cFHLYW0tRphZwJT3X1OUQ1QsWhm4QFxeHI0eOoEOHDv/44FFRUQgPD8eqVavQo0cPrFmzBoMGDUJ8fDxatGhR5TahoaG4c+cO1q1bh1atWiEjIwNlZX8/++nYsWMICwvD/PnzMWzYMERHRyM0NBRxcXHo2rUrAODEiRMoL//7v6YuXLiA/v3745VXXtE61sCBA7FhwwbNe6lU+o+/MxFRQ1U54fzw1bs4n5qDpzybmrokIpMTCYIgGLJBQEAANm/ejI4dO/7jg3ft2hWdOnXC6tWrNW3+/v4YOnQoIiMjdfrv2bMHI0eOREJCAuzt7avcZ1hYGFQqFXbv3q1pGzhwIJo1a4affvqpym3Cw8Oxc+dOXLt2DSKRCEDFiFR2dja2b99u9PdTqVRQKBTIycmBnZ2d0fshIqovlu65jFWHbmBkZ08sfrm9qcshqhOG/H4bfGlv5cqVmDFjBm7evGlsfQCAkpISnDx5EiEhIVrtISEhOHr0aJXb7NixA8HBwVi6dCnc3d3h5+eHadOmobCwUNPn2LFjOvscMGBAtfssKSnBDz/8gAkTJmhCVKVDhw7ByckJfn5+eOONN5CRkVHjdyouLoZKpdJ6ERGZE965R6TN4Et7YWFhKCgogI+PD5o0aQJLS0utz+/du6fXfjIzM1FeXg5nZ2etdmdnZ6Snp1e5TUJCAuLi4iCXyxEdHY3MzExMmjQJ9+7d08yTSk9PN2if27dvR3Z2NsaNG6fVPmjQILzyyitQKpVITEzE7Nmz0bdvX5w8eRIymazKfUVGRmLu3Ln6fH0iogapci2pq3dyUVxWDpkFbzKixs3gILVy5cpaLeDRUSBBEHTaKqnVaohEImzevBkKRcX/mZcvX44RI0bg66+/hpWVlcH7XLduHQYNGgQ3Nzet9rCwMM2fAwMDERwcDKVSiV27dmH48OFV7mvmzJmIiIjQvFepVPD09KyyLxFRQ+TRzApNm1giu6AUV9PzNHfyETVWBgepsWPH1sqBHR0dIZFIdEaKMjIydEaUKrm6usLd3V0TooCKOVWCICAlJQW+vr5wcXHRe5+3bt3Cvn379Lrb0NXVFUqlEteuXau2j0wmq3a0iojIHIhEIgS6KRB3PRPnU3MYpKjRM2pBzvLycmzduhULFizAwoULER0drXUXnD6kUimCgoIQExOj1R4TE4Pu3btXuU2PHj1w+/Zt5OXladquXr0KsVgMDw8PAEC3bt109rl3794q97lhwwY4OTlhyJAhj603KysLycnJcHV1fWxfIiJzFsh5UkQaBo9IXb9+HYMHD0Zqaipat24NQRBw9epVeHp6YteuXfDx8dF7XxERERg9ejSCg4PRrVs3rF27FklJSZg4cSKAiktlqamp2LRpEwBg1KhRmD9/PsaPH4+5c+ciMzMT06dPx4QJEzSX9aZOnYqePXtiyZIleOmll/Drr79i3759iIuL0zq2Wq3Ghg0bMHbsWFhYaJ+GvLw8zJkzBy+//DJcXV1x8+ZNfPTRR3B0dMSwYcMMPWVERGalcsL5xdsMUkQGj0i9++678PHxQXJyMk6dOoXTp08jKSkJ3t7eePfddw3aV1hYGFauXIl58+ahQ4cOOHz4MH777TcolUoAQFpaGpKSkjT9bWxsEBMTg+zsbAQHB+O1117DCy+8gC+++ELTp3v37tiyZQs2bNiA9u3bY+PGjYiKitKsIVVp3759SEpKwoQJE3TqkkgkOH/+PF566SX4+flh7Nix8PPzw7Fjx2Bra2vQdyQiMjeVQepyWi5KytQmrobItAxeR8ra2hrHjx9Hu3bttNrPnj2LHj16aF12a+y4jhQRmSNBEPDU3L1QFZVh55RnNJf6iMxFna4jJZPJkJur+2iAvLw8rvxNRNQIVK5wDgAXOE+KGjmDg9Tzzz+PN998E3/88QcEQYAgCDh+/DgmTpyIF198sS5qJCKieqby8t4FzpOiRs7gIPXFF1/Ax8cH3bp1g1wuh1wuR48ePdCqVSt8/vnndVEjERHVM3/fuccnOFDjZvBde02bNsWvv/6Ka9eu4fLlyxAEAQEBAWjVqlVd1EdERPVQZZC6lKZCabkalhKjVtMhavAMDlKVfH194evrW5u1EBFRA6G0bwJbmQVyi8tw7U4eAtx4Qw01TnoFqYiICMyfPx/W1tZaj0CpyvLly2ulMCIiqr/EYhHautvheMI9XLidwyBFjZZeQer06dMoLS3V/JmIiKidu6IiSKXmIDSYzxWlxkmvIHXw4MEq/0xERI0XHxVDZMRdexMmTKhyHan8/PwqVwknIiLz9PCE87JyrnBOjZPBQeq7775DYWGhTnthYaHmmXhERGT+vB2sYSOzQFGpGjfu5pu6HCKT0PuuPZVKpVmAMzc3F3K5XPNZeXk5fvvtNzg5OdVJkUREVP+IxSIEuNnhz8R7OJ+ag9YufBYpNT56B6mmTZtCJBJBJBLBz89P53ORSIS5c+fWanFERFS/Bbop8GdixYTzEUEepi6H6InTO0gdPHgQgiCgb9++2Lp1K+zt7TWfSaVSKJVKuLm51UmRRERUP7XzqFj2gBPOqbHSO0j16tULAJCYmIgWLVpAJBLVWVFERNQwVD5zL/62CuVqARIxfxuocTF4svmBAwfwyy+/6LT//PPP+O6772qlKCIiahi8HW3QRCpBYWk5Eu7mmbocoifO4CC1ePFiODo66rQ7OTlh0aJFtVIUERE1DBKxCAGuvLxHjZfBQerWrVvw9vbWaVcqlUhKSqqVooiIqOHgwpzUmBkcpJycnHDu3Dmd9rNnz8LBwaFWiiIiooajcp7UxVSViSshevIMDlIjR47Eu+++i4MHD6K8vBzl5eU4cOAApk6dipEjR9ZFjUREVI+183gQpG7nQK0WTFwN0ZOl9117lRYsWIBbt27hueeeg4VFxeZqtRpjxozhHCkiokaopaM15JZi5JeUIyEzH62cbExdEtETY3CQkkqliIqKwvz583H27FlYWVmhXbt2UCqVdVEfERHVcxYSMQJc7XAqKRsXUnMYpKhRMThIVfLz86tyhXMiImp82rkrNEFqaEd3U5dD9MQYHKTKy8uxceNG7N+/HxkZGVCrtZ/4feDAgVorjoiIGgbeuUeNlcFBaurUqdi4cSOGDBmCwMBArnBORESaIHXxtgpqtQAxVzinRsLgILVlyxb85z//weDBg+uiHiIiaoB8nWwgsxAjr7gMN7Py0bI550lR42Dw8gdSqRStWrWqi1qIiKiBspCI4f9ghfMLt7meFDUeBgep999/H59//jkEgWuFEBHR3yoX5rzAeVLUiBh8aS8uLg4HDx7E7t270bZtW1haWmp9vm3btlorjoiIGo5A9wfP3EthkKLGw+Ag1bRpUwwbNqwuaiEiogascsL5hds5EASBNyNRo2BwkNqwYUNd1EFERA2cn7MtpBZi5BaVIeleAZQO1qYuiajOGTxHioiIqCqWEjH8XWwBcD0pajwMHpHy9vaucbg2ISHhHxVEREQNV1t3Bc6m5OB8ag6eb+9m6nKI6pzBQSo8PFzrfWlpKU6fPo09e/Zg+vTptVUXERE1QLxzjxobo1Y2r8rXX3+Nv/766x8XREREDdffQUrFCefUKNTaHKlBgwZh69attbU7IiJqgPycbWEpESGnsBQp9wtNXQ5Rnau1IPXLL7/A3t6+tnZHREQNkNRCjNaccE6NiMGX9jp27Kg1VCsIAtLT03H37l2sWrWqVosjIqKGp527AhdSVTifmoPB7VxNXQ5RnTI4SA0dOlTrvVgsRvPmzdG7d2+0adOmtuoiIqIGqmJhzmROOKdGQa8gFRERgfnz58Pa2hp9+vRBt27ddB4NQ0REBGjfuccJ52Tu9Joj9eWXXyIvLw8A0KdPH9y/f79OiyIioobLz9kWFmIR7heUIjWbE87JvOkVpLy8vPDFF18gNjYWgiDg2LFjOHz4cJUvQ61atQre3t6Qy+UICgrCkSNHauxfXFyMWbNmQalUQiaTwcfHB+vXr9fqs3XrVgQEBEAmkyEgIADR0dFan8+ZMwcikUjr5eLiotVHEATMmTMHbm5usLKyQu/evXHx4kWDvx8RUWMjt5TAz7liwjkv75G50+vS3rJlyzBx4kRERkZCJBJV+9BikUiE8vJyvQ8eFRWF8PBwrFq1Cj169MCaNWswaNAgxMfHo0WLFlVuExoaijt37mDdunVo1aoVMjIyUFZWpvn82LFjCAsLw/z58zFs2DBER0cjNDQUcXFx6Nq1q6Zf27ZtsW/fPs17iUSidZylS5di+fLl2LhxI/z8/LBgwQL0798fV65cga2trd7fkYioMWrnrkB8mgoXUlUYGMgJ52S+RIIgCPp2zsvLg52dHa5cuQInJ6cq+ygUCr0P3rVrV3Tq1AmrV6/WtPn7+2Po0KGIjIzU6b9nzx6MHDkSCQkJ1S61EBYWBpVKhd27d2vaBg4ciGbNmuGnn34CUDEitX37dpw5c6bKfQiCADc3N4SHh+PDDz8EUDES5uzsjCVLluCtt97S6/upVCooFArk5OTAzs5Or22IiMzB98dvYfb2C+jl1xzfTehi6nKIDGLI77dB60jZ2Njg4MGD8Pb2hkKhqPKlr5KSEpw8eRIhISFa7SEhITh69GiV2+zYsQPBwcFYunQp3N3d4efnh2nTpqGw8O9r8MeOHdPZ54ABA3T2ee3aNbi5ucHb21sTziolJiYiPT1daz8ymQy9evWqtjagImypVCqtFxFRYxToVvHjUznhnMhcGbwgZ69evWBhYfCqCToyMzNRXl4OZ2dnrXZnZ2ekp6dXuU1CQgLi4uJw4cIFREdHY+XKlfjll18wefJkTZ/09PTH7rNr167YtGkT/ve//+H//u//kJ6eju7duyMrK0uzj8rt9K0NACIjI7VCpaenpx5ngojI/Pi72kEiFiErvwRpOUWmLoeoztTayubGevS22JpulVWr1RCJRNi8eTO6dOmCwYMHa+YxPTwq9bh9Dho0CC+//DLatWuHfv36YdeuXQCA7777zujaAGDmzJnIycnRvJKTk2v45kRE5ktuKYGvkw0ATjgn82ayIOXo6AiJRKIzwpORkaEzElTJ1dUV7u7uWpcQ/f39IQgCUlJSAAAuLi4G7RMArK2t0a5dO1y7dk2zDwAG70cmk8HOzk7rRUTUWD28nhSRuTJZkJJKpQgKCkJMTIxWe0xMDLp3717lNj169MDt27c1a1oBwNWrVyEWi+Hh4QEA6Natm84+9+7dW+0+gYq5TZcuXYKra8WdJd7e3nBxcdHaT0lJCWJjY2vcDxER/S3wQZDiM/fInBkdpK5fv47//e9/mktqxkwmjIiIwLfffov169fj0qVLeO+995CUlISJEycCqLhUNmbMGE3/UaNGwcHBAePHj0d8fDwOHz6M6dOnY8KECbCysgIATJ06FXv37sWSJUtw+fJlLFmyBPv27UN4eLhmP9OmTUNsbCwSExPxxx9/YMSIEVCpVBg7diyAikt64eHhWLRoEaKjo3HhwgWMGzcOTZo0wahRo4w9ZUREjcrfQUrFCedktgyeNZ6VlYWwsDAcOHAAIpEI165dQ8uWLfH666+jadOm+Oyzz/TeV1hYGLKysjBv3jykpaUhMDAQv/32G5RKJQAgLS0NSUlJmv42NjaIiYnBlClTEBwcDAcHB4SGhmLBggWaPt27d8eWLVvw8ccfY/bs2fDx8UFUVJTWGlIpKSl49dVXkZmZiebNm+Ppp5/G8ePHNccFgA8++ACFhYWYNGkS7t+/j65du2Lv3r1cQ4qISE8BrnYQi4DMvGJk5BbD2U5u6pKIap1B60gBwJgxY5CRkYFvv/0W/v7+OHv2LFq2bIm9e/fivffe4+rfD+E6UkTU2A1YcRhX7uTi2zHB6BdQ/RxTovqkztaRAqC5bFY5J6mSr68vbt26ZejuiIjIjLV1r/gR4jwpMlcGB6n8/Hw0adJEpz0zMxMymaxWiiIiIvPAO/fI3BkcpHr27IlNmzZp3otEIqjVaixbtgx9+vSp1eKIiKhh0wSp2wxSZJ4Mnmy+bNky9O7dG3/99RdKSkrwwQcf4OLFi7h37x5+//33uqiRiIgaqAA3O4hEwB1VMTJyi+BkywnnZF4MHpEKCAjAuXPn0KVLF/Tv3x/5+fkYPnw4Tp8+DR8fn7qokYiIGqgmUgv4NOcK52S+jHponouLC+bOnVvbtRARkRlq567A9Yw8nE9RoW8b3rlH5sXgESlvb2/Mnj0bV65cqYt6iIjIzARynhSZMYOD1JQpU7Bnzx74+/sjKCgIK1euRFpaWl3URkREZoB37pE5MzhIRURE4MSJE7h8+TKef/55rF69Gi1atEBISIjW3XxERETA3xPO03KKkJlXbOpyiGqV0c/a8/Pzw9y5c3HlyhUcOXIEd+/exfjx42uzNiIiMgM2Mgt4O1oD4MKcZH6MDlIA8OeffyI8PBzDhg3DlStXMGLEiNqqi4iIzEjl5b2LDFJkZgwOUlevXsUnn3wCX19f9OjRA/Hx8Vi8eDHu3LmDqKiouqiRiIgauMogxREpMjcGL3/Qpk0bBAcHY/LkyRg5ciRcXFzqoi4iIjIjbd0qJ5yrTFwJUe0yOEhdvnwZfn5+dVELERGZqcqHF6dmF+JefgnsraUmroiodhh8aY8hioiIDGUnt9RMOOcyCGRO9BqRsre3x9WrV+Ho6IhmzZpBJBJV2/fevXu1VhwREZmPQHcFEjPzcT41Bz39mpu6HKJaoVeQWrFiBWxtbTV/rilIERERVSXQzQ7/PXubI1JkVvQKUmPHjtX8edy4cXVVCxERmTHeuUfmyOA5UhKJBBkZGTrtWVlZkEgktVIUERGZn7YPglTK/UJkF5SYuBqi2mFwkBIEocr24uJiSKW8C4OIiKqmsLKE0qEJAC6DQOZD7+UPvvjiCwCASCTCt99+CxsbG81n5eXlOHz4MNq0aVP7FRIRkdkIdFPgVlYBzqfm4BlfR1OXQ/SP6R2kVqxYAaBiROqbb77RuownlUrh5eWFb775pvYrJCIisxHorsCu82mccE5mQ+8glZiYCADo06cPtm3bhmbNmtVZUUREZJ4qJ5xfuM0gRebB4JXNDx48WBd1EBFRIxD4YIXzW1kFyCkshcLK0sQVEf0zBk82HzFiBBYvXqzTvmzZMrzyyiu1UhQREZmnpk2k8GhmBQC4yMt7ZAYMDlKxsbEYMmSITvvAgQNx+PDhWimKiIjMF9eTInNicJDKy8urcpkDS0tLqFS8nZWIiGoWqJknxd8MavgMDlKBgYGIiorSad+yZQsCAgJqpSgiIjJfmgnnHJEiM2DwZPPZs2fj5Zdfxo0bN9C3b18AwP79+/HTTz/h559/rvUCiYjIvFSOSCVm5kNVVAo7OSecU8Nl8IjUiy++iO3bt+P69euYNGkS3n//faSkpGDfvn0YOnRoHZRIRETmxN5aCvemlRPOeXmPGjaDR6QAYMiQIVVOOCciItJHoLsdUrMLcfF2Drr5OJi6HCKjGTwiBQDZ2dn49ttv8dFHH+HevXsAgFOnTiE1NbVWiyMiIvPEO/fIXBg8InXu3Dn069cPCoUCN2/exOuvvw57e3tER0fj1q1b2LRpU13USUREZqQtgxSZCYNHpCIiIjBu3Dhcu3YNcrlc0z5o0CCuI0VERHpp99CE87ziMhNXQ2Q8g4PUiRMn8NZbb+m0u7u7Iz09vVaKIiIi8+ZoI4OrQg5BAOK5nhQ1YAYHKblcXuXCm1euXEHz5s1rpSgiIjJ/gby8R2bA4CD10ksvYd68eSgtLQUAiEQiJCUlYcaMGXj55ZdrvUAiIjJPgW5cmJMaPoOD1Keffoq7d+/CyckJhYWF6NWrF1q1agVbW1ssXLiwLmokIiIz1M7DDgBHpKhhM/iuPTs7O8TFxeHAgQM4deoU1Go1OnXqhH79+tVFfUREZKYqL+3duJuHgpIyNJEatbQhkUkZ/U9t3759NY+IISIiMpSTrRzOdjLcURUj/rYKwV72pi6JyGB6Xdr74osvUFRUpPlzTa/169fjjz/+0LuAVatWwdvbG3K5HEFBQThy5EiN/YuLizFr1iwolUrIZDL4+Phg/fr1Wn22bt2KgIAAyGQyBAQEIDo6WuvzyMhIdO7cGba2tnBycsLQoUNx5coVrT7jxo2DSCTSej399NN6fy8iInq8ynlSvLxHDZVeI1IrVqzAa6+9BrlcjhUrVtTYt7i4GBkZGXjvvfewbNmyGvtGRUUhPDwcq1atQo8ePbBmzRoMGjQI8fHxaNGiRZXbhIaG4s6dO1i3bh1atWqFjIwMlJX9vQbJsWPHEBYWhvnz52PYsGGIjo5GaGgo4uLi0LVrVwBAbGwsJk+ejM6dO6OsrAyzZs1CSEgI4uPjYW1trdnXwIEDsWHDBs17qVT62HNFRET6C3RXYP/lDAYparBEgiAItb3TmJgYjBo1Cnfv3q2xX9euXdGpUyesXr1a0+bv74+hQ4ciMjJSp/+ePXswcuRIJCQkwN6+6iHgsLAwqFQq7N69W9M2cOBANGvWDD/99FOV21ROno+NjUXPnj0BVIxIZWdnY/v27Y/7utVSqVRQKBTIycmBnZ2d0fshIjJX++Lv4PVNf6G1sy3+915PU5dDBMCw32+jnrX3OM888ww+/vjjGvuUlJTg5MmTCAkJ0WoPCQnB0aNHq9xmx44dCA4OxtKlS+Hu7g4/Pz9MmzYNhYWFmj7Hjh3T2eeAAQOq3ScA5ORU/JfQo+Hs0KFDcHJygp+fH9544w1kZGTU+J2Ki4uhUqm0XkREVL12HhWX9q5l5KKwpNzE1RAZzqggtX//fjz//PPw8fFBq1at8Pzzz2Pfvn2az62srDB16tQa95GZmYny8nI4OztrtTs7O1e7QnpCQgLi4uJw4cIFREdHY+XKlfjll18wefJkTZ/09HSD9ikIAiIiIvDMM88gMDBQ0z5o0CBs3rwZBw4cwGeffYYTJ06gb9++KC4urvY7RUZGQqFQaF6enp41ngMiosbOyVYGRxsZ1AIQn8b/+KSGx+Ag9dVXX2HgwIGwtbXF1KlT8e6778LOzg6DBw/GV199ZXABIpFI670gCDptldRqNUQiETZv3owuXbpg8ODBWL58OTZu3Kg1KmXIPt955x2cO3dO57JfWFgYhgwZgsDAQLzwwgvYvXs3rl69il27dlX7XWbOnImcnBzNKzk5ucbvTkTU2IlEIrRzr7h0woU5qSEyePmDyMhIrFixAu+8846m7d1330WPHj2wcOFCrfaaODo6QiKR6IwUZWRk6IwoVXJ1dYW7uzsUCoWmzd/fH4IgICUlBb6+vnBxcdF7n1OmTMGOHTtw+PBheHh41Fivq6srlEolrl27Vm0fmUwGmUxW436IiEhbO3cFDl65yyBFDZLBI1IqlQoDBw7UaQ8JCTFoTpBUKkVQUBBiYmK02mNiYtC9e/cqt+nRowdu376NvLw8TdvVq1chFos1Qahbt246+9y7d6/WPgVBwDvvvINt27bhwIED8Pb2fmy9WVlZSE5Ohqurq97fkYiIHo/P3KOGzOAg9eKLL+qsywQAv/76K1544QWD9hUREYFvv/0W69evx6VLl/Dee+8hKSkJEydOBFBxqWzMmDGa/qNGjYKDgwPGjx+P+Ph4HD58GNOnT8eECRNgZWUFAJg6dSr27t2LJUuW4PLly1iyZAn27duH8PBwzX4mT56MH374AT/++CNsbW2Rnp6O9PR0zeXBvLw8TJs2DceOHcPNmzdx6NAhvPDCC3B0dMSwYcMMPWVERFSDyiB1LSMPRaWccE4Ni16X9r744gvNn/39/bFw4UIcOnQI3bp1AwAcP34cv//+O95//32DDh4WFoasrCzMmzcPaWlpCAwMxG+//QalUgkASEtLQ1JSkqa/jY0NYmJiMGXKFAQHB8PBwQGhoaFYsGCBpk/37t2xZcsWfPzxx5g9ezZ8fHwQFRWlWUMKgGa5hd69e2vVs2HDBowbNw4SiQTnz5/Hpk2bkJ2dDVdXV/Tp0wdRUVGwtbU16DsSEVHNXBVyOFhLkZVfgktpKnRs0czUJRHpTa91pPS59AVUTBpMSEj4x0WZC64jRUSkn7Hr/0Ts1buYPzQQo59WmrocauQM+f3Wa0QqMTGxVgojIiKqSjt3BWKv3sWFFM6ToobF6AU5MzMzkZWVVZu1EBFRIxX4YAkETjinhsagIJWdnY3JkyfD0dERzs7OcHJygqOjI9555x1kZ2fXUYlERGTuKiecX72Tywnn1KDovY7UvXv30K1bN6SmpuK1117TrN906dIlbNy4Efv378fRo0fRrBknCRIRkWHcm1qhWRNL3C8oxdU7uWjv0dTUJRHpRe8gNW/ePEilUty4cUNncct58+YhJCQE8+bNw4oVK2q9SCIiMm8ikQiB7gocuZaJ86k5DFLUYOh9aW/79u349NNPq1wh3MXFBUuXLq1yfSkiIiJ9VF7e4wrn1JDoHaTS0tLQtm3baj8PDAys9sHAREREj9OOK5xTA6R3kHJ0dMTNmzer/TwxMREODg61URMRETVClUHqSnouSsrUJq6GSD96B6mBAwdi1qxZKCkp0fmsuLgYs2fPrvIZfERERPrwaGYFhZUlSssFXL2Ta+pyiPSi92TzuXPnIjg4GL6+vpg8eTLatGkDAIiPj8eqVatQXFyM77//vs4KJSIi81Yx4dwOv1/PwvnUHM2cKaL6TO8g5eHhgWPHjmHSpEmYOXMmKp8sIxKJ0L9/f3z11Vfw9PSss0KJiMj8BborNEHqVVMXQ6QHvYMUUPHMvd27d+P+/fu4du0aAKBVq1awt7evk+KIiKhxqZwndZETzqmBMChIVWrWrBm6dOlS27UQEVEjF+hWEaQupeeitFwNS4nRTzIjeiL4TygREdUbSocmsJVboKRMzQnn1CAwSBERUb0hEok0o1JcmJMaAgYpIiKqV9p5VAYplYkrIXo8BikiIqpX2rrZAeAK59QwMEgREVG9Unnn3qU0FcrKucI51W8MUkREVK94OVjDRmaB4jI1rmXkmbocohoxSBERUb0iFos0l/c44ZzqOwYpIiKqdyofD8MgRfUdgxQREdU7lfOkOOGc6jsGKSIiqncqR6TiOeGc6jkGKSIiqndaOlrDWipBUakaN+7mm7ocomoxSBERUb0jFosQwAnn1AAwSBERUb0UyHlS1AAwSBERUb3UjnfuUQPAIEVERPVSZZC6eFuFcrVg4mqIqsYgRURE9VLL5jawspSgsLQcMfF3TF0OUZUYpIiIqF6SiEXoH+AMAHh780ks33uFI1NU7zBIERFRvbV0RHuM6toCggB8ceA6xqz/A5l5xaYui0iDQYqIiOotuaUEi4a1w4qwp2BlKcHv17Mw+PMj+DPxnqlLIwLAIEVERA3AsI4e2PFOD7RyskFGbjFe/b/j+Cb2BgSBl/rItBikiIioQfB1tsWvk3tgaAc3lKsFLN59GW9s+gs5BaWmLo0aMQYpIiJqMKxlFlgR1gELhwVCKhFj36UMDPnyCM6lZJu6NGqkGKSIiKhBEYlEeK2rEtsmdYenvRVS7hdixOpj+P7YTV7qoyeOQYqIiBqkQHcFdk55FiEBzigpV2P2rxfx7pYzyCsuM3Vp1IgwSBERUYOlsLLEmtFBmDXYHxKxCP89exsvfhWHK+m5pi6NGgkGKSIiatBEIhHe6NkSUW8+DRc7ORLu5uOlr+Ow9WSKqUujRsDkQWrVqlXw9vaGXC5HUFAQjhw5UmP/4uJizJo1C0qlEjKZDD4+Pli/fr1Wn61btyIgIAAymQwBAQGIjo42+LiCIGDOnDlwc3ODlZUVevfujYsXL/7zL0xERHUi2Mseu959Bs/6OqKoVI33fz6LGVvPoai03NSlkRkzaZCKiopCeHg4Zs2ahdOnT+PZZ5/FoEGDkJSUVO02oaGh2L9/P9atW4crV67gp59+Qps2bTSfHzt2DGFhYRg9ejTOnj2L0aNHIzQ0FH/88YdBx126dCmWL1+Or776CidOnICLiwv69++P3FwOFxMR1VcONjJsHN8F7/Xzg0gEbDmRjOGrjuJmZr6pSyMzJRJMeItD165d0alTJ6xevVrT5u/vj6FDhyIyMlKn/549ezBy5EgkJCTA3t6+yn2GhYVBpVJh9+7dmraBAweiWbNm+Omnn/Q6riAIcHNzQ3h4OD788EMAFSNhzs7OWLJkCd566y29vp9KpYJCoUBOTg7s7Oz02oaIiGrHkWt3Eb7lDLLyS2Ajs8CyEe0xqJ2rqcuiBsCQ32+TjUiVlJTg5MmTCAkJ0WoPCQnB0aNHq9xmx44dCA4OxtKlS+Hu7g4/Pz9MmzYNhYWFmj7Hjh3T2eeAAQM0+9TnuImJiUhPT9fqI5PJ0KtXr2prIyKi+uVZ3+bY9e6zCFY2Q15xGd7efArz/huPkjK1qUsjM2JhqgNnZmaivLwczs7OWu3Ozs5IT0+vcpuEhATExcVBLpcjOjoamZmZmDRpEu7du6eZJ5Wenl7jPvU5buX/VtXn1q1b1X6n4uJiFBf//TBNlUpVbV8iIqp7Lgo5fnrzaSz73xWsPZyA9b8n4nTyfXw9qhPcmlqZujwyAyafbC4SibTeC4Kg01ZJrVZDJBJh8+bN6NKlCwYPHozly5dj48aNWqNS+uyztvo8LDIyEgqFQvPy9PSsti8RET0ZlhIxPhrsj7Wjg2Art8DppGwM+eIIDl3JMHVpZAZMFqQcHR0hkUh0Rp8yMjJ0RoIqubq6wt3dHQqFQtPm7+8PQRCQklJxm6uLi0uN+9TnuC4uLgBgUG0AMHPmTOTk5GheycnJ1fYlIqInK6StC3ZNeRbt3BW4X1CK8RtP4LO9V1Cu5mroZDyTBSmpVIqgoCDExMRotcfExKB79+5VbtOjRw/cvn0beXl5mrarV69CLBbDw8MDANCtWzedfe7du1ezT32O6+3tDRcXF60+JSUliI2NrbY2oGIelZ2dndaLiIjqjxYOTfDzxG7419MtIAjAlweuY/S6P3A3t/jxGxNVRTChLVu2CJaWlsK6deuE+Ph4ITw8XLC2thZu3rwpCIIgzJgxQxg9erSmf25uruDh4SGMGDFCuHjxohAbGyv4+voKr7/+uqbP77//LkgkEmHx4sXCpUuXhMWLFwsWFhbC8ePH9T6uIAjC4sWLBYVCIWzbtk04f/688Oqrrwqurq6CSqXS+/vl5OQIAIScnJx/cpqIiKgObD+dIvjP3i0oP9wpdF4QIxy/kWnqkqieMOT326RBShAE4euvvxaUSqUglUqFTp06CbGxsZrPxo4dK/Tq1Uur/6VLl4R+/foJVlZWgoeHhxARESEUFBRo9fn555+F1q1bC5aWlkKbNm2ErVu3GnRcQRAEtVotfPLJJ4KLi4sgk8mEnj17CufPnzfouzFIERHVb9fuqIR+nx0SlB/uFLxn7BS+PnhNKC9Xm7osMjFDfr9Nuo6UueM6UkRE9V9BSRk+jr6AbadTAQDPtXHCZ6FPoWkTqYkrI1NpEOtIERER1QdNpBb4LPQpRA5vB6mFGPsvZ2DIF3E4m5xt6tKoAWCQIiKiRk8kEuHVLi2w7e3uUDo0QWp2IUZ8cxTfHb0JXrihmjBIERERPRDorsB/pzyDAW2dUVou4JMdFzHlp9PIKy4zdWlUTzFIERERPcRObolv/hWEj4f4w0Isws5zaXjxyzhcTufTKkgXgxQREdEjRCIRXn+2JaLeehquCjkSMvMx9Ovf8fNfXGiZtDFIERERVSNIaY9d7z6Lnn7NUVSqxvRfzuGDX86iqLTc1KVRPcEgRUREVAN7ayk2juuMiP5+EImA//yVgqFf/47EzHxTl0b1AIMUERHRY4jFIrz7nC9++HdXONpIcTk9Fy98GYffzqeZujQyMQYpIiIiPfVo5Yhd7z6LLl72yCsuw6TNpzBnx0WUlKlNXRqZCIMUERGRAZzt5Pjxja54q1dLAMDGozcRuuYYUrMLTVwZmQKDFBERkYEsJGLMHOSP/xsTDDu5Bc4kZ2PIF0dw8HKGqUujJ4xBioiIyEj9A5yx691n0d5DgeyCUozfeAJL91xGWTkv9TUWfGhxHeJDi4mIGofisnIs2HkJ3x+/BQBo76FAS0drE1dlGHtrGSb2bgknW7mpSzE5Q36/GaTqEIMUEVHjsuPsbczYeg4FJQ1znSl/Vzv8PLEbbGQWpi7FpBik6gkGKSKixicpqwD7L99Bubrh/LwKArDm8A1k5pWgp19zrBsbDEtJ4539wyBVTzBIERFRQ3EuJRtha46jsLQcocEeWPJye4hEIlOXZRKG/H433rhJREREGu09muLLVztC/GD19i8PXDd1SQ0CgxQREREBAPoFOGPui20BAMtjruKXkykmrqj+Y5AiIiIijdHdvDSLjc7Yeg6/X880cUX1G4MUERERaflwQBs8394VZWoBE78/icvpKlOXVG8xSBEREZEWsViET195Cl287JFbXIbxG04gPafI1GXVSwxSREREpENuKcHaMUFo2dwaaTlFGL/xBHKLSk1dVr3DIEVERERVatpEiu/Gd4GjjRSX0lSYtPkUSvn4Gy0MUkRERFQtT/smWD+uM6wsJThyLROzos+DS1D+jUGKiIiIasQ1pqrHIEVERESPxTWmqsYgRURERHrhGlO6GKSIiIhIbx8OaIMXnnLjGlMPMEgRERGR3irWmGqPLt5cYwpgkCIiIiIDySwkWDs6CD5cY4pBioiIiAzXtIkUG8d3gaONrFGvMcUgRUREREapWGMquFGvMcUgRUREREZr79EUX41qvGtMMUgRERHRP/KcvzPmvRQIoPGtMcUgRURERP/Yv55WYmIvHwAVa0zFXWsca0wxSBEREVGt+GBA67/XmPrhJC6lmf8aUwxSREREVCseXmMq78EaU2k5haYuq04xSBEREVGteXiNqXRVEcZvMO81phikiIiIqFY9vMbU5fRcs15jikGKiIiIat2ja0x9tM0815gyeZBatWoVvL29IZfLERQUhCNHjlTb99ChQxCJRDqvy5cva/qUlpZi3rx58PHxgVwux1NPPYU9e/Zo7cfLy6vK/UyePFnTZ9y4cTqfP/3007V/AoiIiMzUw2tM/XwyBV/sN781pkwapKKiohAeHo5Zs2bh9OnTePbZZzFo0CAkJSXVuN2VK1eQlpamefn6+mo++/jjj7FmzRp8+eWXiI+Px8SJEzFs2DCcPn1a0+fEiRNa28fExAAAXnnlFa3jDBw4UKvfb7/9VovfnoiIyPw9vMbUin3mt8aUSDDhOFvXrl3RqVMnrF69WtPm7++PoUOHIjIyUqf/oUOH0KdPH9y/fx9Nmzatcp9ubm6YNWuW1ujS0KFDYWNjgx9++KHKbcLDw7Fz505cu3YNIpEIQMWIVHZ2NrZv327091OpVFAoFMjJyYGdnZ3R+yEiImroFu++jG9ib8BCLMLG8V3wjK+jqUuqliG/3yYbkSopKcHJkycREhKi1R4SEoKjR4/WuG3Hjh3h6uqK5557DgcPHtT6rLi4GHK5XKvNysoKcXFx1dbxww8/YMKECZoQVenQoUNwcnKCn58f3njjDWRkZOj79YiIiOghHwxojRfNcI0pkwWpzMxMlJeXw9nZWavd2dkZ6enpVW7j6uqKtWvXYuvWrdi2bRtat26N5557DocPH9b0GTBgAJYvX45r165BrVYjJiYGv/76K9LS0qrc5/bt25GdnY1x48ZptQ8aNAibN2/GgQMH8Nlnn+HEiRPo27cviouLq/1OxcXFUKlUWi8iIiKqWGNq2Svt0dXM1pgy2aW927dvw93dHUePHkW3bt007QsXLsT333+vNYG8Ji+88AJEIhF27NgBALh79y7eeOMN/Pe//4VIJIKPjw/69euHDRs2oKCgQGf7AQMGQCqV4r///W+Nx0lLS4NSqcSWLVswfPjwKvvMmTMHc+fO1WnnpT0iIqIKOQWlePmbo7iekYc2Lrb4eWI32MotTV2WlgZxac/R0RESiURn9CkjI0NnlKomTz/9NK5du6Z537x5c2zfvh35+fm4desWLl++DBsbG3h7e+tse+vWLezbtw+vv/76Y4/j6uoKpVKpdaxHzZw5Ezk5OZpXcnKy3t+DiIioMVA0scSGcZ3NZo0pkwUpqVSKoKAgzR1zlWJiYtC9e3e993P69Gm4urrqtMvlcri7u6OsrAxbt27FSy+9pNNnw4YNcHJywpAhQx57nKysLCQnJ1d5rEoymQx2dnZaLyIiItLmad8EG8Z1Nos1pixMefCIiAiMHj0awcHB6NatG9auXYukpCRMnDgRQMUIT2pqKjZt2gQAWLlyJby8vNC2bVvNJPGtW7di69atmn3+8ccfSE1NRYcOHZCamoo5c+ZArVbjgw8+0Dq2Wq3Ghg0bMHbsWFhYaJ+GvLw8zJkzBy+//DJcXV1x8+ZNfPTRR3B0dMSwYcPq+KwQERGZv3YeCnz9Wke8/t1f+PlkCjyaNcHUfr6P37CeMWmQCgsLQ1ZWFubNm4e0tDQEBgbit99+g1KpBFAxL+nhNaVKSkowbdo0pKamwsrKCm3btsWuXbswePBgTZ+ioiJ8/PHHSEhIgI2NDQYPHozvv/9eZ7mEffv2ISkpCRMmTNCpSyKR4Pz589i0aROys7Ph6uqKPn36ICoqCra2tnVzMoiIiBqZvm2cMX9oIGZFX8CKfVfh3swKI4I8TF2WQUy6jpS54zpSREREj7dkz2WsPlR/1phqEJPNiYiIiABgekjDXWOKQYqIiIhMqiGvMcUgRURERCYns5Bg7ehgtHKyQbqqCOM3nEBuUampy3osBikiIiKqFx5dY+rtH+r/GlMMUkRERFRvPLzGVNz1TMys52tMMUgRERFRvVK5xpRYBPxyMgWf76/+qSKmxiBFRERE9U7lGlMAsHLfNfz8V/187BqDFBEREdVLr3VV4u3ePgCAmdvO48i1uyauSBeDFBEREdVb00Na46UOFWtMvf3DqXq3xhSDFBEREdVbYrEIS0fU3zWmGKSIiIioXqtqjSlVPVljikGKiIiI6j1FE0tsHN8ZzW0r1piaVE/WmGKQIiIiogbBo1kTrB/bGU2k9WeNKQYpIiIiajDaeSjw9ahO9WaNKQYpIiIialD6tHHCgqHtIBYBDtZSk9ZiYdKjExERERlhVNcW6OJtj1ZONiatgyNSRERE1CCZOkQBDFJERERERmOQIiIiIjISgxQRERGRkRikiIiIiIzEIEVERERkJAYpIiIiIiMxSBEREREZiUGKiIiIyEgMUkRERERGYpAiIiIiMhKDFBEREZGRGKSIiIiIjMQgRURERGQkC1MXYM4EQQAAqFQqE1dCRERE+qr83a78Ha8Jg1Qdys3NBQB4enqauBIiIiIyVG5uLhQKRY19RII+cYuMolarcfv2bdja2kIkEtXqvlUqFTw9PZGcnAw7O7ta3Tf9jef5yeB5fjJ4np8Mnucnoy7PsyAIyM3NhZubG8TimmdBcUSqDonFYnh4eNTpMezs7Ph/1CeA5/nJ4Hl+Mnienwye5yejrs7z40aiKnGyOREREZGRGKSIiIiIjMQg1UDJZDJ88sknkMlkpi7FrPE8Pxk8z08Gz/OTwfP8ZNSX88zJ5kRERERG4ogUERERkZEYpIiIiIiMxCBFREREZCQGKSIiIiIjMUg1QKtWrYK3tzfkcjmCgoJw5MgRU5dkViIjI9G5c2fY2trCyckJQ4cOxZUrV0xdltmLjIyESCRCeHi4qUsxS6mpqfjXv/4FBwcHNGnSBB06dMDJkydNXZZZKSsrw8cffwxvb29YWVmhZcuWmDdvHtRqtalLa9AOHz6MF154AW5ubhCJRNi+fbvW54IgYM6cOXBzc4OVlRV69+6NixcvPrH6GKQamKioKISHh2PWrFk4ffo0nn32WQwaNAhJSUmmLs1sxMbGYvLkyTh+/DhiYmJQVlaGkJAQ5Ofnm7o0s3XixAmsXbsW7du3N3UpZun+/fvo0aMHLC0tsXv3bsTHx+Ozzz5D06ZNTV2aWVmyZAm++eYbfPXVV7h06RKWLl2KZcuW4csvvzR1aQ1afn4+nnrqKXz11VdVfr506VIsX74cX331FU6cOAEXFxf0799f87zbOidQg9KlSxdh4sSJWm1t2rQRZsyYYaKKzF9GRoYAQIiNjTV1KWYpNzdX8PX1FWJiYoRevXoJU6dONXVJZufDDz8UnnnmGVOXYfaGDBkiTJgwQatt+PDhwr/+9S8TVWR+AAjR0dGa92q1WnBxcREWL16saSsqKhIUCoXwzTffPJGaOCLVgJSUlODkyZMICQnRag8JCcHRo0dNVJX5y8nJAQDY29ubuBLzNHnyZAwZMgT9+vUzdSlma8eOHQgODsYrr7wCJycndOzYEf/3f/9n6rLMzjPPPIP9+/fj6tWrAICzZ88iLi4OgwcPNnFl5isxMRHp6elav4symQy9evV6Yr+LfGhxA5KZmYny8nI4OztrtTs7OyM9Pd1EVZk3QRAQERGBZ555BoGBgaYux+xs2bIFp06dwokTJ0xdillLSEjA6tWrERERgY8++gh//vkn3n33XchkMowZM8bU5ZmNDz/8EDk5OWjTpg0kEgnKy8uxcOFCvPrqq6YuzWxV/vZV9bt469atJ1IDg1QDJBKJtN4LgqDTRrXjnXfewblz5xAXF2fqUsxOcnIypk6dir1790Iul5u6HLOmVqsRHByMRYsWAQA6duyIixcvYvXq1QxStSgqKgo//PADfvzxR7Rt2xZnzpxBeHg43NzcMHbsWFOXZ9ZM+bvIINWAODo6QiKR6Iw+ZWRk6KRx+uemTJmCHTt24PDhw/Dw8DB1OWbn5MmTyMjIQFBQkKatvLwchw8fxldffYXi4mJIJBITVmg+XF1dERAQoNXm7++PrVu3mqgi8zR9+nTMmDEDI0eOBAC0a9cOt27dQmRkJINUHXFxcQFQMTLl6uqqaX+Sv4ucI9WASKVSBAUFISYmRqs9JiYG3bt3N1FV5kcQBLzzzjvYtm0bDhw4AG9vb1OXZJaee+45nD9/HmfOnNG8goOD8dprr+HMmTMMUbWoR48eOkt4XL16FUql0kQVmaeCggKIxdo/qxKJhMsf1CFvb2+4uLho/S6WlJQgNjb2if0uckSqgYmIiMDo0aMRHByMbt26Ye3atUhKSsLEiRNNXZrZmDx5Mn788Uf8+uuvsLW11YwAKhQKWFlZmbg682Fra6sz78za2hoODg6cj1bL3nvvPXTv3h2LFi1CaGgo/vzzT6xduxZr1641dWlm5YUXXsDChQvRokULtG3bFqdPn8by5csxYcIEU5fWoOXl5eH69eua94mJiThz5gzs7e3RokULhIeHY9GiRfD19YWvry8WLVqEJk2aYNSoUU+mwCdybyDVqq+//lpQKpWCVCoVOnXqxNvyaxmAKl8bNmwwdWlmj8sf1J3//ve/QmBgoCCTyYQ2bdoIa9euNXVJZkelUglTp04VWrRoIcjlcqFly5bCrFmzhOLiYlOX1qAdPHiwyn8njx07VhCEiiUQPvnkE8HFxUWQyWRCz549hfPnzz+x+kSCIAhPJrIRERERmRfOkSIiIiIyEoMUERERkZEYpIiIiIiMxCBFREREZCQGKSIiIiIjMUgRERERGYlBioiIiMhIDFJERHXIy8sLK1euNHUZRFRHGKSIyGyMGzcOQ4cOBQD07t0b4eHhT+zYGzduRNOmTXXaT5w4gTfffPOJ1UFETxaftUdEVIOSkhJIpVKjt2/evHktVkNE9Q1HpIjI7IwbNw6xsbH4/PPPIRKJIBKJcPPmTQBAfHw8Bg8eDBsbGzg7O2P06NHIzMzUbNu7d2+88847iIiIgKOjI/r37w8AWL58Odq1awdra2t4enpi0qRJyMvLAwAcOnQI48ePR05OjuZ4c+bMAaB7aS8pKQkvvfQSbGxsYGdnh9DQUNy5c0fz+Zw5c9ChQwd8//338PLygkKhwMiRI5Gbm1u3J42IjMIgRURm5/PPP0e3bt3wxhtvIC0tDWlpafD09ERaWhp69eqFDh064K+//sKePXtw584dhIaGam3/3XffwcLCAr///jvWrFkDABCLxfjiiy9w4cIFfPfddzhw4AA++OADAED37t2xcuVK2NnZaY43bdo0nboEQcDQoUNx7949xMbGIiYmBjdu3EBYWJhWvxs3bmD79u3YuXMndu7cidjYWCxevLiOzhYR/RO8tEdEZkehUEAqlaJJkyZwcXHRtK9evRqdOnXCokWLNG3r16+Hp6cnrl69Cj8/PwBAq1atsHTpUq19PjzfytvbG/Pnz8fbb7+NVatWQSqVQqFQQCQSaR3vUfv27cO5c+eQmJgIT09PAMD333+Ptm3b4sSJE+jcuTMAQK1WY+PGjbC1tQUAjB49Gvv378fChQv/2YkholrHESkiajROnjyJgwcPwsbGRvNq06YNgIpRoErBwcE62x48eBD9+/eHu7s7bG1tMWbMGGRlZSE/P1/v41+6dAmenp6aEAUAAQEBaNq0KS5duqRp8/Ly0oQoAHB1dUVGRoZB35WIngyOSBFRo6FWq/HCCy9gyZIlOp+5urpq/mxtba312a1btzB48GBMnDgR8+fPh729PeLi4vDvf/8bpaWleh9fEASIRKLHtltaWmp9LhKJoFar9T4OET05DFJEZJakUinKy8u12jp16oStW7fCy8sLFhb6/+vvr7/+QllZGT777DOIxRUD+f/5z38ee7xHBQQEICkpCcnJyZpRqfj4eOTk5MDf31/veoio/uClPSIyS15eXvjjjz9w8+ZNZGZmQq1WY/Lkybh37x5effVV/Pnnn0hISMDevXsxYcKEGkOQj48PysrK8OWXXyIhIQHff/89vvnmG53j5eXlYf/+/cjMzERBQYHOfvr164f27dvjtddew6lTp/Dnn39izJgx6NWrV5WXE4mo/mOQIiKzNG3aNEgkEgQEBKB58+ZISkqCm5sbfv/9d5SXl2PAgAEIDAzE1KlToVAoNCNNVenQoQOWL1+OJUuWIDAwEJs3b0ZkZKRWn+7du2PixIkICwtD8+bNdSarAxWX6LZv345mzZqhZ8+e6NevH1q2bImoqKha//5E9GSIBEEQTF0EERERUUPEESkiIiIiIzFIERERERmJQYqIiIjISAxSREREREZikCIiIiIyEoMUERERkZEYpIiIiIiMxCBFREREZCQGKSIiIiIjMUgRERERGYlBioiIiMhIDFJERERERvr/i2batZRCCIUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Parameters (GA): lstm_units = 76, dropout_rate = 0.25290333922644315, learning_rate = 0.005376892691117486, batch_size = 20\n"
     ]
    }
   ],
   "source": [
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "\n",
    "# Define the fitness function for LSTM model\n",
    "def lstm_fitness_function_ga(params):\n",
    "    lstm_units = int(params[0])\n",
    "    dropout_rate = params[1]\n",
    "    learning_rate = params[2]\n",
    "    batch_size = int(params[3])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True, input_shape=(X_train_m1_lstm.shape[1], X_train_m1_lstm.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    model.fit(X_train_m1_lstm, y_train_m1, epochs=10, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(X_test_m1_lstm)\n",
    "    mse = mean_squared_error(y_test_m1, y_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Set the bounds for GA: [lstm_units, dropout_rate, learning_rate, batch_size]\n",
    "varbound = np.array([[10, 100], [0.1, 0.5], [0.0001, 0.01], [16, 128]])\n",
    "\n",
    "algorithm_param = {'max_num_iteration': 100, 'population_size': 50, 'mutation_probability': 0.1, 'elit_ratio': 0.01, 'crossover_probability': 0.5, 'parents_portion': 0.3, 'crossover_type':'uniform', 'max_iteration_without_improv':10}\n",
    "\n",
    "model = model = ga(function=lstm_fitness_function_ga, \n",
    "           dimension=4, \n",
    "           variable_type='real', \n",
    "           variable_boundaries=varbound, \n",
    "           algorithm_parameters=algorithm_param,\n",
    "           function_timeout=300)  # Increase the timeout\n",
    "\n",
    "model.run()\n",
    "\n",
    "best_params_ga = model.output_dict['variable']\n",
    "\n",
    "print(f'Optimized Parameters (GA): lstm_units = {int(best_params_ga[0])}, dropout_rate = {best_params_ga[1]}, learning_rate = {best_params_ga[2]}, batch_size = {int(best_params_ga[3])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "351/351 [==============================] - 25s 8ms/step - loss: 0.7846\n",
      "Epoch 2/20\n",
      "351/351 [==============================] - 3s 8ms/step - loss: 0.7585\n",
      "Epoch 3/20\n",
      "351/351 [==============================] - 3s 9ms/step - loss: 0.7584\n",
      "Epoch 4/20\n",
      "351/351 [==============================] - 3s 7ms/step - loss: 0.7495\n",
      "Epoch 5/20\n",
      "351/351 [==============================] - 3s 8ms/step - loss: 0.7439\n",
      "Epoch 6/20\n",
      "351/351 [==============================] - 3s 8ms/step - loss: 0.7361\n",
      "Epoch 7/20\n",
      "351/351 [==============================] - 3s 9ms/step - loss: 0.7133\n",
      "Epoch 8/20\n",
      "351/351 [==============================] - 3s 9ms/step - loss: 0.7202\n",
      "Epoch 9/20\n",
      "351/351 [==============================] - 3s 9ms/step - loss: 0.7158\n",
      "Epoch 10/20\n",
      "351/351 [==============================] - 3s 8ms/step - loss: 0.7039\n",
      "Epoch 11/20\n",
      "351/351 [==============================] - 3s 8ms/step - loss: 0.6988\n",
      "Epoch 12/20\n",
      "351/351 [==============================] - 3s 7ms/step - loss: 0.6955\n",
      "Epoch 13/20\n",
      "351/351 [==============================] - 2s 7ms/step - loss: 0.6915\n",
      "Epoch 14/20\n",
      "351/351 [==============================] - 3s 9ms/step - loss: 0.6948\n",
      "Epoch 15/20\n",
      "351/351 [==============================] - 3s 10ms/step - loss: 0.6984\n",
      "Epoch 16/20\n",
      "351/351 [==============================] - 3s 9ms/step - loss: 0.6953\n",
      "Epoch 17/20\n",
      "351/351 [==============================] - 3s 8ms/step - loss: 0.6913\n",
      "Epoch 18/20\n",
      "351/351 [==============================] - 3s 8ms/step - loss: 0.6974\n",
      "Epoch 19/20\n",
      "351/351 [==============================] - 3s 10ms/step - loss: 0.6881\n",
      "Epoch 20/20\n",
      "351/351 [==============================] - 3s 7ms/step - loss: 0.6898\n",
      "219/219 [==============================] - 2s 3ms/step\n",
      "55/55 [==============================] - 3s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model with the GA-optimized parameters\n",
    "optimized_lstm_model_ga = Sequential()\n",
    "optimized_lstm_model_ga.add(LSTM(units=int(best_params_ga[0]), return_sequences=True, input_shape=(X_train_m1_lstm.shape[1], X_train_m1_lstm.shape[2])))\n",
    "optimized_lstm_model_ga.add(Dropout(best_params_ga[1]))\n",
    "optimized_lstm_model_ga.add(LSTM(units=int(best_params_ga[0])))\n",
    "optimized_lstm_model_ga.add(Dropout(best_params_ga[1]))\n",
    "optimized_lstm_model_ga.add(Dense(1))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=best_params_ga[2])\n",
    "optimized_lstm_model_ga.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "optimized_lstm_model_ga.fit(X_train_m1_lstm, y_train_m1, epochs=20, batch_size=int(best_params_ga[3]), verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_lstm_ga = optimized_lstm_model_ga.predict(X_train_m1_lstm)\n",
    "y_test_pred_lstm_ga = optimized_lstm_model_ga.predict(X_test_m1_lstm)\n",
    "\n",
    "# Save predictions vs. ground truth to Excel\n",
    "optimized_lstm_train_results_ga = pd.DataFrame({'Ground Truth': y_train_m1, 'Prediction': y_train_pred_lstm_ga.flatten()})\n",
    "optimized_lstm_test_results_ga = pd.DataFrame({'Ground Truth': y_test_m1, 'Prediction': y_test_pred_lstm_ga.flatten()})\n",
    "\n",
    "optimized_lstm_train_results_ga.to_excel('outputs/optimized_lstm_train_predictions_ga.xlsx', index=False)\n",
    "optimized_lstm_test_results_ga.to_excel('outputs/optimized_lstm_test_predictions_ga.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7008, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_m1_lstm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 1s 6ms/step\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 13ms/step\n",
      "55/55 [==============================] - 1s 5ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 1s 6ms/step\n",
      "55/55 [==============================] - 1s 6ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 1s 6ms/step\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      "55/55 [==============================] - 1s 6ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 1s 6ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "55/55 [==============================] - 2s 8ms/step\n",
      "55/55 [==============================] - 2s 7ms/step\n",
      "Optimized Parameters (HHO): lstm_units = 47, dropout_rate = 0.1\n",
      "219/219 [==============================] - 2s 6ms/step\n",
      "55/55 [==============================] - 2s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "from niapy.algorithms.basic import HarrisHawksOptimization\n",
    "from niapy.task import Task\n",
    "from niapy.problems import Problem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def create_lstm_model(units, dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(1, 6)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "X_train_m1_lstm = X_train_m1_scaled.reshape((X_train_m1_scaled.shape[0], 1, X_train_m1_scaled.shape[1]))\n",
    "X_test_m1_lstm = X_test_m1_scaled.reshape((X_test_m1_scaled.shape[0], 1, X_test_m1_scaled.shape[1]))\n",
    "\n",
    "class CustomLSTMBenchmark(Problem):\n",
    "    def __init__(self):\n",
    "        super().__init__(dimension=2, lower=[10, 0.1], upper=[100, 0.5])\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        units = int(x[0])  # Ensure units is an integer\n",
    "        dropout_rate = x[1]\n",
    "        \n",
    "        lstm_model = create_lstm_model(units=units, dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Use early stopping to reduce training time\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=0)\n",
    "        \n",
    "        lstm_model.fit(X_train_m1_lstm, y_train_m1, epochs=20, batch_size=32, verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        y_pred = lstm_model.predict(X_test_m1_lstm)\n",
    "        return mean_squared_error(y_test_m1, y_pred.flatten())\n",
    "\n",
    "task = Task(problem=CustomLSTMBenchmark(), max_evals=30)  # Reduced evaluations\n",
    "algo = HarrisHawksOptimization(population_size=10)  # Reduced population size\n",
    "\n",
    "best_params_hho, best_loss = algo.run(task)\n",
    "\n",
    "# Extracting the parameters from the first element of the tuple\n",
    "best_units_hho = int(best_params_hho[0])\n",
    "best_dropout_rate_hho = best_params_hho[1]\n",
    "\n",
    "print(f\"Optimized Parameters (HHO): lstm_units = {best_units_hho}, dropout_rate = {best_dropout_rate_hho}\")\n",
    "\n",
    "# Train LSTM with HHO optimized parameters\n",
    "lstm_hho_model = create_lstm_model(units=best_units_hho, dropout_rate=best_dropout_rate_hho)\n",
    "lstm_hho_model.fit(X_train_m1_lstm, y_train_m1, epochs=2, batch_size=32, verbose=0)\n",
    "\n",
    "y_train_pred_hho = lstm_hho_model.predict(X_train_m1_lstm)\n",
    "y_test_pred_hho = lstm_hho_model.predict(X_test_m1_lstm)\n",
    "\n",
    "# Save the predictions\n",
    "results_train_hho = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_hho.flatten()})\n",
    "results_test_hho = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_hho.flatten()})\n",
    "\n",
    "results_train_hho.to_excel('outputs/lstm_hho_train_predictions_hho.xlsx', index=False)\n",
    "results_test_hho.to_excel('outputs/lstm_hho_test_predictions_hho.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 16:59:11,023] A new study created in memory with name: no-name-048f65e2-9b6b-46f2-83c2-0f9bec1b2e45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:00:44,635] Trial 0 finished with value: 0.6193000270118493 and parameters: {'units': 27, 'dropout_rate': 0.19290107525704225}. Best is trial 0 with value: 0.6193000270118493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:02:30,131] Trial 1 finished with value: 0.616787556386968 and parameters: {'units': 81, 'dropout_rate': 0.22592647098912885}. Best is trial 1 with value: 0.616787556386968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:04:02,055] Trial 2 finished with value: 0.6198152559898225 and parameters: {'units': 17, 'dropout_rate': 0.17510423233950415}. Best is trial 1 with value: 0.616787556386968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:05:36,199] Trial 3 finished with value: 0.6178862198156558 and parameters: {'units': 49, 'dropout_rate': 0.3017686888250678}. Best is trial 1 with value: 0.616787556386968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:07:10,204] Trial 4 finished with value: 0.6207096824822149 and parameters: {'units': 48, 'dropout_rate': 0.4122273184696782}. Best is trial 1 with value: 0.616787556386968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:08:37,274] Trial 5 finished with value: 0.6220503183480063 and parameters: {'units': 51, 'dropout_rate': 0.3224397060185198}. Best is trial 1 with value: 0.616787556386968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:09:52,420] Trial 6 finished with value: 0.6180803810874532 and parameters: {'units': 80, 'dropout_rate': 0.42106260956444574}. Best is trial 1 with value: 0.616787556386968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:10:55,979] Trial 7 finished with value: 0.6154991322050799 and parameters: {'units': 34, 'dropout_rate': 0.2016035474180319}. Best is trial 7 with value: 0.6154991322050799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:12:06,778] Trial 8 finished with value: 0.6194569452185072 and parameters: {'units': 83, 'dropout_rate': 0.13984284900650368}. Best is trial 7 with value: 0.6154991322050799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:13:07,939] Trial 9 finished with value: 0.6168205898621401 and parameters: {'units': 26, 'dropout_rate': 0.2875330256804518}. Best is trial 7 with value: 0.6154991322050799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:14:32,837] Trial 10 finished with value: 0.6198552869083199 and parameters: {'units': 97, 'dropout_rate': 0.49190206056826136}. Best is trial 7 with value: 0.6154991322050799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:16:04,778] Trial 11 finished with value: 0.622984699228768 and parameters: {'units': 72, 'dropout_rate': 0.23554350697044535}. Best is trial 7 with value: 0.6154991322050799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:17:19,150] Trial 12 finished with value: 0.6250899910973282 and parameters: {'units': 65, 'dropout_rate': 0.12055879935185097}. Best is trial 7 with value: 0.6154991322050799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:18:16,995] Trial 13 finished with value: 0.6157937459143344 and parameters: {'units': 31, 'dropout_rate': 0.24961893266463037}. Best is trial 7 with value: 0.6154991322050799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:19:16,769] Trial 14 finished with value: 0.6151696529206305 and parameters: {'units': 35, 'dropout_rate': 0.2551310456008211}. Best is trial 14 with value: 0.6151696529206305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:20:17,372] Trial 15 finished with value: 0.6212863201313206 and parameters: {'units': 38, 'dropout_rate': 0.3441570517890099}. Best is trial 14 with value: 0.6151696529206305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:21:00,462] Trial 16 finished with value: 0.6155732446431755 and parameters: {'units': 16, 'dropout_rate': 0.17238481786647908}. Best is trial 14 with value: 0.6151696529206305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:21:45,878] Trial 17 finished with value: 0.6155907717448135 and parameters: {'units': 39, 'dropout_rate': 0.3645713929401039}. Best is trial 14 with value: 0.6151696529206305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:22:25,719] Trial 18 finished with value: 0.6160678220319517 and parameters: {'units': 10, 'dropout_rate': 0.2691414826530318}. Best is trial 14 with value: 0.6151696529206305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:23:11,855] Trial 19 finished with value: 0.6183425973483612 and parameters: {'units': 62, 'dropout_rate': 0.21378406916450865}. Best is trial 14 with value: 0.6151696529206305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:23:54,445] Trial 20 finished with value: 0.634204808660602 and parameters: {'units': 40, 'dropout_rate': 0.13514975663689277}. Best is trial 14 with value: 0.6151696529206305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:24:35,134] Trial 21 finished with value: 0.6143583725318751 and parameters: {'units': 18, 'dropout_rate': 0.17278453028916627}. Best is trial 21 with value: 0.6143583725318751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:25:23,327] Trial 22 finished with value: 0.617001784002883 and parameters: {'units': 22, 'dropout_rate': 0.16581138162108247}. Best is trial 21 with value: 0.6143583725318751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:26:36,545] Trial 23 finished with value: 0.6364072747071592 and parameters: {'units': 32, 'dropout_rate': 0.2040078942260639}. Best is trial 21 with value: 0.6143583725318751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:27:40,420] Trial 24 finished with value: 0.6125256695284728 and parameters: {'units': 10, 'dropout_rate': 0.2578008004281273}. Best is trial 24 with value: 0.6125256695284728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:28:40,874] Trial 25 finished with value: 0.6120825705376208 and parameters: {'units': 12, 'dropout_rate': 0.10022513474581862}. Best is trial 25 with value: 0.6120825705376208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:29:43,524] Trial 26 finished with value: 0.6203807668969836 and parameters: {'units': 11, 'dropout_rate': 0.10553205525966941}. Best is trial 25 with value: 0.6120825705376208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:30:56,183] Trial 27 finished with value: 0.6219117470297392 and parameters: {'units': 19, 'dropout_rate': 0.14918969976772245}. Best is trial 25 with value: 0.6120825705376208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:32:32,489] Trial 28 finished with value: 0.6133632988390728 and parameters: {'units': 11, 'dropout_rate': 0.11164432301846859}. Best is trial 25 with value: 0.6120825705376208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-02 17:34:04,571] Trial 29 finished with value: 0.6183785246981112 and parameters: {'units': 25, 'dropout_rate': 0.10033135848157035}. Best is trial 25 with value: 0.6120825705376208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 3s 7ms/step\n",
      "55/55 [==============================] - 2s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define the LSTM model creation function\n",
    "def create_lstm_model(units, dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=False, input_shape=(1, X_train_m1_lstm.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))  # Assuming your output is a single continuous value\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Reshape input data to 3D for LSTM\n",
    "X_train_m1_lstm = X_train_m1_scaled.reshape((X_train_m1_scaled.shape[0], 1, X_train_m1_scaled.shape[1]))\n",
    "X_test_m1_lstm = X_test_m1_scaled.reshape((X_test_m1_scaled.shape[0], 1, X_test_m1_scaled.shape[1]))\n",
    "\n",
    "# Objective function for BBO\n",
    "def bbo_lstm_objective(trial):\n",
    "    units = trial.suggest_int(\"units\", 10, 100)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    \n",
    "    lstm_model = create_lstm_model(units=units, dropout_rate=dropout_rate)\n",
    "    lstm_model.fit(X_train_m1_lstm, y_train_m1, epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "    y_pred = lstm_model.predict(X_test_m1_lstm)\n",
    "    return mean_squared_error(y_test_m1, y_pred.flatten())\n",
    "\n",
    "# Create and optimize study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(bbo_lstm_objective, n_trials=30)\n",
    "\n",
    "# Retrieve best parameters\n",
    "best_units_bbo = study.best_params[\"units\"]\n",
    "best_dropout_rate_bbo = study.best_params[\"dropout_rate\"]\n",
    "\n",
    "# Train LSTM with BBO optimized parameters\n",
    "lstm_bbo_model = create_lstm_model(units=best_units_bbo, dropout_rate=best_dropout_rate_bbo)\n",
    "lstm_bbo_model.fit(X_train_m1_lstm, y_train_m1, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_bbo = lstm_bbo_model.predict(X_train_m1_lstm)\n",
    "y_test_pred_bbo = lstm_bbo_model.predict(X_test_m1_lstm)\n",
    "\n",
    "# Save the predictions\n",
    "results_train_bbo = pd.DataFrame({'GroundTruth': y_train_m1, 'Predictions': y_train_pred_bbo.flatten()})\n",
    "results_test_bbo = pd.DataFrame({'GroundTruth': y_test_m1, 'Predictions': y_test_pred_bbo.flatten()})\n",
    "\n",
    "results_train_bbo.to_excel('outputs/lstm_bbo_train_predictions.xlsx', index=False)\n",
    "results_test_bbo.to_excel('outputs/lstm_bbo_test_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
